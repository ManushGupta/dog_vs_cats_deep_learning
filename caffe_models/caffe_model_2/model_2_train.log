I0729 18:15:13.279281 17816 caffe.cpp:185] Using GPUs 0
I0729 18:15:13.296898 17816 caffe.cpp:190] GPU 0: GeForce GT 650M
I0729 18:15:13.459147 17816 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 5000
snapshot_prefix: "/home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2"
solver_mode: GPU
device_id: 0
net: "/home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffenet_train_val_2.prototxt"
I0729 18:15:13.459484 17816 solver.cpp:91] Creating training net from net file: /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffenet_train_val_2.prototxt
I0729 18:15:13.461314 17816 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0729 18:15:13.461402 17816 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0729 18:15:13.461947 17816 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/manush/deeplearning-image-classifier/input/mean.binaryproto"
  }
  data_param {
    source: "/home/manush/deeplearning-image-classifier/input/train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-cats-dogs"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8-cats-dogs"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-cats-dogs"
  bottom: "label"
  top: "loss"
}
I0729 18:15:13.462281 17816 layer_factory.hpp:77] Creating layer data
I0729 18:15:13.463476 17816 net.cpp:91] Creating Layer data
I0729 18:15:13.463542 17816 net.cpp:399] data -> data
I0729 18:15:13.463614 17816 net.cpp:399] data -> label
I0729 18:15:13.463654 17816 data_transformer.cpp:25] Loading mean file from: /home/manush/deeplearning-image-classifier/input/mean.binaryproto
I0729 18:15:13.473568 17822 db_lmdb.cpp:35] Opened lmdb /home/manush/deeplearning-image-classifier/input/train_lmdb
I0729 18:15:13.502698 17816 data_layer.cpp:41] output data size: 64,3,227,227
I0729 18:15:13.566813 17816 net.cpp:141] Setting up data
I0729 18:15:13.566892 17816 net.cpp:148] Top shape: 64 3 227 227 (9893568)
I0729 18:15:13.566903 17816 net.cpp:148] Top shape: 64 (64)
I0729 18:15:13.566910 17816 net.cpp:156] Memory required for data: 39574528
I0729 18:15:13.566923 17816 layer_factory.hpp:77] Creating layer conv1
I0729 18:15:13.566948 17816 net.cpp:91] Creating Layer conv1
I0729 18:15:13.566964 17816 net.cpp:425] conv1 <- data
I0729 18:15:13.566983 17816 net.cpp:399] conv1 -> conv1
I0729 18:15:13.574925 17816 net.cpp:141] Setting up conv1
I0729 18:15:13.574955 17816 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0729 18:15:13.574962 17816 net.cpp:156] Memory required for data: 113916928
I0729 18:15:13.575001 17816 layer_factory.hpp:77] Creating layer relu1
I0729 18:15:13.575016 17816 net.cpp:91] Creating Layer relu1
I0729 18:15:13.575023 17816 net.cpp:425] relu1 <- conv1
I0729 18:15:13.575032 17816 net.cpp:386] relu1 -> conv1 (in-place)
I0729 18:15:13.575047 17816 net.cpp:141] Setting up relu1
I0729 18:15:13.575054 17816 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0729 18:15:13.575060 17816 net.cpp:156] Memory required for data: 188259328
I0729 18:15:13.575065 17816 layer_factory.hpp:77] Creating layer pool1
I0729 18:15:13.575074 17816 net.cpp:91] Creating Layer pool1
I0729 18:15:13.575080 17816 net.cpp:425] pool1 <- conv1
I0729 18:15:13.575088 17816 net.cpp:399] pool1 -> pool1
I0729 18:15:13.575137 17816 net.cpp:141] Setting up pool1
I0729 18:15:13.575162 17816 net.cpp:148] Top shape: 64 96 27 27 (4478976)
I0729 18:15:13.575201 17816 net.cpp:156] Memory required for data: 206175232
I0729 18:15:13.575209 17816 layer_factory.hpp:77] Creating layer norm1
I0729 18:15:13.575220 17816 net.cpp:91] Creating Layer norm1
I0729 18:15:13.575227 17816 net.cpp:425] norm1 <- pool1
I0729 18:15:13.575234 17816 net.cpp:399] norm1 -> norm1
I0729 18:15:13.575274 17816 net.cpp:141] Setting up norm1
I0729 18:15:13.575285 17816 net.cpp:148] Top shape: 64 96 27 27 (4478976)
I0729 18:15:13.575291 17816 net.cpp:156] Memory required for data: 224091136
I0729 18:15:13.575297 17816 layer_factory.hpp:77] Creating layer conv2
I0729 18:15:13.575310 17816 net.cpp:91] Creating Layer conv2
I0729 18:15:13.575316 17816 net.cpp:425] conv2 <- norm1
I0729 18:15:13.575325 17816 net.cpp:399] conv2 -> conv2
I0729 18:15:13.586958 17816 net.cpp:141] Setting up conv2
I0729 18:15:13.586990 17816 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0729 18:15:13.586997 17816 net.cpp:156] Memory required for data: 271866880
I0729 18:15:13.587028 17816 layer_factory.hpp:77] Creating layer relu2
I0729 18:15:13.587043 17816 net.cpp:91] Creating Layer relu2
I0729 18:15:13.587049 17816 net.cpp:425] relu2 <- conv2
I0729 18:15:13.587059 17816 net.cpp:386] relu2 -> conv2 (in-place)
I0729 18:15:13.587072 17816 net.cpp:141] Setting up relu2
I0729 18:15:13.587080 17816 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0729 18:15:13.587085 17816 net.cpp:156] Memory required for data: 319642624
I0729 18:15:13.587091 17816 layer_factory.hpp:77] Creating layer pool2
I0729 18:15:13.587100 17816 net.cpp:91] Creating Layer pool2
I0729 18:15:13.587106 17816 net.cpp:425] pool2 <- conv2
I0729 18:15:13.587115 17816 net.cpp:399] pool2 -> pool2
I0729 18:15:13.587154 17816 net.cpp:141] Setting up pool2
I0729 18:15:13.587165 17816 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0729 18:15:13.587172 17816 net.cpp:156] Memory required for data: 330718208
I0729 18:15:13.587178 17816 layer_factory.hpp:77] Creating layer norm2
I0729 18:15:13.587189 17816 net.cpp:91] Creating Layer norm2
I0729 18:15:13.587195 17816 net.cpp:425] norm2 <- pool2
I0729 18:15:13.587203 17816 net.cpp:399] norm2 -> norm2
I0729 18:15:13.587234 17816 net.cpp:141] Setting up norm2
I0729 18:15:13.587245 17816 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0729 18:15:13.587251 17816 net.cpp:156] Memory required for data: 341793792
I0729 18:15:13.587257 17816 layer_factory.hpp:77] Creating layer conv3
I0729 18:15:13.587270 17816 net.cpp:91] Creating Layer conv3
I0729 18:15:13.587276 17816 net.cpp:425] conv3 <- norm2
I0729 18:15:13.587285 17816 net.cpp:399] conv3 -> conv3
I0729 18:15:13.590651 17823 blocking_queue.cpp:50] Waiting for data
I0729 18:15:13.613451 17816 net.cpp:141] Setting up conv3
I0729 18:15:13.613494 17816 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0729 18:15:13.613502 17816 net.cpp:156] Memory required for data: 358407168
I0729 18:15:13.613540 17816 layer_factory.hpp:77] Creating layer relu3
I0729 18:15:13.613554 17816 net.cpp:91] Creating Layer relu3
I0729 18:15:13.613561 17816 net.cpp:425] relu3 <- conv3
I0729 18:15:13.613571 17816 net.cpp:386] relu3 -> conv3 (in-place)
I0729 18:15:13.613584 17816 net.cpp:141] Setting up relu3
I0729 18:15:13.613590 17816 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0729 18:15:13.613596 17816 net.cpp:156] Memory required for data: 375020544
I0729 18:15:13.613602 17816 layer_factory.hpp:77] Creating layer conv4
I0729 18:15:13.613615 17816 net.cpp:91] Creating Layer conv4
I0729 18:15:13.613621 17816 net.cpp:425] conv4 <- conv3
I0729 18:15:13.613631 17816 net.cpp:399] conv4 -> conv4
I0729 18:15:13.633384 17816 net.cpp:141] Setting up conv4
I0729 18:15:13.633414 17816 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0729 18:15:13.633421 17816 net.cpp:156] Memory required for data: 391633920
I0729 18:15:13.633435 17816 layer_factory.hpp:77] Creating layer relu4
I0729 18:15:13.633447 17816 net.cpp:91] Creating Layer relu4
I0729 18:15:13.633455 17816 net.cpp:425] relu4 <- conv4
I0729 18:15:13.633466 17816 net.cpp:386] relu4 -> conv4 (in-place)
I0729 18:15:13.633477 17816 net.cpp:141] Setting up relu4
I0729 18:15:13.633507 17816 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0729 18:15:13.633520 17816 net.cpp:156] Memory required for data: 408247296
I0729 18:15:13.633532 17816 layer_factory.hpp:77] Creating layer conv5
I0729 18:15:13.633553 17816 net.cpp:91] Creating Layer conv5
I0729 18:15:13.633566 17816 net.cpp:425] conv5 <- conv4
I0729 18:15:13.633584 17816 net.cpp:399] conv5 -> conv5
I0729 18:15:13.646793 17816 net.cpp:141] Setting up conv5
I0729 18:15:13.646826 17816 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0729 18:15:13.646837 17816 net.cpp:156] Memory required for data: 419322880
I0729 18:15:13.646877 17816 layer_factory.hpp:77] Creating layer relu5
I0729 18:15:13.646898 17816 net.cpp:91] Creating Layer relu5
I0729 18:15:13.646913 17816 net.cpp:425] relu5 <- conv5
I0729 18:15:13.646941 17816 net.cpp:386] relu5 -> conv5 (in-place)
I0729 18:15:13.646967 17816 net.cpp:141] Setting up relu5
I0729 18:15:13.646984 17816 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0729 18:15:13.646996 17816 net.cpp:156] Memory required for data: 430398464
I0729 18:15:13.647007 17816 layer_factory.hpp:77] Creating layer pool5
I0729 18:15:13.647023 17816 net.cpp:91] Creating Layer pool5
I0729 18:15:13.647035 17816 net.cpp:425] pool5 <- conv5
I0729 18:15:13.647052 17816 net.cpp:399] pool5 -> pool5
I0729 18:15:13.647100 17816 net.cpp:141] Setting up pool5
I0729 18:15:13.647116 17816 net.cpp:148] Top shape: 64 256 6 6 (589824)
I0729 18:15:13.647127 17816 net.cpp:156] Memory required for data: 432757760
I0729 18:15:13.647140 17816 layer_factory.hpp:77] Creating layer fc6
I0729 18:15:13.647159 17816 net.cpp:91] Creating Layer fc6
I0729 18:15:13.647171 17816 net.cpp:425] fc6 <- pool5
I0729 18:15:13.647200 17816 net.cpp:399] fc6 -> fc6
I0729 18:15:14.728081 17816 net.cpp:141] Setting up fc6
I0729 18:15:14.728121 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:14.728132 17816 net.cpp:156] Memory required for data: 433806336
I0729 18:15:14.728152 17816 layer_factory.hpp:77] Creating layer relu6
I0729 18:15:14.728183 17816 net.cpp:91] Creating Layer relu6
I0729 18:15:14.728201 17816 net.cpp:425] relu6 <- fc6
I0729 18:15:14.728212 17816 net.cpp:386] relu6 -> fc6 (in-place)
I0729 18:15:14.728224 17816 net.cpp:141] Setting up relu6
I0729 18:15:14.728232 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:14.728237 17816 net.cpp:156] Memory required for data: 434854912
I0729 18:15:14.728243 17816 layer_factory.hpp:77] Creating layer drop6
I0729 18:15:14.728256 17816 net.cpp:91] Creating Layer drop6
I0729 18:15:14.728262 17816 net.cpp:425] drop6 <- fc6
I0729 18:15:14.728271 17816 net.cpp:386] drop6 -> fc6 (in-place)
I0729 18:15:14.728299 17816 net.cpp:141] Setting up drop6
I0729 18:15:14.728322 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:14.728327 17816 net.cpp:156] Memory required for data: 435903488
I0729 18:15:14.728333 17816 layer_factory.hpp:77] Creating layer fc7
I0729 18:15:14.728344 17816 net.cpp:91] Creating Layer fc7
I0729 18:15:14.728359 17816 net.cpp:425] fc7 <- fc6
I0729 18:15:14.728368 17816 net.cpp:399] fc7 -> fc7
I0729 18:15:15.203284 17816 net.cpp:141] Setting up fc7
I0729 18:15:15.203320 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:15.203336 17816 net.cpp:156] Memory required for data: 436952064
I0729 18:15:15.203349 17816 layer_factory.hpp:77] Creating layer relu7
I0729 18:15:15.203363 17816 net.cpp:91] Creating Layer relu7
I0729 18:15:15.203371 17816 net.cpp:425] relu7 <- fc7
I0729 18:15:15.203389 17816 net.cpp:386] relu7 -> fc7 (in-place)
I0729 18:15:15.203402 17816 net.cpp:141] Setting up relu7
I0729 18:15:15.203411 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:15.203418 17816 net.cpp:156] Memory required for data: 438000640
I0729 18:15:15.203423 17816 layer_factory.hpp:77] Creating layer drop7
I0729 18:15:15.203433 17816 net.cpp:91] Creating Layer drop7
I0729 18:15:15.203438 17816 net.cpp:425] drop7 <- fc7
I0729 18:15:15.203446 17816 net.cpp:386] drop7 -> fc7 (in-place)
I0729 18:15:15.203470 17816 net.cpp:141] Setting up drop7
I0729 18:15:15.203480 17816 net.cpp:148] Top shape: 64 4096 (262144)
I0729 18:15:15.203507 17816 net.cpp:156] Memory required for data: 439049216
I0729 18:15:15.203516 17816 layer_factory.hpp:77] Creating layer fc8-cats-dogs
I0729 18:15:15.203526 17816 net.cpp:91] Creating Layer fc8-cats-dogs
I0729 18:15:15.203531 17816 net.cpp:425] fc8-cats-dogs <- fc7
I0729 18:15:15.203541 17816 net.cpp:399] fc8-cats-dogs -> fc8-cats-dogs
I0729 18:15:15.204293 17816 net.cpp:141] Setting up fc8-cats-dogs
I0729 18:15:15.204308 17816 net.cpp:148] Top shape: 64 2 (128)
I0729 18:15:15.204313 17816 net.cpp:156] Memory required for data: 439049728
I0729 18:15:15.204322 17816 layer_factory.hpp:77] Creating layer loss
I0729 18:15:15.204336 17816 net.cpp:91] Creating Layer loss
I0729 18:15:15.204351 17816 net.cpp:425] loss <- fc8-cats-dogs
I0729 18:15:15.204360 17816 net.cpp:425] loss <- label
I0729 18:15:15.204370 17816 net.cpp:399] loss -> loss
I0729 18:15:15.204390 17816 layer_factory.hpp:77] Creating layer loss
I0729 18:15:15.204473 17816 net.cpp:141] Setting up loss
I0729 18:15:15.204484 17816 net.cpp:148] Top shape: (1)
I0729 18:15:15.204490 17816 net.cpp:151]     with loss weight 1
I0729 18:15:15.204514 17816 net.cpp:156] Memory required for data: 439049732
I0729 18:15:15.204530 17816 net.cpp:217] loss needs backward computation.
I0729 18:15:15.204537 17816 net.cpp:217] fc8-cats-dogs needs backward computation.
I0729 18:15:15.204543 17816 net.cpp:217] drop7 needs backward computation.
I0729 18:15:15.204550 17816 net.cpp:217] relu7 needs backward computation.
I0729 18:15:15.204555 17816 net.cpp:217] fc7 needs backward computation.
I0729 18:15:15.204560 17816 net.cpp:217] drop6 needs backward computation.
I0729 18:15:15.204566 17816 net.cpp:217] relu6 needs backward computation.
I0729 18:15:15.204571 17816 net.cpp:217] fc6 needs backward computation.
I0729 18:15:15.204577 17816 net.cpp:217] pool5 needs backward computation.
I0729 18:15:15.204584 17816 net.cpp:217] relu5 needs backward computation.
I0729 18:15:15.204589 17816 net.cpp:217] conv5 needs backward computation.
I0729 18:15:15.204596 17816 net.cpp:217] relu4 needs backward computation.
I0729 18:15:15.204602 17816 net.cpp:217] conv4 needs backward computation.
I0729 18:15:15.204607 17816 net.cpp:217] relu3 needs backward computation.
I0729 18:15:15.204613 17816 net.cpp:217] conv3 needs backward computation.
I0729 18:15:15.204619 17816 net.cpp:217] norm2 needs backward computation.
I0729 18:15:15.204625 17816 net.cpp:217] pool2 needs backward computation.
I0729 18:15:15.204632 17816 net.cpp:217] relu2 needs backward computation.
I0729 18:15:15.204638 17816 net.cpp:217] conv2 needs backward computation.
I0729 18:15:15.204643 17816 net.cpp:217] norm1 needs backward computation.
I0729 18:15:15.204649 17816 net.cpp:217] pool1 needs backward computation.
I0729 18:15:15.204655 17816 net.cpp:217] relu1 needs backward computation.
I0729 18:15:15.204661 17816 net.cpp:217] conv1 needs backward computation.
I0729 18:15:15.204668 17816 net.cpp:219] data does not need backward computation.
I0729 18:15:15.204674 17816 net.cpp:261] This network produces output loss
I0729 18:15:15.204689 17816 net.cpp:274] Network initialization done.
I0729 18:15:15.205360 17816 solver.cpp:181] Creating test net (#0) specified by net file: /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffenet_train_val_2.prototxt
I0729 18:15:15.205430 17816 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0729 18:15:15.205627 17816 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/manush/deeplearning-image-classifier/input/mean.binaryproto"
  }
  data_param {
    source: "/home/manush/deeplearning-image-classifier/input/validation_lmdb"
    batch_size: 25
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-cats-dogs"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8-cats-dogs"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8-cats-dogs"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-cats-dogs"
  bottom: "label"
  top: "loss"
}
I0729 18:15:15.205749 17816 layer_factory.hpp:77] Creating layer data
I0729 18:15:15.205832 17816 net.cpp:91] Creating Layer data
I0729 18:15:15.205843 17816 net.cpp:399] data -> data
I0729 18:15:15.205855 17816 net.cpp:399] data -> label
I0729 18:15:15.205868 17816 data_transformer.cpp:25] Loading mean file from: /home/manush/deeplearning-image-classifier/input/mean.binaryproto
I0729 18:15:15.243341 17826 db_lmdb.cpp:35] Opened lmdb /home/manush/deeplearning-image-classifier/input/validation_lmdb
I0729 18:15:15.265638 17816 data_layer.cpp:41] output data size: 25,3,227,227
I0729 18:15:15.295435 17816 net.cpp:141] Setting up data
I0729 18:15:15.295472 17816 net.cpp:148] Top shape: 25 3 227 227 (3864675)
I0729 18:15:15.295481 17816 net.cpp:148] Top shape: 25 (25)
I0729 18:15:15.295487 17816 net.cpp:156] Memory required for data: 15458800
I0729 18:15:15.295496 17816 layer_factory.hpp:77] Creating layer label_data_1_split
I0729 18:15:15.295514 17816 net.cpp:91] Creating Layer label_data_1_split
I0729 18:15:15.295524 17816 net.cpp:425] label_data_1_split <- label
I0729 18:15:15.295536 17816 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0729 18:15:15.295548 17816 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0729 18:15:15.295644 17816 net.cpp:141] Setting up label_data_1_split
I0729 18:15:15.295657 17816 net.cpp:148] Top shape: 25 (25)
I0729 18:15:15.295665 17816 net.cpp:148] Top shape: 25 (25)
I0729 18:15:15.295670 17816 net.cpp:156] Memory required for data: 15459000
I0729 18:15:15.295676 17816 layer_factory.hpp:77] Creating layer conv1
I0729 18:15:15.295692 17816 net.cpp:91] Creating Layer conv1
I0729 18:15:15.295699 17816 net.cpp:425] conv1 <- data
I0729 18:15:15.295707 17816 net.cpp:399] conv1 -> conv1
I0729 18:15:15.298930 17816 net.cpp:141] Setting up conv1
I0729 18:15:15.298954 17816 net.cpp:148] Top shape: 25 96 55 55 (7260000)
I0729 18:15:15.298960 17816 net.cpp:156] Memory required for data: 44499000
I0729 18:15:15.298975 17816 layer_factory.hpp:77] Creating layer relu1
I0729 18:15:15.298986 17816 net.cpp:91] Creating Layer relu1
I0729 18:15:15.298992 17816 net.cpp:425] relu1 <- conv1
I0729 18:15:15.299001 17816 net.cpp:386] relu1 -> conv1 (in-place)
I0729 18:15:15.299011 17816 net.cpp:141] Setting up relu1
I0729 18:15:15.299018 17816 net.cpp:148] Top shape: 25 96 55 55 (7260000)
I0729 18:15:15.299024 17816 net.cpp:156] Memory required for data: 73539000
I0729 18:15:15.299031 17816 layer_factory.hpp:77] Creating layer pool1
I0729 18:15:15.299039 17816 net.cpp:91] Creating Layer pool1
I0729 18:15:15.299046 17816 net.cpp:425] pool1 <- conv1
I0729 18:15:15.299053 17816 net.cpp:399] pool1 -> pool1
I0729 18:15:15.299091 17816 net.cpp:141] Setting up pool1
I0729 18:15:15.299100 17816 net.cpp:148] Top shape: 25 96 27 27 (1749600)
I0729 18:15:15.299106 17816 net.cpp:156] Memory required for data: 80537400
I0729 18:15:15.299113 17816 layer_factory.hpp:77] Creating layer norm1
I0729 18:15:15.299123 17816 net.cpp:91] Creating Layer norm1
I0729 18:15:15.299129 17816 net.cpp:425] norm1 <- pool1
I0729 18:15:15.299136 17816 net.cpp:399] norm1 -> norm1
I0729 18:15:15.299168 17816 net.cpp:141] Setting up norm1
I0729 18:15:15.299180 17816 net.cpp:148] Top shape: 25 96 27 27 (1749600)
I0729 18:15:15.299185 17816 net.cpp:156] Memory required for data: 87535800
I0729 18:15:15.299191 17816 layer_factory.hpp:77] Creating layer conv2
I0729 18:15:15.299203 17816 net.cpp:91] Creating Layer conv2
I0729 18:15:15.299209 17816 net.cpp:425] conv2 <- norm1
I0729 18:15:15.299218 17816 net.cpp:399] conv2 -> conv2
I0729 18:15:15.308888 17816 net.cpp:141] Setting up conv2
I0729 18:15:15.308928 17816 net.cpp:148] Top shape: 25 256 27 27 (4665600)
I0729 18:15:15.308936 17816 net.cpp:156] Memory required for data: 106198200
I0729 18:15:15.308954 17816 layer_factory.hpp:77] Creating layer relu2
I0729 18:15:15.308966 17816 net.cpp:91] Creating Layer relu2
I0729 18:15:15.308974 17816 net.cpp:425] relu2 <- conv2
I0729 18:15:15.308984 17816 net.cpp:386] relu2 -> conv2 (in-place)
I0729 18:15:15.308995 17816 net.cpp:141] Setting up relu2
I0729 18:15:15.309002 17816 net.cpp:148] Top shape: 25 256 27 27 (4665600)
I0729 18:15:15.309007 17816 net.cpp:156] Memory required for data: 124860600
I0729 18:15:15.309013 17816 layer_factory.hpp:77] Creating layer pool2
I0729 18:15:15.309025 17816 net.cpp:91] Creating Layer pool2
I0729 18:15:15.309046 17816 net.cpp:425] pool2 <- conv2
I0729 18:15:15.309056 17816 net.cpp:399] pool2 -> pool2
I0729 18:15:15.309097 17816 net.cpp:141] Setting up pool2
I0729 18:15:15.309108 17816 net.cpp:148] Top shape: 25 256 13 13 (1081600)
I0729 18:15:15.309114 17816 net.cpp:156] Memory required for data: 129187000
I0729 18:15:15.309120 17816 layer_factory.hpp:77] Creating layer norm2
I0729 18:15:15.309130 17816 net.cpp:91] Creating Layer norm2
I0729 18:15:15.309136 17816 net.cpp:425] norm2 <- pool2
I0729 18:15:15.309144 17816 net.cpp:399] norm2 -> norm2
I0729 18:15:15.309176 17816 net.cpp:141] Setting up norm2
I0729 18:15:15.309187 17816 net.cpp:148] Top shape: 25 256 13 13 (1081600)
I0729 18:15:15.309193 17816 net.cpp:156] Memory required for data: 133513400
I0729 18:15:15.309200 17816 layer_factory.hpp:77] Creating layer conv3
I0729 18:15:15.309211 17816 net.cpp:91] Creating Layer conv3
I0729 18:15:15.309217 17816 net.cpp:425] conv3 <- norm2
I0729 18:15:15.309226 17816 net.cpp:399] conv3 -> conv3
I0729 18:15:15.335759 17816 net.cpp:141] Setting up conv3
I0729 18:15:15.335808 17816 net.cpp:148] Top shape: 25 384 13 13 (1622400)
I0729 18:15:15.335816 17816 net.cpp:156] Memory required for data: 140003000
I0729 18:15:15.335834 17816 layer_factory.hpp:77] Creating layer relu3
I0729 18:15:15.335846 17816 net.cpp:91] Creating Layer relu3
I0729 18:15:15.335853 17816 net.cpp:425] relu3 <- conv3
I0729 18:15:15.335863 17816 net.cpp:386] relu3 -> conv3 (in-place)
I0729 18:15:15.335876 17816 net.cpp:141] Setting up relu3
I0729 18:15:15.335883 17816 net.cpp:148] Top shape: 25 384 13 13 (1622400)
I0729 18:15:15.335889 17816 net.cpp:156] Memory required for data: 146492600
I0729 18:15:15.335894 17816 layer_factory.hpp:77] Creating layer conv4
I0729 18:15:15.335907 17816 net.cpp:91] Creating Layer conv4
I0729 18:15:15.335913 17816 net.cpp:425] conv4 <- conv3
I0729 18:15:15.335922 17816 net.cpp:399] conv4 -> conv4
I0729 18:15:15.355428 17816 net.cpp:141] Setting up conv4
I0729 18:15:15.355456 17816 net.cpp:148] Top shape: 25 384 13 13 (1622400)
I0729 18:15:15.355473 17816 net.cpp:156] Memory required for data: 152982200
I0729 18:15:15.355485 17816 layer_factory.hpp:77] Creating layer relu4
I0729 18:15:15.355497 17816 net.cpp:91] Creating Layer relu4
I0729 18:15:15.355504 17816 net.cpp:425] relu4 <- conv4
I0729 18:15:15.355515 17816 net.cpp:386] relu4 -> conv4 (in-place)
I0729 18:15:15.355526 17816 net.cpp:141] Setting up relu4
I0729 18:15:15.355533 17816 net.cpp:148] Top shape: 25 384 13 13 (1622400)
I0729 18:15:15.355538 17816 net.cpp:156] Memory required for data: 159471800
I0729 18:15:15.355553 17816 layer_factory.hpp:77] Creating layer conv5
I0729 18:15:15.355567 17816 net.cpp:91] Creating Layer conv5
I0729 18:15:15.355573 17816 net.cpp:425] conv5 <- conv4
I0729 18:15:15.355582 17816 net.cpp:399] conv5 -> conv5
I0729 18:15:15.368950 17816 net.cpp:141] Setting up conv5
I0729 18:15:15.368981 17816 net.cpp:148] Top shape: 25 256 13 13 (1081600)
I0729 18:15:15.368998 17816 net.cpp:156] Memory required for data: 163798200
I0729 18:15:15.369014 17816 layer_factory.hpp:77] Creating layer relu5
I0729 18:15:15.369026 17816 net.cpp:91] Creating Layer relu5
I0729 18:15:15.369043 17816 net.cpp:425] relu5 <- conv5
I0729 18:15:15.369053 17816 net.cpp:386] relu5 -> conv5 (in-place)
I0729 18:15:15.369096 17816 net.cpp:141] Setting up relu5
I0729 18:15:15.369105 17816 net.cpp:148] Top shape: 25 256 13 13 (1081600)
I0729 18:15:15.369112 17816 net.cpp:156] Memory required for data: 168124600
I0729 18:15:15.369117 17816 layer_factory.hpp:77] Creating layer pool5
I0729 18:15:15.369127 17816 net.cpp:91] Creating Layer pool5
I0729 18:15:15.369143 17816 net.cpp:425] pool5 <- conv5
I0729 18:15:15.369151 17816 net.cpp:399] pool5 -> pool5
I0729 18:15:15.369190 17816 net.cpp:141] Setting up pool5
I0729 18:15:15.369202 17816 net.cpp:148] Top shape: 25 256 6 6 (230400)
I0729 18:15:15.369217 17816 net.cpp:156] Memory required for data: 169046200
I0729 18:15:15.369223 17816 layer_factory.hpp:77] Creating layer fc6
I0729 18:15:15.369235 17816 net.cpp:91] Creating Layer fc6
I0729 18:15:15.369240 17816 net.cpp:425] fc6 <- pool5
I0729 18:15:15.369249 17816 net.cpp:399] fc6 -> fc6
I0729 18:15:16.425621 17816 net.cpp:141] Setting up fc6
I0729 18:15:16.425664 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.425673 17816 net.cpp:156] Memory required for data: 169455800
I0729 18:15:16.425685 17816 layer_factory.hpp:77] Creating layer relu6
I0729 18:15:16.425699 17816 net.cpp:91] Creating Layer relu6
I0729 18:15:16.425706 17816 net.cpp:425] relu6 <- fc6
I0729 18:15:16.425716 17816 net.cpp:386] relu6 -> fc6 (in-place)
I0729 18:15:16.425729 17816 net.cpp:141] Setting up relu6
I0729 18:15:16.425745 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.425751 17816 net.cpp:156] Memory required for data: 169865400
I0729 18:15:16.425756 17816 layer_factory.hpp:77] Creating layer drop6
I0729 18:15:16.425765 17816 net.cpp:91] Creating Layer drop6
I0729 18:15:16.425771 17816 net.cpp:425] drop6 <- fc6
I0729 18:15:16.425779 17816 net.cpp:386] drop6 -> fc6 (in-place)
I0729 18:15:16.425817 17816 net.cpp:141] Setting up drop6
I0729 18:15:16.425825 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.425832 17816 net.cpp:156] Memory required for data: 170275000
I0729 18:15:16.425837 17816 layer_factory.hpp:77] Creating layer fc7
I0729 18:15:16.425848 17816 net.cpp:91] Creating Layer fc7
I0729 18:15:16.425853 17816 net.cpp:425] fc7 <- fc6
I0729 18:15:16.425863 17816 net.cpp:399] fc7 -> fc7
I0729 18:15:16.897529 17816 net.cpp:141] Setting up fc7
I0729 18:15:16.897563 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.897583 17816 net.cpp:156] Memory required for data: 170684600
I0729 18:15:16.897596 17816 layer_factory.hpp:77] Creating layer relu7
I0729 18:15:16.897609 17816 net.cpp:91] Creating Layer relu7
I0729 18:15:16.897617 17816 net.cpp:425] relu7 <- fc7
I0729 18:15:16.897627 17816 net.cpp:386] relu7 -> fc7 (in-place)
I0729 18:15:16.897639 17816 net.cpp:141] Setting up relu7
I0729 18:15:16.897646 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.897651 17816 net.cpp:156] Memory required for data: 171094200
I0729 18:15:16.897671 17816 layer_factory.hpp:77] Creating layer drop7
I0729 18:15:16.897680 17816 net.cpp:91] Creating Layer drop7
I0729 18:15:16.897686 17816 net.cpp:425] drop7 <- fc7
I0729 18:15:16.897693 17816 net.cpp:386] drop7 -> fc7 (in-place)
I0729 18:15:16.897722 17816 net.cpp:141] Setting up drop7
I0729 18:15:16.897743 17816 net.cpp:148] Top shape: 25 4096 (102400)
I0729 18:15:16.897749 17816 net.cpp:156] Memory required for data: 171503800
I0729 18:15:16.897755 17816 layer_factory.hpp:77] Creating layer fc8-cats-dogs
I0729 18:15:16.897765 17816 net.cpp:91] Creating Layer fc8-cats-dogs
I0729 18:15:16.897771 17816 net.cpp:425] fc8-cats-dogs <- fc7
I0729 18:15:16.897779 17816 net.cpp:399] fc8-cats-dogs -> fc8-cats-dogs
I0729 18:15:16.898097 17816 net.cpp:141] Setting up fc8-cats-dogs
I0729 18:15:16.898108 17816 net.cpp:148] Top shape: 25 2 (50)
I0729 18:15:16.898114 17816 net.cpp:156] Memory required for data: 171504000
I0729 18:15:16.898136 17816 layer_factory.hpp:77] Creating layer fc8-cats-dogs_fc8-cats-dogs_0_split
I0729 18:15:16.898144 17816 net.cpp:91] Creating Layer fc8-cats-dogs_fc8-cats-dogs_0_split
I0729 18:15:16.898150 17816 net.cpp:425] fc8-cats-dogs_fc8-cats-dogs_0_split <- fc8-cats-dogs
I0729 18:15:16.898178 17816 net.cpp:399] fc8-cats-dogs_fc8-cats-dogs_0_split -> fc8-cats-dogs_fc8-cats-dogs_0_split_0
I0729 18:15:16.898190 17816 net.cpp:399] fc8-cats-dogs_fc8-cats-dogs_0_split -> fc8-cats-dogs_fc8-cats-dogs_0_split_1
I0729 18:15:16.898222 17816 net.cpp:141] Setting up fc8-cats-dogs_fc8-cats-dogs_0_split
I0729 18:15:16.898231 17816 net.cpp:148] Top shape: 25 2 (50)
I0729 18:15:16.898237 17816 net.cpp:148] Top shape: 25 2 (50)
I0729 18:15:16.898243 17816 net.cpp:156] Memory required for data: 171504400
I0729 18:15:16.898249 17816 layer_factory.hpp:77] Creating layer accuracy
I0729 18:15:16.898264 17816 net.cpp:91] Creating Layer accuracy
I0729 18:15:16.898270 17816 net.cpp:425] accuracy <- fc8-cats-dogs_fc8-cats-dogs_0_split_0
I0729 18:15:16.898277 17816 net.cpp:425] accuracy <- label_data_1_split_0
I0729 18:15:16.898285 17816 net.cpp:399] accuracy -> accuracy
I0729 18:15:16.898299 17816 net.cpp:141] Setting up accuracy
I0729 18:15:16.898306 17816 net.cpp:148] Top shape: (1)
I0729 18:15:16.898311 17816 net.cpp:156] Memory required for data: 171504404
I0729 18:15:16.898318 17816 layer_factory.hpp:77] Creating layer loss
I0729 18:15:16.898325 17816 net.cpp:91] Creating Layer loss
I0729 18:15:16.898330 17816 net.cpp:425] loss <- fc8-cats-dogs_fc8-cats-dogs_0_split_1
I0729 18:15:16.898337 17816 net.cpp:425] loss <- label_data_1_split_1
I0729 18:15:16.898344 17816 net.cpp:399] loss -> loss
I0729 18:15:16.898355 17816 layer_factory.hpp:77] Creating layer loss
I0729 18:15:16.898442 17816 net.cpp:141] Setting up loss
I0729 18:15:16.898452 17816 net.cpp:148] Top shape: (1)
I0729 18:15:16.898458 17816 net.cpp:151]     with loss weight 1
I0729 18:15:16.898484 17816 net.cpp:156] Memory required for data: 171504408
I0729 18:15:16.898490 17816 net.cpp:217] loss needs backward computation.
I0729 18:15:16.898497 17816 net.cpp:219] accuracy does not need backward computation.
I0729 18:15:16.898504 17816 net.cpp:217] fc8-cats-dogs_fc8-cats-dogs_0_split needs backward computation.
I0729 18:15:16.898509 17816 net.cpp:217] fc8-cats-dogs needs backward computation.
I0729 18:15:16.898515 17816 net.cpp:217] drop7 needs backward computation.
I0729 18:15:16.898520 17816 net.cpp:217] relu7 needs backward computation.
I0729 18:15:16.898525 17816 net.cpp:217] fc7 needs backward computation.
I0729 18:15:16.898531 17816 net.cpp:217] drop6 needs backward computation.
I0729 18:15:16.898536 17816 net.cpp:217] relu6 needs backward computation.
I0729 18:15:16.898542 17816 net.cpp:217] fc6 needs backward computation.
I0729 18:15:16.898548 17816 net.cpp:217] pool5 needs backward computation.
I0729 18:15:16.898553 17816 net.cpp:217] relu5 needs backward computation.
I0729 18:15:16.898560 17816 net.cpp:217] conv5 needs backward computation.
I0729 18:15:16.898566 17816 net.cpp:217] relu4 needs backward computation.
I0729 18:15:16.898571 17816 net.cpp:217] conv4 needs backward computation.
I0729 18:15:16.898576 17816 net.cpp:217] relu3 needs backward computation.
I0729 18:15:16.898582 17816 net.cpp:217] conv3 needs backward computation.
I0729 18:15:16.898588 17816 net.cpp:217] norm2 needs backward computation.
I0729 18:15:16.898594 17816 net.cpp:217] pool2 needs backward computation.
I0729 18:15:16.898600 17816 net.cpp:217] relu2 needs backward computation.
I0729 18:15:16.898605 17816 net.cpp:217] conv2 needs backward computation.
I0729 18:15:16.898612 17816 net.cpp:217] norm1 needs backward computation.
I0729 18:15:16.898617 17816 net.cpp:217] pool1 needs backward computation.
I0729 18:15:16.898623 17816 net.cpp:217] relu1 needs backward computation.
I0729 18:15:16.898628 17816 net.cpp:217] conv1 needs backward computation.
I0729 18:15:16.898635 17816 net.cpp:219] label_data_1_split does not need backward computation.
I0729 18:15:16.898641 17816 net.cpp:219] data does not need backward computation.
I0729 18:15:16.898646 17816 net.cpp:261] This network produces output accuracy
I0729 18:15:16.898653 17816 net.cpp:261] This network produces output loss
I0729 18:15:16.898669 17816 net.cpp:274] Network initialization done.
I0729 18:15:16.898797 17816 solver.cpp:60] Solver scaffolding done.
I0729 18:15:16.899248 17816 caffe.cpp:129] Finetuning from /home/manush/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0729 18:15:21.600379 17816 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/manush/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0729 18:15:21.600464 17816 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0729 18:15:21.600481 17816 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0729 18:15:21.600719 17816 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/manush/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0729 18:15:21.861312 17816 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0729 18:15:21.940490 17816 net.cpp:752] Ignoring source layer fc8
I0729 18:15:23.166752 17816 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/manush/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0729 18:15:23.166802 17816 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0729 18:15:23.166813 17816 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0729 18:15:23.166833 17816 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/manush/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0729 18:15:23.662422 17816 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0729 18:15:23.716400 17816 net.cpp:752] Ignoring source layer fc8
I0729 18:15:23.749168 17816 caffe.cpp:219] Starting Optimization
I0729 18:15:23.749212 17816 solver.cpp:279] Solving CaffeNet
I0729 18:15:23.749222 17816 solver.cpp:280] Learning Rate Policy: step
I0729 18:15:23.750753 17816 solver.cpp:337] Iteration 0, Testing net (#0)
I0729 18:19:26.112368 17816 solver.cpp:404]     Test net output #0: accuracy = 0.423599
I0729 18:19:26.112493 17816 solver.cpp:404]     Test net output #1: loss = 0.882282 (* 1 = 0.882282 loss)
I0729 18:19:27.577078 17816 solver.cpp:228] Iteration 0, loss = 0.87424
I0729 18:19:27.577134 17816 solver.cpp:244]     Train net output #0: loss = 0.87424 (* 1 = 0.87424 loss)
I0729 18:19:27.577180 17816 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0729 18:21:00.230490 17816 solver.cpp:228] Iteration 50, loss = 0.0680368
I0729 18:21:00.230618 17816 solver.cpp:244]     Train net output #0: loss = 0.0680368 (* 1 = 0.0680368 loss)
I0729 18:21:00.230645 17816 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0729 18:22:32.259397 17816 solver.cpp:228] Iteration 100, loss = 0.178605
I0729 18:22:32.259536 17816 solver.cpp:244]     Train net output #0: loss = 0.178605 (* 1 = 0.178605 loss)
I0729 18:22:32.259564 17816 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0729 18:24:06.720098 17816 solver.cpp:228] Iteration 150, loss = 0.0831821
I0729 18:24:06.720228 17816 solver.cpp:244]     Train net output #0: loss = 0.0831821 (* 1 = 0.0831821 loss)
I0729 18:24:06.720257 17816 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0729 18:25:40.546203 17816 solver.cpp:228] Iteration 200, loss = 0.144286
I0729 18:25:40.546366 17816 solver.cpp:244]     Train net output #0: loss = 0.144286 (* 1 = 0.144286 loss)
I0729 18:25:40.546393 17816 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0729 18:27:14.034513 17816 solver.cpp:228] Iteration 250, loss = 0.106414
I0729 18:27:14.034679 17816 solver.cpp:244]     Train net output #0: loss = 0.106414 (* 1 = 0.106414 loss)
I0729 18:27:14.034711 17816 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0729 18:28:47.329707 17816 solver.cpp:228] Iteration 300, loss = 0.0822473
I0729 18:28:47.329838 17816 solver.cpp:244]     Train net output #0: loss = 0.0822473 (* 1 = 0.0822473 loss)
I0729 18:28:47.329855 17816 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0729 18:30:20.536810 17816 solver.cpp:228] Iteration 350, loss = 0.0506567
I0729 18:30:20.536926 17816 solver.cpp:244]     Train net output #0: loss = 0.0506567 (* 1 = 0.0506567 loss)
I0729 18:30:20.536943 17816 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0729 18:31:55.760839 17816 solver.cpp:228] Iteration 400, loss = 0.146081
I0729 18:31:55.760967 17816 solver.cpp:244]     Train net output #0: loss = 0.146081 (* 1 = 0.146081 loss)
I0729 18:31:55.760984 17816 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0729 18:33:33.873584 17816 solver.cpp:228] Iteration 450, loss = 0.0707053
I0729 18:33:33.873716 17816 solver.cpp:244]     Train net output #0: loss = 0.0707053 (* 1 = 0.0707053 loss)
I0729 18:33:33.873734 17816 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0729 18:35:10.722461 17816 solver.cpp:228] Iteration 500, loss = 0.0390339
I0729 18:35:10.722628 17816 solver.cpp:244]     Train net output #0: loss = 0.0390339 (* 1 = 0.0390339 loss)
I0729 18:35:10.722646 17816 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0729 18:36:46.211900 17816 solver.cpp:228] Iteration 550, loss = 0.0230326
I0729 18:36:46.212029 17816 solver.cpp:244]     Train net output #0: loss = 0.0230326 (* 1 = 0.0230326 loss)
I0729 18:36:46.212047 17816 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0729 18:38:21.575897 17816 solver.cpp:228] Iteration 600, loss = 0.104897
I0729 18:38:21.576056 17816 solver.cpp:244]     Train net output #0: loss = 0.104897 (* 1 = 0.104897 loss)
I0729 18:38:21.576073 17816 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0729 18:39:56.953811 17816 solver.cpp:228] Iteration 650, loss = 0.106078
I0729 18:39:56.953984 17816 solver.cpp:244]     Train net output #0: loss = 0.106078 (* 1 = 0.106078 loss)
I0729 18:39:56.954002 17816 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0729 18:41:32.229729 17816 solver.cpp:228] Iteration 700, loss = 0.0382654
I0729 18:41:32.229890 17816 solver.cpp:244]     Train net output #0: loss = 0.0382653 (* 1 = 0.0382653 loss)
I0729 18:41:32.229908 17816 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0729 18:43:07.433403 17816 solver.cpp:228] Iteration 750, loss = 0.0364346
I0729 18:43:07.433571 17816 solver.cpp:244]     Train net output #0: loss = 0.0364345 (* 1 = 0.0364345 loss)
I0729 18:43:07.433589 17816 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0729 18:44:42.740736 17816 solver.cpp:228] Iteration 800, loss = 0.031716
I0729 18:44:42.740864 17816 solver.cpp:244]     Train net output #0: loss = 0.0317159 (* 1 = 0.0317159 loss)
I0729 18:44:42.740880 17816 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0729 18:46:18.061730 17816 solver.cpp:228] Iteration 850, loss = 0.0523669
I0729 18:46:18.061852 17816 solver.cpp:244]     Train net output #0: loss = 0.0523669 (* 1 = 0.0523669 loss)
I0729 18:46:18.061869 17816 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0729 18:47:57.945673 17816 solver.cpp:228] Iteration 900, loss = 0.0717026
I0729 18:47:57.945823 17816 solver.cpp:244]     Train net output #0: loss = 0.0717026 (* 1 = 0.0717026 loss)
I0729 18:47:57.945843 17816 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0729 18:49:38.714942 17816 solver.cpp:228] Iteration 950, loss = 0.0773925
I0729 18:49:38.715129 17816 solver.cpp:244]     Train net output #0: loss = 0.0773925 (* 1 = 0.0773925 loss)
I0729 18:49:38.715150 17816 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0729 18:51:15.891548 17816 solver.cpp:337] Iteration 1000, Testing net (#0)
I0729 18:55:44.204500 17816 solver.cpp:404]     Test net output #0: accuracy = 0.961123
I0729 18:55:44.204630 17816 solver.cpp:404]     Test net output #1: loss = 0.0990699 (* 1 = 0.0990699 loss)
I0729 18:55:45.614490 17816 solver.cpp:228] Iteration 1000, loss = 0.0203576
I0729 18:55:45.614542 17816 solver.cpp:244]     Train net output #0: loss = 0.0203576 (* 1 = 0.0203576 loss)
I0729 18:55:45.614558 17816 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0729 18:57:22.608886 17816 solver.cpp:228] Iteration 1050, loss = 0.0347018
I0729 18:57:22.609159 17816 solver.cpp:244]     Train net output #0: loss = 0.0347018 (* 1 = 0.0347018 loss)
I0729 18:57:22.609177 17816 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0729 18:58:59.367118 17816 solver.cpp:228] Iteration 1100, loss = 0.0451125
I0729 18:58:59.390777 17816 solver.cpp:244]     Train net output #0: loss = 0.0451124 (* 1 = 0.0451124 loss)
I0729 18:58:59.390832 17816 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0729 19:00:36.293186 17816 solver.cpp:228] Iteration 1150, loss = 0.0889296
I0729 19:00:36.293319 17816 solver.cpp:244]     Train net output #0: loss = 0.0889296 (* 1 = 0.0889296 loss)
I0729 19:00:36.293337 17816 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0729 19:02:12.994954 17816 solver.cpp:228] Iteration 1200, loss = 0.0220462
I0729 19:02:12.995086 17816 solver.cpp:244]     Train net output #0: loss = 0.0220462 (* 1 = 0.0220462 loss)
I0729 19:02:12.995105 17816 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0729 19:03:50.017911 17816 solver.cpp:228] Iteration 1250, loss = 0.0308664
I0729 19:03:50.018070 17816 solver.cpp:244]     Train net output #0: loss = 0.0308663 (* 1 = 0.0308663 loss)
I0729 19:03:50.018088 17816 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0729 19:05:27.098074 17816 solver.cpp:228] Iteration 1300, loss = 0.121909
I0729 19:05:27.098234 17816 solver.cpp:244]     Train net output #0: loss = 0.121909 (* 1 = 0.121909 loss)
I0729 19:05:27.098253 17816 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0729 19:07:04.096316 17816 solver.cpp:228] Iteration 1350, loss = 0.0155192
I0729 19:07:04.096443 17816 solver.cpp:244]     Train net output #0: loss = 0.0155191 (* 1 = 0.0155191 loss)
I0729 19:07:04.096462 17816 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0729 19:08:40.951531 17816 solver.cpp:228] Iteration 1400, loss = 0.0157801
I0729 19:08:40.951673 17816 solver.cpp:244]     Train net output #0: loss = 0.01578 (* 1 = 0.01578 loss)
I0729 19:08:40.951691 17816 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0729 19:10:17.858695 17816 solver.cpp:228] Iteration 1450, loss = 0.0264895
I0729 19:10:17.858902 17816 solver.cpp:244]     Train net output #0: loss = 0.0264894 (* 1 = 0.0264894 loss)
I0729 19:10:17.858933 17816 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0729 19:11:54.864729 17816 solver.cpp:228] Iteration 1500, loss = 0.0539862
I0729 19:11:54.864925 17816 solver.cpp:244]     Train net output #0: loss = 0.0539862 (* 1 = 0.0539862 loss)
I0729 19:11:54.864943 17816 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0729 19:13:31.794560 17816 solver.cpp:228] Iteration 1550, loss = 0.0480264
I0729 19:13:31.794724 17816 solver.cpp:244]     Train net output #0: loss = 0.0480263 (* 1 = 0.0480263 loss)
I0729 19:13:31.794742 17816 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0729 19:15:08.750679 17816 solver.cpp:228] Iteration 1600, loss = 0.04758
I0729 19:15:08.750811 17816 solver.cpp:244]     Train net output #0: loss = 0.0475799 (* 1 = 0.0475799 loss)
I0729 19:15:08.750828 17816 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0729 19:16:45.626233 17816 solver.cpp:228] Iteration 1650, loss = 0.0257448
I0729 19:16:45.626391 17816 solver.cpp:244]     Train net output #0: loss = 0.0257448 (* 1 = 0.0257448 loss)
I0729 19:16:45.626410 17816 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0729 19:18:22.443331 17816 solver.cpp:228] Iteration 1700, loss = 0.0132252
I0729 19:18:22.443462 17816 solver.cpp:244]     Train net output #0: loss = 0.0132251 (* 1 = 0.0132251 loss)
I0729 19:18:22.443480 17816 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0729 19:19:59.332785 17816 solver.cpp:228] Iteration 1750, loss = 0.0105424
I0729 19:19:59.332948 17816 solver.cpp:244]     Train net output #0: loss = 0.0105424 (* 1 = 0.0105424 loss)
I0729 19:19:59.332967 17816 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0729 19:21:36.275655 17816 solver.cpp:228] Iteration 1800, loss = 0.0127506
I0729 19:21:36.275816 17816 solver.cpp:244]     Train net output #0: loss = 0.0127506 (* 1 = 0.0127506 loss)
I0729 19:21:36.275835 17816 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0729 19:23:13.285599 17816 solver.cpp:228] Iteration 1850, loss = 0.023095
I0729 19:23:13.285753 17816 solver.cpp:244]     Train net output #0: loss = 0.023095 (* 1 = 0.023095 loss)
I0729 19:23:13.285770 17816 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0729 19:24:50.110898 17816 solver.cpp:228] Iteration 1900, loss = 0.0844871
I0729 19:24:50.111024 17816 solver.cpp:244]     Train net output #0: loss = 0.0844871 (* 1 = 0.0844871 loss)
I0729 19:24:50.111042 17816 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0729 19:26:27.179811 17816 solver.cpp:228] Iteration 1950, loss = 0.0184255
I0729 19:26:27.179940 17816 solver.cpp:244]     Train net output #0: loss = 0.0184254 (* 1 = 0.0184254 loss)
I0729 19:26:27.179960 17816 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0729 19:28:02.123317 17816 solver.cpp:337] Iteration 2000, Testing net (#0)
I0729 19:32:30.258347 17816 solver.cpp:404]     Test net output #0: accuracy = 0.971923
I0729 19:32:30.258476 17816 solver.cpp:404]     Test net output #1: loss = 0.0811658 (* 1 = 0.0811658 loss)
I0729 19:32:31.660534 17816 solver.cpp:228] Iteration 2000, loss = 0.00288333
I0729 19:32:31.660585 17816 solver.cpp:244]     Train net output #0: loss = 0.0028833 (* 1 = 0.0028833 loss)
I0729 19:32:31.660601 17816 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0729 19:34:08.639346 17816 solver.cpp:228] Iteration 2050, loss = 0.00703757
I0729 19:34:08.639506 17816 solver.cpp:244]     Train net output #0: loss = 0.00703754 (* 1 = 0.00703754 loss)
I0729 19:34:08.639524 17816 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0729 19:35:45.328119 17816 solver.cpp:228] Iteration 2100, loss = 0.00140077
I0729 19:35:45.328250 17816 solver.cpp:244]     Train net output #0: loss = 0.00140075 (* 1 = 0.00140075 loss)
I0729 19:35:45.328269 17816 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0729 19:37:20.778228 17816 solver.cpp:228] Iteration 2150, loss = 0.00530195
I0729 19:37:20.778394 17816 solver.cpp:244]     Train net output #0: loss = 0.0053019 (* 1 = 0.0053019 loss)
I0729 19:37:20.778412 17816 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0729 19:38:56.120853 17816 solver.cpp:228] Iteration 2200, loss = 0.0334333
I0729 19:38:56.120977 17816 solver.cpp:244]     Train net output #0: loss = 0.0334332 (* 1 = 0.0334332 loss)
I0729 19:38:56.120995 17816 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0729 19:40:31.645438 17816 solver.cpp:228] Iteration 2250, loss = 0.025958
I0729 19:40:31.645565 17816 solver.cpp:244]     Train net output #0: loss = 0.0259579 (* 1 = 0.0259579 loss)
I0729 19:40:31.645583 17816 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0729 19:42:07.033350 17816 solver.cpp:228] Iteration 2300, loss = 0.0239762
I0729 19:42:07.033529 17816 solver.cpp:244]     Train net output #0: loss = 0.0239762 (* 1 = 0.0239762 loss)
I0729 19:42:07.033547 17816 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0729 19:43:42.539046 17816 solver.cpp:228] Iteration 2350, loss = 0.00733445
I0729 19:43:42.539180 17816 solver.cpp:244]     Train net output #0: loss = 0.00733439 (* 1 = 0.00733439 loss)
I0729 19:43:42.539198 17816 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0729 19:45:17.973269 17816 solver.cpp:228] Iteration 2400, loss = 0.00237508
I0729 19:45:17.973455 17816 solver.cpp:244]     Train net output #0: loss = 0.00237502 (* 1 = 0.00237502 loss)
I0729 19:45:17.973474 17816 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0729 19:46:53.363730 17816 solver.cpp:228] Iteration 2450, loss = 0.036314
I0729 19:46:53.363862 17816 solver.cpp:244]     Train net output #0: loss = 0.036314 (* 1 = 0.036314 loss)
I0729 19:46:53.363878 17816 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0729 19:48:28.610319 17816 solver.cpp:228] Iteration 2500, loss = 0.0227321
I0729 19:48:28.610447 17816 solver.cpp:244]     Train net output #0: loss = 0.022732 (* 1 = 0.022732 loss)
I0729 19:48:28.610465 17816 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0729 19:50:04.069950 17816 solver.cpp:228] Iteration 2550, loss = 0.0088155
I0729 19:50:04.070096 17816 solver.cpp:244]     Train net output #0: loss = 0.00881546 (* 1 = 0.00881546 loss)
I0729 19:50:04.070114 17816 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0729 19:51:39.589330 17816 solver.cpp:228] Iteration 2600, loss = 0.00388792
I0729 19:51:39.618674 17816 solver.cpp:244]     Train net output #0: loss = 0.00388788 (* 1 = 0.00388788 loss)
I0729 19:51:39.618741 17816 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0729 19:53:13.938697 17816 solver.cpp:228] Iteration 2650, loss = 0.00791217
I0729 19:53:13.938863 17816 solver.cpp:244]     Train net output #0: loss = 0.00791213 (* 1 = 0.00791213 loss)
I0729 19:53:13.938884 17816 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0729 19:54:47.147642 17816 solver.cpp:228] Iteration 2700, loss = 0.000471493
I0729 19:54:47.147807 17816 solver.cpp:244]     Train net output #0: loss = 0.000471454 (* 1 = 0.000471454 loss)
I0729 19:54:47.147827 17816 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0729 19:56:20.280208 17816 solver.cpp:228] Iteration 2750, loss = 0.00517255
I0729 19:56:20.280351 17816 solver.cpp:244]     Train net output #0: loss = 0.00517251 (* 1 = 0.00517251 loss)
I0729 19:56:20.280371 17816 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0729 19:57:53.567337 17816 solver.cpp:228] Iteration 2800, loss = 0.00169401
I0729 19:57:53.567517 17816 solver.cpp:244]     Train net output #0: loss = 0.00169397 (* 1 = 0.00169397 loss)
I0729 19:57:53.567535 17816 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0729 19:59:26.685525 17816 solver.cpp:228] Iteration 2850, loss = 0.00858617
I0729 19:59:26.685757 17816 solver.cpp:244]     Train net output #0: loss = 0.00858613 (* 1 = 0.00858613 loss)
I0729 19:59:26.685787 17816 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0729 20:00:59.942093 17816 solver.cpp:228] Iteration 2900, loss = 0.0108446
I0729 20:00:59.942265 17816 solver.cpp:244]     Train net output #0: loss = 0.0108445 (* 1 = 0.0108445 loss)
I0729 20:00:59.942284 17816 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0729 20:02:33.189859 17816 solver.cpp:228] Iteration 2950, loss = 0.0013595
I0729 20:02:33.190006 17816 solver.cpp:244]     Train net output #0: loss = 0.00135947 (* 1 = 0.00135947 loss)
I0729 20:02:33.190024 17816 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0729 20:04:04.750470 17816 solver.cpp:337] Iteration 3000, Testing net (#0)
I0729 20:08:27.551314 17816 solver.cpp:404]     Test net output #0: accuracy = 0.971922
I0729 20:08:27.551447 17816 solver.cpp:404]     Test net output #1: loss = 0.0815316 (* 1 = 0.0815316 loss)
I0729 20:08:28.936740 17816 solver.cpp:228] Iteration 3000, loss = 0.00416556
I0729 20:08:28.936790 17816 solver.cpp:244]     Train net output #0: loss = 0.00416553 (* 1 = 0.00416553 loss)
I0729 20:08:28.936806 17816 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0729 20:10:04.311069 17816 solver.cpp:228] Iteration 3050, loss = 0.000836443
I0729 20:10:04.311202 17816 solver.cpp:244]     Train net output #0: loss = 0.000836411 (* 1 = 0.000836411 loss)
I0729 20:10:04.311219 17816 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0729 20:11:39.630372 17816 solver.cpp:228] Iteration 3100, loss = 0.000508513
I0729 20:11:39.630501 17816 solver.cpp:244]     Train net output #0: loss = 0.000508474 (* 1 = 0.000508474 loss)
I0729 20:11:39.630518 17816 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0729 20:13:15.009554 17816 solver.cpp:228] Iteration 3150, loss = 0.00101113
I0729 20:13:15.009737 17816 solver.cpp:244]     Train net output #0: loss = 0.00101109 (* 1 = 0.00101109 loss)
I0729 20:13:15.009755 17816 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0729 20:14:50.403020 17816 solver.cpp:228] Iteration 3200, loss = 0.00245353
I0729 20:14:50.403192 17816 solver.cpp:244]     Train net output #0: loss = 0.00245348 (* 1 = 0.00245348 loss)
I0729 20:14:50.403213 17816 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0729 20:16:25.805416 17816 solver.cpp:228] Iteration 3250, loss = 0.00365199
I0729 20:16:25.805619 17816 solver.cpp:244]     Train net output #0: loss = 0.00365194 (* 1 = 0.00365194 loss)
I0729 20:16:25.805639 17816 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0729 20:18:01.329838 17816 solver.cpp:228] Iteration 3300, loss = 0.0163464
I0729 20:18:01.353019 17816 solver.cpp:244]     Train net output #0: loss = 0.0163464 (* 1 = 0.0163464 loss)
I0729 20:18:01.353071 17816 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0729 20:19:34.576201 17816 solver.cpp:228] Iteration 3350, loss = 0.0452745
I0729 20:19:34.576393 17816 solver.cpp:244]     Train net output #0: loss = 0.0452745 (* 1 = 0.0452745 loss)
I0729 20:19:34.576427 17816 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0729 20:21:07.677353 17816 solver.cpp:228] Iteration 3400, loss = 0.00180945
I0729 20:21:07.677533 17816 solver.cpp:244]     Train net output #0: loss = 0.0018094 (* 1 = 0.0018094 loss)
I0729 20:21:07.677556 17816 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0729 20:22:40.889323 17816 solver.cpp:228] Iteration 3450, loss = 0.00965745
I0729 20:22:40.889493 17816 solver.cpp:244]     Train net output #0: loss = 0.00965741 (* 1 = 0.00965741 loss)
I0729 20:22:40.889513 17816 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0729 20:24:14.061995 17816 solver.cpp:228] Iteration 3500, loss = 0.00951671
I0729 20:24:14.062163 17816 solver.cpp:244]     Train net output #0: loss = 0.00951667 (* 1 = 0.00951667 loss)
I0729 20:24:14.062186 17816 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0729 20:25:47.332904 17816 solver.cpp:228] Iteration 3550, loss = 0.00145943
I0729 20:25:47.333050 17816 solver.cpp:244]     Train net output #0: loss = 0.00145939 (* 1 = 0.00145939 loss)
I0729 20:25:47.333071 17816 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0729 20:27:20.596956 17816 solver.cpp:228] Iteration 3600, loss = 0.0142439
I0729 20:27:20.597149 17816 solver.cpp:244]     Train net output #0: loss = 0.0142438 (* 1 = 0.0142438 loss)
I0729 20:27:20.597172 17816 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0729 20:28:53.658149 17816 solver.cpp:228] Iteration 3650, loss = 0.00313059
I0729 20:28:53.658360 17816 solver.cpp:244]     Train net output #0: loss = 0.00313055 (* 1 = 0.00313055 loss)
I0729 20:28:53.658383 17816 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0729 20:30:26.773062 17816 solver.cpp:228] Iteration 3700, loss = 0.00620259
I0729 20:30:26.773229 17816 solver.cpp:244]     Train net output #0: loss = 0.00620255 (* 1 = 0.00620255 loss)
I0729 20:30:26.773249 17816 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0729 20:31:59.979804 17816 solver.cpp:228] Iteration 3750, loss = 0.00117982
I0729 20:31:59.979989 17816 solver.cpp:244]     Train net output #0: loss = 0.00117978 (* 1 = 0.00117978 loss)
I0729 20:31:59.980011 17816 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0729 20:33:33.264106 17816 solver.cpp:228] Iteration 3800, loss = 0.00199072
I0729 20:33:33.264255 17816 solver.cpp:244]     Train net output #0: loss = 0.00199068 (* 1 = 0.00199068 loss)
I0729 20:33:33.264276 17816 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0729 20:35:06.525226 17816 solver.cpp:228] Iteration 3850, loss = 0.00675799
I0729 20:35:06.525370 17816 solver.cpp:244]     Train net output #0: loss = 0.00675795 (* 1 = 0.00675795 loss)
I0729 20:35:06.525393 17816 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0729 20:36:39.747920 17816 solver.cpp:228] Iteration 3900, loss = 0.00942511
I0729 20:36:39.748103 17816 solver.cpp:244]     Train net output #0: loss = 0.00942508 (* 1 = 0.00942508 loss)
I0729 20:36:39.748126 17816 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0729 20:38:12.810443 17816 solver.cpp:228] Iteration 3950, loss = 0.00181208
I0729 20:38:12.810588 17816 solver.cpp:244]     Train net output #0: loss = 0.00181205 (* 1 = 0.00181205 loss)
I0729 20:38:12.810609 17816 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0729 20:39:44.061767 17816 solver.cpp:337] Iteration 4000, Testing net (#0)
I0729 20:44:01.231712 17816 solver.cpp:404]     Test net output #0: accuracy = 0.973123
I0729 20:44:01.231921 17816 solver.cpp:404]     Test net output #1: loss = 0.0830902 (* 1 = 0.0830902 loss)
I0729 20:44:02.584312 17816 solver.cpp:228] Iteration 4000, loss = 0.00343601
I0729 20:44:02.584373 17816 solver.cpp:244]     Train net output #0: loss = 0.00343598 (* 1 = 0.00343598 loss)
I0729 20:44:02.584393 17816 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0729 20:45:37.249784 17816 solver.cpp:228] Iteration 4050, loss = 0.00299799
I0729 20:45:37.249969 17816 solver.cpp:244]     Train net output #0: loss = 0.00299796 (* 1 = 0.00299796 loss)
I0729 20:45:37.249989 17816 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0729 20:47:12.716536 17816 solver.cpp:228] Iteration 4100, loss = 0.00103027
I0729 20:47:12.716701 17816 solver.cpp:244]     Train net output #0: loss = 0.00103024 (* 1 = 0.00103024 loss)
I0729 20:47:12.716727 17816 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0729 20:48:48.111153 17816 solver.cpp:228] Iteration 4150, loss = 0.00314741
I0729 20:48:48.111289 17816 solver.cpp:244]     Train net output #0: loss = 0.00314738 (* 1 = 0.00314738 loss)
I0729 20:48:48.111316 17816 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0729 20:50:23.600738 17816 solver.cpp:228] Iteration 4200, loss = 0.000253311
I0729 20:50:23.600872 17816 solver.cpp:244]     Train net output #0: loss = 0.000253284 (* 1 = 0.000253284 loss)
I0729 20:50:23.600893 17816 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0729 20:51:59.106515 17816 solver.cpp:228] Iteration 4250, loss = 0.008571
I0729 20:51:59.106650 17816 solver.cpp:244]     Train net output #0: loss = 0.00857097 (* 1 = 0.00857097 loss)
I0729 20:51:59.106669 17816 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0729 20:53:34.401020 17816 solver.cpp:228] Iteration 4300, loss = 0.00419954
I0729 20:53:34.401258 17816 solver.cpp:244]     Train net output #0: loss = 0.0041995 (* 1 = 0.0041995 loss)
I0729 20:53:34.401278 17816 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0729 20:55:09.883061 17816 solver.cpp:228] Iteration 4350, loss = 0.00287464
I0729 20:55:09.883234 17816 solver.cpp:244]     Train net output #0: loss = 0.0028746 (* 1 = 0.0028746 loss)
I0729 20:55:09.883255 17816 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0729 20:56:45.480455 17816 solver.cpp:228] Iteration 4400, loss = 0.000473508
I0729 20:56:45.480581 17816 solver.cpp:244]     Train net output #0: loss = 0.000473469 (* 1 = 0.000473469 loss)
I0729 20:56:45.480599 17816 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0729 20:58:19.477994 17816 solver.cpp:228] Iteration 4450, loss = 0.0029779
I0729 20:58:19.478147 17816 solver.cpp:244]     Train net output #0: loss = 0.00297786 (* 1 = 0.00297786 loss)
I0729 20:58:19.478168 17816 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0729 20:59:52.488533 17816 solver.cpp:228] Iteration 4500, loss = 0.0102585
I0729 20:59:52.488754 17816 solver.cpp:244]     Train net output #0: loss = 0.0102585 (* 1 = 0.0102585 loss)
I0729 20:59:52.488775 17816 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0729 21:01:25.754235 17816 solver.cpp:228] Iteration 4550, loss = 0.0109346
I0729 21:01:25.754412 17816 solver.cpp:244]     Train net output #0: loss = 0.0109346 (* 1 = 0.0109346 loss)
I0729 21:01:25.754436 17816 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0729 21:02:58.837319 17816 solver.cpp:228] Iteration 4600, loss = 0.0237385
I0729 21:02:58.837502 17816 solver.cpp:244]     Train net output #0: loss = 0.0237385 (* 1 = 0.0237385 loss)
I0729 21:02:58.837529 17816 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0729 21:04:31.995637 17816 solver.cpp:228] Iteration 4650, loss = 0.0985101
I0729 21:04:31.995820 17816 solver.cpp:244]     Train net output #0: loss = 0.09851 (* 1 = 0.09851 loss)
I0729 21:04:31.995841 17816 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0729 21:06:05.044756 17816 solver.cpp:228] Iteration 4700, loss = 0.00603231
I0729 21:06:05.044944 17816 solver.cpp:244]     Train net output #0: loss = 0.00603227 (* 1 = 0.00603227 loss)
I0729 21:06:05.044965 17816 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0729 21:07:38.252377 17816 solver.cpp:228] Iteration 4750, loss = 0.0334623
I0729 21:07:38.252585 17816 solver.cpp:244]     Train net output #0: loss = 0.0334623 (* 1 = 0.0334623 loss)
I0729 21:07:38.252607 17816 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0729 21:09:11.583356 17816 solver.cpp:228] Iteration 4800, loss = 0.0161448
I0729 21:09:11.583520 17816 solver.cpp:244]     Train net output #0: loss = 0.0161448 (* 1 = 0.0161448 loss)
I0729 21:09:11.583539 17816 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0729 21:10:44.778172 17816 solver.cpp:228] Iteration 4850, loss = 0.0196466
I0729 21:10:44.778354 17816 solver.cpp:244]     Train net output #0: loss = 0.0196466 (* 1 = 0.0196466 loss)
I0729 21:10:44.778386 17816 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0729 21:12:18.020042 17816 solver.cpp:228] Iteration 4900, loss = 0.00233335
I0729 21:12:18.020205 17816 solver.cpp:244]     Train net output #0: loss = 0.00233331 (* 1 = 0.00233331 loss)
I0729 21:12:18.020223 17816 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0729 21:13:52.154660 17816 solver.cpp:228] Iteration 4950, loss = 0.0065098
I0729 21:13:52.154805 17816 solver.cpp:244]     Train net output #0: loss = 0.00650976 (* 1 = 0.00650976 loss)
I0729 21:13:52.154826 17816 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0729 21:15:24.061861 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_5000.caffemodel
I0729 21:15:27.947031 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_5000.solverstate
I0729 21:15:32.532536 17816 solver.cpp:337] Iteration 5000, Testing net (#0)
I0729 21:19:47.564554 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972883
I0729 21:19:47.564710 17816 solver.cpp:404]     Test net output #1: loss = 0.0851368 (* 1 = 0.0851368 loss)
I0729 21:19:48.919750 17816 solver.cpp:228] Iteration 5000, loss = 0.000243539
I0729 21:19:48.919809 17816 solver.cpp:244]     Train net output #0: loss = 0.000243504 (* 1 = 0.000243504 loss)
I0729 21:19:48.919828 17816 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0729 21:21:22.553372 17816 solver.cpp:228] Iteration 5050, loss = 0.00864129
I0729 21:21:22.553536 17816 solver.cpp:244]     Train net output #0: loss = 0.00864126 (* 1 = 0.00864126 loss)
I0729 21:21:22.553555 17816 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0729 21:22:57.639538 17816 solver.cpp:228] Iteration 5100, loss = 0.00429204
I0729 21:22:57.639669 17816 solver.cpp:244]     Train net output #0: loss = 0.004292 (* 1 = 0.004292 loss)
I0729 21:22:57.639693 17816 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0729 21:24:36.889276 17816 solver.cpp:228] Iteration 5150, loss = 0.0022737
I0729 21:24:36.889457 17816 solver.cpp:244]     Train net output #0: loss = 0.00227367 (* 1 = 0.00227367 loss)
I0729 21:24:36.889482 17816 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0729 21:26:18.274889 17816 solver.cpp:228] Iteration 5200, loss = 0.00729468
I0729 21:26:18.275063 17816 solver.cpp:244]     Train net output #0: loss = 0.00729466 (* 1 = 0.00729466 loss)
I0729 21:26:18.275089 17816 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0729 21:27:59.353464 17816 solver.cpp:228] Iteration 5250, loss = 0.0006819
I0729 21:27:59.353597 17816 solver.cpp:244]     Train net output #0: loss = 0.000681876 (* 1 = 0.000681876 loss)
I0729 21:27:59.353618 17816 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0729 21:29:41.183101 17816 solver.cpp:228] Iteration 5300, loss = 0.00199899
I0729 21:29:41.183259 17816 solver.cpp:244]     Train net output #0: loss = 0.00199896 (* 1 = 0.00199896 loss)
I0729 21:29:41.183300 17816 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0729 21:31:23.354851 17816 solver.cpp:228] Iteration 5350, loss = 0.00557708
I0729 21:31:23.354996 17816 solver.cpp:244]     Train net output #0: loss = 0.00557705 (* 1 = 0.00557705 loss)
I0729 21:31:23.355016 17816 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0729 21:33:06.666838 17816 solver.cpp:228] Iteration 5400, loss = 0.0148028
I0729 21:33:06.688451 17816 solver.cpp:244]     Train net output #0: loss = 0.0148028 (* 1 = 0.0148028 loss)
I0729 21:33:06.688580 17816 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0729 21:34:49.850311 17816 solver.cpp:228] Iteration 5450, loss = 0.00775408
I0729 21:34:49.880079 17816 solver.cpp:244]     Train net output #0: loss = 0.00775406 (* 1 = 0.00775406 loss)
I0729 21:34:49.880120 17816 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0729 21:36:33.355952 17816 solver.cpp:228] Iteration 5500, loss = 0.00215855
I0729 21:36:33.382359 17816 solver.cpp:244]     Train net output #0: loss = 0.00215853 (* 1 = 0.00215853 loss)
I0729 21:36:33.382392 17816 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0729 21:38:16.677003 17816 solver.cpp:228] Iteration 5550, loss = 0.00127249
I0729 21:38:16.707216 17816 solver.cpp:244]     Train net output #0: loss = 0.00127247 (* 1 = 0.00127247 loss)
I0729 21:38:16.707252 17816 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0729 21:40:00.138267 17816 solver.cpp:228] Iteration 5600, loss = 0.00171819
I0729 21:40:00.154094 17816 solver.cpp:244]     Train net output #0: loss = 0.00171816 (* 1 = 0.00171816 loss)
I0729 21:40:00.154136 17816 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0729 21:41:43.458461 17816 solver.cpp:228] Iteration 5650, loss = 0.000949779
I0729 21:41:43.478963 17816 solver.cpp:244]     Train net output #0: loss = 0.000949753 (* 1 = 0.000949753 loss)
I0729 21:41:43.479004 17816 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0729 21:43:26.501112 17816 solver.cpp:228] Iteration 5700, loss = 0.000425348
I0729 21:43:26.515672 17816 solver.cpp:244]     Train net output #0: loss = 0.000425321 (* 1 = 0.000425321 loss)
I0729 21:43:26.515691 17816 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0729 21:45:09.213356 17816 solver.cpp:228] Iteration 5750, loss = 0.0020284
I0729 21:45:09.230175 17816 solver.cpp:244]     Train net output #0: loss = 0.00202837 (* 1 = 0.00202837 loss)
I0729 21:45:09.230306 17816 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0729 21:46:52.402936 17816 solver.cpp:228] Iteration 5800, loss = 0.000540251
I0729 21:46:52.403117 17816 solver.cpp:244]     Train net output #0: loss = 0.000540221 (* 1 = 0.000540221 loss)
I0729 21:46:52.403143 17816 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0729 21:48:35.484726 17816 solver.cpp:228] Iteration 5850, loss = 0.00146983
I0729 21:48:35.513733 17816 solver.cpp:244]     Train net output #0: loss = 0.0014698 (* 1 = 0.0014698 loss)
I0729 21:48:35.513772 17816 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0729 21:50:18.490128 17816 solver.cpp:228] Iteration 5900, loss = 0.000908293
I0729 21:50:18.505750 17816 solver.cpp:244]     Train net output #0: loss = 0.000908262 (* 1 = 0.000908262 loss)
I0729 21:50:18.505798 17816 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0729 21:52:01.636073 17816 solver.cpp:228] Iteration 5950, loss = 0.00078986
I0729 21:52:01.653172 17816 solver.cpp:244]     Train net output #0: loss = 0.00078983 (* 1 = 0.00078983 loss)
I0729 21:52:01.653226 17816 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0729 21:53:42.749652 17816 solver.cpp:337] Iteration 6000, Testing net (#0)
I0729 21:58:27.599458 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972882
I0729 21:58:27.629165 17816 solver.cpp:404]     Test net output #1: loss = 0.0854478 (* 1 = 0.0854478 loss)
I0729 21:58:29.113564 17816 solver.cpp:228] Iteration 6000, loss = 0.00389872
I0729 21:58:29.113649 17816 solver.cpp:244]     Train net output #0: loss = 0.00389869 (* 1 = 0.00389869 loss)
I0729 21:58:29.113680 17816 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0729 22:00:12.406334 17816 solver.cpp:228] Iteration 6050, loss = 0.00209356
I0729 22:00:12.429358 17816 solver.cpp:244]     Train net output #0: loss = 0.00209352 (* 1 = 0.00209352 loss)
I0729 22:00:12.429405 17816 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0729 22:01:55.535820 17816 solver.cpp:228] Iteration 6100, loss = 0.0120107
I0729 22:01:55.565687 17816 solver.cpp:244]     Train net output #0: loss = 0.0120107 (* 1 = 0.0120107 loss)
I0729 22:01:55.565737 17816 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0729 22:03:38.690179 17816 solver.cpp:228] Iteration 6150, loss = 0.0134393
I0729 22:03:38.701985 17816 solver.cpp:244]     Train net output #0: loss = 0.0134393 (* 1 = 0.0134393 loss)
I0729 22:03:38.702014 17816 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0729 22:05:21.728409 17816 solver.cpp:228] Iteration 6200, loss = 0.0106318
I0729 22:05:21.749568 17816 solver.cpp:244]     Train net output #0: loss = 0.0106318 (* 1 = 0.0106318 loss)
I0729 22:05:21.749627 17816 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0729 22:07:04.439371 17816 solver.cpp:228] Iteration 6250, loss = 0.00762293
I0729 22:07:04.464287 17816 solver.cpp:244]     Train net output #0: loss = 0.0076229 (* 1 = 0.0076229 loss)
I0729 22:07:04.464339 17816 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0729 22:08:45.665633 17816 solver.cpp:228] Iteration 6300, loss = 0.00390193
I0729 22:08:45.681288 17816 solver.cpp:244]     Train net output #0: loss = 0.0039019 (* 1 = 0.0039019 loss)
I0729 22:08:45.681345 17816 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0729 22:10:28.604933 17816 solver.cpp:228] Iteration 6350, loss = 0.00160731
I0729 22:10:28.629009 17816 solver.cpp:244]     Train net output #0: loss = 0.00160728 (* 1 = 0.00160728 loss)
I0729 22:10:28.629077 17816 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0729 22:12:11.937361 17816 solver.cpp:228] Iteration 6400, loss = 0.0031389
I0729 22:12:12.109239 17816 solver.cpp:244]     Train net output #0: loss = 0.00313887 (* 1 = 0.00313887 loss)
I0729 22:12:12.109295 17816 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0729 22:13:55.369076 17816 solver.cpp:228] Iteration 6450, loss = 0.0118185
I0729 22:13:55.400825 17816 solver.cpp:244]     Train net output #0: loss = 0.0118185 (* 1 = 0.0118185 loss)
I0729 22:13:55.400862 17816 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0729 22:15:39.227872 17816 solver.cpp:228] Iteration 6500, loss = 0.00567064
I0729 22:15:39.240097 17816 solver.cpp:244]     Train net output #0: loss = 0.00567061 (* 1 = 0.00567061 loss)
I0729 22:15:39.240149 17816 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0729 22:17:22.407058 17816 solver.cpp:228] Iteration 6550, loss = 0.00290909
I0729 22:17:22.428714 17816 solver.cpp:244]     Train net output #0: loss = 0.00290906 (* 1 = 0.00290906 loss)
I0729 22:17:22.428771 17816 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0729 22:19:05.599520 17816 solver.cpp:228] Iteration 6600, loss = 0.00726918
I0729 22:19:05.631641 17816 solver.cpp:244]     Train net output #0: loss = 0.00726914 (* 1 = 0.00726914 loss)
I0729 22:19:05.631714 17816 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0729 22:20:48.926184 17816 solver.cpp:228] Iteration 6650, loss = 0.000902893
I0729 22:20:48.945384 17816 solver.cpp:244]     Train net output #0: loss = 0.000902857 (* 1 = 0.000902857 loss)
I0729 22:20:48.945451 17816 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0729 22:22:31.971809 17816 solver.cpp:228] Iteration 6700, loss = 0.00141817
I0729 22:22:32.004122 17816 solver.cpp:244]     Train net output #0: loss = 0.00141814 (* 1 = 0.00141814 loss)
I0729 22:22:32.004180 17816 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0729 22:24:15.747822 17816 solver.cpp:228] Iteration 6750, loss = 0.000590127
I0729 22:24:15.772595 17816 solver.cpp:244]     Train net output #0: loss = 0.000590087 (* 1 = 0.000590087 loss)
I0729 22:24:15.772647 17816 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0729 22:26:01.422412 17816 solver.cpp:228] Iteration 6800, loss = 0.00199911
I0729 22:26:01.453965 17816 solver.cpp:244]     Train net output #0: loss = 0.00199907 (* 1 = 0.00199907 loss)
I0729 22:26:01.454005 17816 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0729 22:27:47.507004 17816 solver.cpp:228] Iteration 6850, loss = 0.00745746
I0729 22:27:47.530030 17816 solver.cpp:244]     Train net output #0: loss = 0.00745742 (* 1 = 0.00745742 loss)
I0729 22:27:47.530073 17816 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0729 22:29:27.177669 17816 solver.cpp:228] Iteration 6900, loss = 0.00332322
I0729 22:29:27.194054 17816 solver.cpp:244]     Train net output #0: loss = 0.00332319 (* 1 = 0.00332319 loss)
I0729 22:29:27.194100 17816 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0729 22:31:05.526125 17816 solver.cpp:228] Iteration 6950, loss = 0.00713769
I0729 22:31:05.537892 17816 solver.cpp:244]     Train net output #0: loss = 0.00713767 (* 1 = 0.00713767 loss)
I0729 22:31:05.537937 17816 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0729 22:32:39.805527 17816 solver.cpp:337] Iteration 7000, Testing net (#0)
I0729 22:37:03.561238 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972882
I0729 22:37:03.561394 17816 solver.cpp:404]     Test net output #1: loss = 0.0856031 (* 1 = 0.0856031 loss)
I0729 22:37:04.938482 17816 solver.cpp:228] Iteration 7000, loss = 0.0073028
I0729 22:37:04.938529 17816 solver.cpp:244]     Train net output #0: loss = 0.00730278 (* 1 = 0.00730278 loss)
I0729 22:37:04.938544 17816 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0729 22:38:40.574125 17816 solver.cpp:228] Iteration 7050, loss = 0.0206841
I0729 22:38:40.574277 17816 solver.cpp:244]     Train net output #0: loss = 0.020684 (* 1 = 0.020684 loss)
I0729 22:38:40.574295 17816 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0729 22:40:16.254036 17816 solver.cpp:228] Iteration 7100, loss = 0.00397497
I0729 22:40:16.254166 17816 solver.cpp:244]     Train net output #0: loss = 0.00397495 (* 1 = 0.00397495 loss)
I0729 22:40:16.254184 17816 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0729 22:41:51.843574 17816 solver.cpp:228] Iteration 7150, loss = 0.00572524
I0729 22:41:51.843749 17816 solver.cpp:244]     Train net output #0: loss = 0.00572522 (* 1 = 0.00572522 loss)
I0729 22:41:51.843773 17816 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0729 22:43:28.317422 17816 solver.cpp:228] Iteration 7200, loss = 0.00938794
I0729 22:43:28.317558 17816 solver.cpp:244]     Train net output #0: loss = 0.00938792 (* 1 = 0.00938792 loss)
I0729 22:43:28.317575 17816 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0729 22:45:05.904397 17816 solver.cpp:228] Iteration 7250, loss = 0.00148619
I0729 22:45:05.904566 17816 solver.cpp:244]     Train net output #0: loss = 0.00148617 (* 1 = 0.00148617 loss)
I0729 22:45:05.904587 17816 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0729 22:46:42.218920 17816 solver.cpp:228] Iteration 7300, loss = 0.00107561
I0729 22:46:42.219080 17816 solver.cpp:244]     Train net output #0: loss = 0.00107559 (* 1 = 0.00107559 loss)
I0729 22:46:42.219099 17816 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0729 22:48:19.525444 17816 solver.cpp:228] Iteration 7350, loss = 0.00277831
I0729 22:48:19.525606 17816 solver.cpp:244]     Train net output #0: loss = 0.00277829 (* 1 = 0.00277829 loss)
I0729 22:48:19.525625 17816 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0729 22:49:56.924767 17816 solver.cpp:228] Iteration 7400, loss = 0.000249526
I0729 22:49:56.924933 17816 solver.cpp:244]     Train net output #0: loss = 0.000249502 (* 1 = 0.000249502 loss)
I0729 22:49:56.924954 17816 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0729 22:51:33.532323 17816 solver.cpp:228] Iteration 7450, loss = 0.000978013
I0729 22:51:33.532541 17816 solver.cpp:244]     Train net output #0: loss = 0.000977991 (* 1 = 0.000977991 loss)
I0729 22:51:33.532562 17816 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0729 22:53:09.328058 17816 solver.cpp:228] Iteration 7500, loss = 0.0036711
I0729 22:53:09.328218 17816 solver.cpp:244]     Train net output #0: loss = 0.00367108 (* 1 = 0.00367108 loss)
I0729 22:53:09.328243 17816 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0729 22:54:45.292410 17816 solver.cpp:228] Iteration 7550, loss = 0.0109288
I0729 22:54:45.292544 17816 solver.cpp:244]     Train net output #0: loss = 0.0109287 (* 1 = 0.0109287 loss)
I0729 22:54:45.292563 17816 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0729 22:56:21.143090 17816 solver.cpp:228] Iteration 7600, loss = 0.000338337
I0729 22:56:21.143242 17816 solver.cpp:244]     Train net output #0: loss = 0.000338315 (* 1 = 0.000338315 loss)
I0729 22:56:21.143260 17816 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0729 22:57:57.406827 17816 solver.cpp:228] Iteration 7650, loss = 0.00253964
I0729 22:57:57.407004 17816 solver.cpp:244]     Train net output #0: loss = 0.00253962 (* 1 = 0.00253962 loss)
I0729 22:57:57.407045 17816 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0729 22:59:34.595793 17816 solver.cpp:228] Iteration 7700, loss = 0.0015417
I0729 22:59:34.595959 17816 solver.cpp:244]     Train net output #0: loss = 0.00154168 (* 1 = 0.00154168 loss)
I0729 22:59:34.595983 17816 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0729 23:01:10.382055 17816 solver.cpp:228] Iteration 7750, loss = 0.00873784
I0729 23:01:10.382184 17816 solver.cpp:244]     Train net output #0: loss = 0.00873782 (* 1 = 0.00873782 loss)
I0729 23:01:10.382210 17816 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0729 23:02:46.732949 17816 solver.cpp:228] Iteration 7800, loss = 0.00209104
I0729 23:02:46.733091 17816 solver.cpp:244]     Train net output #0: loss = 0.00209102 (* 1 = 0.00209102 loss)
I0729 23:02:46.733113 17816 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0729 23:04:22.715245 17816 solver.cpp:228] Iteration 7850, loss = 0.00174946
I0729 23:04:22.715368 17816 solver.cpp:244]     Train net output #0: loss = 0.00174944 (* 1 = 0.00174944 loss)
I0729 23:04:22.715387 17816 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0729 23:06:00.324787 17816 solver.cpp:228] Iteration 7900, loss = 0.00221087
I0729 23:06:00.324980 17816 solver.cpp:244]     Train net output #0: loss = 0.00221085 (* 1 = 0.00221085 loss)
I0729 23:06:00.325001 17816 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0729 23:07:36.741317 17816 solver.cpp:228] Iteration 7950, loss = 0.00230729
I0729 23:07:36.741492 17816 solver.cpp:244]     Train net output #0: loss = 0.00230727 (* 1 = 0.00230727 loss)
I0729 23:07:36.741513 17816 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0729 23:09:11.825755 17816 solver.cpp:337] Iteration 8000, Testing net (#0)
I0729 23:13:39.478528 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0729 23:13:39.478646 17816 solver.cpp:404]     Test net output #1: loss = 0.0859032 (* 1 = 0.0859032 loss)
I0729 23:13:40.892386 17816 solver.cpp:228] Iteration 8000, loss = 0.00345681
I0729 23:13:40.892452 17816 solver.cpp:244]     Train net output #0: loss = 0.00345679 (* 1 = 0.00345679 loss)
I0729 23:13:40.892472 17816 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0729 23:15:16.844945 17816 solver.cpp:228] Iteration 8050, loss = 0.00113537
I0729 23:15:16.845095 17816 solver.cpp:244]     Train net output #0: loss = 0.00113535 (* 1 = 0.00113535 loss)
I0729 23:15:16.845115 17816 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0729 23:16:52.336627 17816 solver.cpp:228] Iteration 8100, loss = 0.00170089
I0729 23:16:52.336765 17816 solver.cpp:244]     Train net output #0: loss = 0.00170086 (* 1 = 0.00170086 loss)
I0729 23:16:52.336793 17816 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0729 23:18:27.801554 17816 solver.cpp:228] Iteration 8150, loss = 0.000753067
I0729 23:18:27.801743 17816 solver.cpp:244]     Train net output #0: loss = 0.000753033 (* 1 = 0.000753033 loss)
I0729 23:18:27.801765 17816 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0729 23:20:03.861626 17816 solver.cpp:228] Iteration 8200, loss = 0.0173372
I0729 23:20:03.861776 17816 solver.cpp:244]     Train net output #0: loss = 0.0173372 (* 1 = 0.0173372 loss)
I0729 23:20:03.861795 17816 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0729 23:21:41.918264 17816 solver.cpp:228] Iteration 8250, loss = 0.00336656
I0729 23:21:41.918438 17816 solver.cpp:244]     Train net output #0: loss = 0.00336653 (* 1 = 0.00336653 loss)
I0729 23:21:41.918464 17816 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0729 23:23:22.884284 17816 solver.cpp:228] Iteration 8300, loss = 0.00243289
I0729 23:23:22.884491 17816 solver.cpp:244]     Train net output #0: loss = 0.00243285 (* 1 = 0.00243285 loss)
I0729 23:23:22.884524 17816 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0729 23:25:04.247737 17816 solver.cpp:228] Iteration 8350, loss = 0.00364545
I0729 23:25:04.274107 17816 solver.cpp:244]     Train net output #0: loss = 0.00364541 (* 1 = 0.00364541 loss)
I0729 23:25:04.274148 17816 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0729 23:26:44.388628 17816 solver.cpp:228] Iteration 8400, loss = 0.00441731
I0729 23:26:44.415329 17816 solver.cpp:244]     Train net output #0: loss = 0.00441727 (* 1 = 0.00441727 loss)
I0729 23:26:44.415374 17816 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0729 23:28:25.564399 17816 solver.cpp:228] Iteration 8450, loss = 0.0339652
I0729 23:28:25.577339 17816 solver.cpp:244]     Train net output #0: loss = 0.0339652 (* 1 = 0.0339652 loss)
I0729 23:28:25.577378 17816 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0729 23:30:09.075845 17816 solver.cpp:228] Iteration 8500, loss = 0.000775692
I0729 23:30:09.101483 17816 solver.cpp:244]     Train net output #0: loss = 0.000775654 (* 1 = 0.000775654 loss)
I0729 23:30:09.101536 17816 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0729 23:31:51.716044 17816 solver.cpp:228] Iteration 8550, loss = 0.00048854
I0729 23:31:51.738672 17816 solver.cpp:244]     Train net output #0: loss = 0.000488499 (* 1 = 0.000488499 loss)
I0729 23:31:51.738721 17816 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0729 23:33:34.994715 17816 solver.cpp:228] Iteration 8600, loss = 0.00186097
I0729 23:33:35.019238 17816 solver.cpp:244]     Train net output #0: loss = 0.00186093 (* 1 = 0.00186093 loss)
I0729 23:33:35.019304 17816 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0729 23:35:17.954284 17816 solver.cpp:228] Iteration 8650, loss = 0.0200591
I0729 23:35:17.978036 17816 solver.cpp:244]     Train net output #0: loss = 0.020059 (* 1 = 0.020059 loss)
I0729 23:35:17.978097 17816 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0729 23:37:01.414659 17816 solver.cpp:228] Iteration 8700, loss = 0.00416162
I0729 23:37:01.447065 17816 solver.cpp:244]     Train net output #0: loss = 0.00416157 (* 1 = 0.00416157 loss)
I0729 23:37:01.447106 17816 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0729 23:38:44.764803 17816 solver.cpp:228] Iteration 8750, loss = 0.0240284
I0729 23:38:44.783136 17816 solver.cpp:244]     Train net output #0: loss = 0.0240283 (* 1 = 0.0240283 loss)
I0729 23:38:44.783169 17816 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0729 23:40:28.227324 17816 solver.cpp:228] Iteration 8800, loss = 0.010173
I0729 23:40:28.252130 17816 solver.cpp:244]     Train net output #0: loss = 0.0101729 (* 1 = 0.0101729 loss)
I0729 23:40:28.252171 17816 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0729 23:42:11.529594 17816 solver.cpp:228] Iteration 8850, loss = 0.000258767
I0729 23:42:11.543869 17816 solver.cpp:244]     Train net output #0: loss = 0.000258726 (* 1 = 0.000258726 loss)
I0729 23:42:11.543973 17816 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0729 23:43:55.003453 17816 solver.cpp:228] Iteration 8900, loss = 0.00691645
I0729 23:43:55.035122 17816 solver.cpp:244]     Train net output #0: loss = 0.00691641 (* 1 = 0.00691641 loss)
I0729 23:43:55.035192 17816 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0729 23:45:38.198730 17816 solver.cpp:228] Iteration 8950, loss = 0.000159691
I0729 23:45:38.226832 17816 solver.cpp:244]     Train net output #0: loss = 0.000159656 (* 1 = 0.000159656 loss)
I0729 23:45:38.226888 17816 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0729 23:47:19.635226 17816 solver.cpp:337] Iteration 9000, Testing net (#0)
I0729 23:52:05.698906 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0729 23:52:05.722527 17816 solver.cpp:404]     Test net output #1: loss = 0.0859185 (* 1 = 0.0859185 loss)
I0729 23:52:07.206297 17816 solver.cpp:228] Iteration 9000, loss = 0.00143797
I0729 23:52:07.206365 17816 solver.cpp:244]     Train net output #0: loss = 0.00143793 (* 1 = 0.00143793 loss)
I0729 23:52:07.206388 17816 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0729 23:53:48.858707 17816 solver.cpp:228] Iteration 9050, loss = 0.00925855
I0729 23:53:48.880918 17816 solver.cpp:244]     Train net output #0: loss = 0.00925851 (* 1 = 0.00925851 loss)
I0729 23:53:48.880962 17816 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0729 23:55:24.756217 17816 solver.cpp:228] Iteration 9100, loss = 0.00144146
I0729 23:55:24.773336 17816 solver.cpp:244]     Train net output #0: loss = 0.00144143 (* 1 = 0.00144143 loss)
I0729 23:55:24.773403 17816 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0729 23:56:57.903043 17816 solver.cpp:228] Iteration 9150, loss = 0.00165999
I0729 23:56:57.903168 17816 solver.cpp:244]     Train net output #0: loss = 0.00165996 (* 1 = 0.00165996 loss)
I0729 23:56:57.903197 17816 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0729 23:58:31.114722 17816 solver.cpp:228] Iteration 9200, loss = 0.00130027
I0729 23:58:31.114856 17816 solver.cpp:244]     Train net output #0: loss = 0.00130025 (* 1 = 0.00130025 loss)
I0729 23:58:31.114884 17816 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0730 00:00:04.312783 17816 solver.cpp:228] Iteration 9250, loss = 0.00226079
I0730 00:00:04.312950 17816 solver.cpp:244]     Train net output #0: loss = 0.00226076 (* 1 = 0.00226076 loss)
I0730 00:00:04.312978 17816 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0730 00:01:37.559499 17816 solver.cpp:228] Iteration 9300, loss = 0.0012655
I0730 00:01:37.559633 17816 solver.cpp:244]     Train net output #0: loss = 0.00126547 (* 1 = 0.00126547 loss)
I0730 00:01:37.559661 17816 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0730 00:03:10.602155 17816 solver.cpp:228] Iteration 9350, loss = 0.00381146
I0730 00:03:10.602331 17816 solver.cpp:244]     Train net output #0: loss = 0.00381143 (* 1 = 0.00381143 loss)
I0730 00:03:10.602352 17816 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0730 00:04:44.002799 17816 solver.cpp:228] Iteration 9400, loss = 0.00372951
I0730 00:04:44.002955 17816 solver.cpp:244]     Train net output #0: loss = 0.00372949 (* 1 = 0.00372949 loss)
I0730 00:04:44.002975 17816 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0730 00:06:17.187176 17816 solver.cpp:228] Iteration 9450, loss = 0.00197585
I0730 00:06:17.187345 17816 solver.cpp:244]     Train net output #0: loss = 0.00197582 (* 1 = 0.00197582 loss)
I0730 00:06:17.187366 17816 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0730 00:07:50.909045 17816 solver.cpp:228] Iteration 9500, loss = 0.00348098
I0730 00:07:50.909209 17816 solver.cpp:244]     Train net output #0: loss = 0.00348095 (* 1 = 0.00348095 loss)
I0730 00:07:50.909240 17816 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0730 00:09:31.166415 17816 solver.cpp:228] Iteration 9550, loss = 0.00120097
I0730 00:09:31.166597 17816 solver.cpp:244]     Train net output #0: loss = 0.00120095 (* 1 = 0.00120095 loss)
I0730 00:09:31.166622 17816 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0730 00:11:11.871110 17816 solver.cpp:228] Iteration 9600, loss = 0.000207565
I0730 00:11:11.871248 17816 solver.cpp:244]     Train net output #0: loss = 0.000207543 (* 1 = 0.000207543 loss)
I0730 00:11:11.871271 17816 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0730 00:12:54.836863 17816 solver.cpp:228] Iteration 9650, loss = 0.000587746
I0730 00:12:54.837116 17816 solver.cpp:244]     Train net output #0: loss = 0.000587723 (* 1 = 0.000587723 loss)
I0730 00:12:54.837146 17816 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0730 00:14:33.424463 17816 solver.cpp:228] Iteration 9700, loss = 0.00209654
I0730 00:14:33.424605 17816 solver.cpp:244]     Train net output #0: loss = 0.00209652 (* 1 = 0.00209652 loss)
I0730 00:14:33.424630 17816 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0730 00:16:14.516069 17816 solver.cpp:228] Iteration 9750, loss = 0.00289144
I0730 00:16:14.516221 17816 solver.cpp:244]     Train net output #0: loss = 0.00289141 (* 1 = 0.00289141 loss)
I0730 00:16:14.516244 17816 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0730 00:17:55.942286 17816 solver.cpp:228] Iteration 9800, loss = 0.00207556
I0730 00:17:55.942471 17816 solver.cpp:244]     Train net output #0: loss = 0.00207553 (* 1 = 0.00207553 loss)
I0730 00:17:55.942504 17816 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0730 00:19:37.168874 17816 solver.cpp:228] Iteration 9850, loss = 0.00140145
I0730 00:19:37.169080 17816 solver.cpp:244]     Train net output #0: loss = 0.00140142 (* 1 = 0.00140142 loss)
I0730 00:19:37.169106 17816 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0730 00:21:19.860939 17816 solver.cpp:228] Iteration 9900, loss = 0.0461169
I0730 00:21:19.861088 17816 solver.cpp:244]     Train net output #0: loss = 0.0461169 (* 1 = 0.0461169 loss)
I0730 00:21:19.861110 17816 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0730 00:23:03.100213 17816 solver.cpp:228] Iteration 9950, loss = 0.000518611
I0730 00:23:03.100361 17816 solver.cpp:244]     Train net output #0: loss = 0.00051858 (* 1 = 0.00051858 loss)
I0730 00:23:03.100384 17816 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0730 00:24:44.489384 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_10000.caffemodel
I0730 00:24:50.716867 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_10000.solverstate
I0730 00:24:53.553917 17816 solver.cpp:337] Iteration 10000, Testing net (#0)
I0730 00:29:35.453510 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972682
I0730 00:29:35.453742 17816 solver.cpp:404]     Test net output #1: loss = 0.0858757 (* 1 = 0.0858757 loss)
I0730 00:29:36.918408 17816 solver.cpp:228] Iteration 10000, loss = 0.0136695
I0730 00:29:36.918480 17816 solver.cpp:244]     Train net output #0: loss = 0.0136695 (* 1 = 0.0136695 loss)
I0730 00:29:36.918505 17816 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0730 00:31:19.798001 17816 solver.cpp:228] Iteration 10050, loss = 0.00502076
I0730 00:31:19.798151 17816 solver.cpp:244]     Train net output #0: loss = 0.00502072 (* 1 = 0.00502072 loss)
I0730 00:31:19.798177 17816 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0730 00:33:02.970765 17816 solver.cpp:228] Iteration 10100, loss = 0.0251336
I0730 00:33:02.970921 17816 solver.cpp:244]     Train net output #0: loss = 0.0251336 (* 1 = 0.0251336 loss)
I0730 00:33:02.970947 17816 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0730 00:34:46.752120 17816 solver.cpp:228] Iteration 10150, loss = 0.00221628
I0730 00:34:46.752282 17816 solver.cpp:244]     Train net output #0: loss = 0.00221624 (* 1 = 0.00221624 loss)
I0730 00:34:46.752311 17816 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0730 00:36:32.347713 17816 solver.cpp:228] Iteration 10200, loss = 0.00370283
I0730 00:36:32.347911 17816 solver.cpp:244]     Train net output #0: loss = 0.0037028 (* 1 = 0.0037028 loss)
I0730 00:36:32.347941 17816 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0730 00:38:16.892446 17816 solver.cpp:228] Iteration 10250, loss = 0.00143972
I0730 00:38:16.892635 17816 solver.cpp:244]     Train net output #0: loss = 0.00143968 (* 1 = 0.00143968 loss)
I0730 00:38:16.892662 17816 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0730 00:39:59.431758 17816 solver.cpp:228] Iteration 10300, loss = 0.00138143
I0730 00:39:59.431921 17816 solver.cpp:244]     Train net output #0: loss = 0.0013814 (* 1 = 0.0013814 loss)
I0730 00:39:59.431947 17816 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0730 00:41:42.054975 17816 solver.cpp:228] Iteration 10350, loss = 0.00151473
I0730 00:41:42.057129 17816 solver.cpp:244]     Train net output #0: loss = 0.00151469 (* 1 = 0.00151469 loss)
I0730 00:41:42.057168 17816 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0730 00:43:24.584071 17816 solver.cpp:228] Iteration 10400, loss = 0.0115888
I0730 00:43:24.584224 17816 solver.cpp:244]     Train net output #0: loss = 0.0115887 (* 1 = 0.0115887 loss)
I0730 00:43:24.584249 17816 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0730 00:45:07.337565 17816 solver.cpp:228] Iteration 10450, loss = 0.00133365
I0730 00:45:07.337767 17816 solver.cpp:244]     Train net output #0: loss = 0.00133361 (* 1 = 0.00133361 loss)
I0730 00:45:07.337798 17816 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0730 00:46:50.135664 17816 solver.cpp:228] Iteration 10500, loss = 0.0110466
I0730 00:46:50.135866 17816 solver.cpp:244]     Train net output #0: loss = 0.0110466 (* 1 = 0.0110466 loss)
I0730 00:46:50.135901 17816 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0730 00:48:32.737088 17816 solver.cpp:228] Iteration 10550, loss = 0.00166645
I0730 00:48:32.762848 17816 solver.cpp:244]     Train net output #0: loss = 0.00166642 (* 1 = 0.00166642 loss)
I0730 00:48:32.762897 17816 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0730 00:50:15.318249 17816 solver.cpp:228] Iteration 10600, loss = 0.0169518
I0730 00:50:15.318481 17816 solver.cpp:244]     Train net output #0: loss = 0.0169517 (* 1 = 0.0169517 loss)
I0730 00:50:15.318560 17816 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0730 00:51:57.865721 17816 solver.cpp:228] Iteration 10650, loss = 0.00189369
I0730 00:51:57.865880 17816 solver.cpp:244]     Train net output #0: loss = 0.00189365 (* 1 = 0.00189365 loss)
I0730 00:51:57.865905 17816 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0730 00:53:40.166990 17816 solver.cpp:228] Iteration 10700, loss = 0.00421443
I0730 00:53:40.167129 17816 solver.cpp:244]     Train net output #0: loss = 0.00421439 (* 1 = 0.00421439 loss)
I0730 00:53:40.167150 17816 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0730 00:55:21.950969 17816 solver.cpp:228] Iteration 10750, loss = 0.00584253
I0730 00:55:21.951115 17816 solver.cpp:244]     Train net output #0: loss = 0.00584249 (* 1 = 0.00584249 loss)
I0730 00:55:21.951148 17816 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0730 00:57:05.254540 17816 solver.cpp:228] Iteration 10800, loss = 0.00022972
I0730 00:57:05.255362 17816 solver.cpp:244]     Train net output #0: loss = 0.000229679 (* 1 = 0.000229679 loss)
I0730 00:57:05.255403 17816 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0730 00:58:48.534466 17816 solver.cpp:228] Iteration 10850, loss = 0.000489227
I0730 00:58:48.534642 17816 solver.cpp:244]     Train net output #0: loss = 0.000489185 (* 1 = 0.000489185 loss)
I0730 00:58:48.534687 17816 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0730 01:00:32.067261 17816 solver.cpp:228] Iteration 10900, loss = 0.00720131
I0730 01:00:32.067410 17816 solver.cpp:244]     Train net output #0: loss = 0.00720127 (* 1 = 0.00720127 loss)
I0730 01:00:32.067450 17816 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0730 01:02:15.208442 17816 solver.cpp:228] Iteration 10950, loss = 0.00159035
I0730 01:02:15.208592 17816 solver.cpp:244]     Train net output #0: loss = 0.00159031 (* 1 = 0.00159031 loss)
I0730 01:02:15.208616 17816 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0730 01:03:56.487769 17816 solver.cpp:337] Iteration 11000, Testing net (#0)
I0730 01:08:43.880203 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 01:08:43.880352 17816 solver.cpp:404]     Test net output #1: loss = 0.0859069 (* 1 = 0.0859069 loss)
I0730 01:08:45.365062 17816 solver.cpp:228] Iteration 11000, loss = 0.00879929
I0730 01:08:45.365125 17816 solver.cpp:244]     Train net output #0: loss = 0.00879925 (* 1 = 0.00879925 loss)
I0730 01:08:45.365145 17816 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0730 01:10:28.757742 17816 solver.cpp:228] Iteration 11050, loss = 0.00052517
I0730 01:10:28.757894 17816 solver.cpp:244]     Train net output #0: loss = 0.000525133 (* 1 = 0.000525133 loss)
I0730 01:10:28.757918 17816 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0730 01:12:11.876034 17816 solver.cpp:228] Iteration 11100, loss = 0.00591458
I0730 01:12:11.881152 17816 solver.cpp:244]     Train net output #0: loss = 0.00591455 (* 1 = 0.00591455 loss)
I0730 01:12:11.881217 17816 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0730 01:13:53.657594 17816 solver.cpp:228] Iteration 11150, loss = 0.000371082
I0730 01:13:53.657791 17816 solver.cpp:244]     Train net output #0: loss = 0.000371041 (* 1 = 0.000371041 loss)
I0730 01:13:53.657877 17816 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0730 01:15:36.716226 17816 solver.cpp:228] Iteration 11200, loss = 0.00264546
I0730 01:15:36.716410 17816 solver.cpp:244]     Train net output #0: loss = 0.00264543 (* 1 = 0.00264543 loss)
I0730 01:15:36.716439 17816 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0730 01:17:19.368486 17816 solver.cpp:228] Iteration 11250, loss = 0.00165668
I0730 01:17:19.368654 17816 solver.cpp:244]     Train net output #0: loss = 0.00165664 (* 1 = 0.00165664 loss)
I0730 01:17:19.368680 17816 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0730 01:19:03.033133 17816 solver.cpp:228] Iteration 11300, loss = 0.00132836
I0730 01:19:03.033315 17816 solver.cpp:244]     Train net output #0: loss = 0.00132833 (* 1 = 0.00132833 loss)
I0730 01:19:03.033344 17816 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0730 01:20:45.680121 17816 solver.cpp:228] Iteration 11350, loss = 0.00690369
I0730 01:20:45.680332 17816 solver.cpp:244]     Train net output #0: loss = 0.00690366 (* 1 = 0.00690366 loss)
I0730 01:20:45.680367 17816 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0730 01:22:28.442011 17816 solver.cpp:228] Iteration 11400, loss = 0.00955413
I0730 01:22:28.442201 17816 solver.cpp:244]     Train net output #0: loss = 0.0095541 (* 1 = 0.0095541 loss)
I0730 01:22:28.442232 17816 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0730 01:24:11.995431 17816 solver.cpp:228] Iteration 11450, loss = 0.0179002
I0730 01:24:11.995566 17816 solver.cpp:244]     Train net output #0: loss = 0.0179002 (* 1 = 0.0179002 loss)
I0730 01:24:11.995587 17816 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0730 01:25:55.225101 17816 solver.cpp:228] Iteration 11500, loss = 0.000808828
I0730 01:25:55.225245 17816 solver.cpp:244]     Train net output #0: loss = 0.000808794 (* 1 = 0.000808794 loss)
I0730 01:25:55.225268 17816 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0730 01:27:38.536056 17816 solver.cpp:228] Iteration 11550, loss = 0.000115319
I0730 01:27:38.536236 17816 solver.cpp:244]     Train net output #0: loss = 0.000115282 (* 1 = 0.000115282 loss)
I0730 01:27:38.536262 17816 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0730 01:29:21.869067 17816 solver.cpp:228] Iteration 11600, loss = 0.00310101
I0730 01:29:21.869213 17816 solver.cpp:244]     Train net output #0: loss = 0.00310097 (* 1 = 0.00310097 loss)
I0730 01:29:21.869236 17816 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0730 01:31:02.089452 17816 solver.cpp:228] Iteration 11650, loss = 0.00855339
I0730 01:31:02.089612 17816 solver.cpp:244]     Train net output #0: loss = 0.00855335 (* 1 = 0.00855335 loss)
I0730 01:31:02.089630 17816 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0730 01:32:38.982877 17816 solver.cpp:228] Iteration 11700, loss = 0.0182119
I0730 01:32:38.983003 17816 solver.cpp:244]     Train net output #0: loss = 0.0182119 (* 1 = 0.0182119 loss)
I0730 01:32:38.983021 17816 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0730 01:34:14.816727 17816 solver.cpp:228] Iteration 11750, loss = 0.000516954
I0730 01:34:14.816881 17816 solver.cpp:244]     Train net output #0: loss = 0.000516916 (* 1 = 0.000516916 loss)
I0730 01:34:14.816900 17816 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0730 01:35:50.217389 17816 solver.cpp:228] Iteration 11800, loss = 0.00101945
I0730 01:35:50.217514 17816 solver.cpp:244]     Train net output #0: loss = 0.00101941 (* 1 = 0.00101941 loss)
I0730 01:35:50.217532 17816 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0730 01:37:25.761436 17816 solver.cpp:228] Iteration 11850, loss = 0.000407051
I0730 01:37:25.761611 17816 solver.cpp:244]     Train net output #0: loss = 0.000407011 (* 1 = 0.000407011 loss)
I0730 01:37:25.761632 17816 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0730 01:39:00.354897 17816 solver.cpp:228] Iteration 11900, loss = 0.00123732
I0730 01:39:00.355029 17816 solver.cpp:244]     Train net output #0: loss = 0.00123728 (* 1 = 0.00123728 loss)
I0730 01:39:00.355047 17816 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0730 01:40:33.481048 17816 solver.cpp:228] Iteration 11950, loss = 0.00932803
I0730 01:40:33.481204 17816 solver.cpp:244]     Train net output #0: loss = 0.00932799 (* 1 = 0.00932799 loss)
I0730 01:40:33.481223 17816 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0730 01:42:04.717727 17816 solver.cpp:337] Iteration 12000, Testing net (#0)
I0730 01:46:22.148877 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 01:46:22.149021 17816 solver.cpp:404]     Test net output #1: loss = 0.0859063 (* 1 = 0.0859063 loss)
I0730 01:46:23.492384 17816 solver.cpp:228] Iteration 12000, loss = 0.00507095
I0730 01:46:23.492434 17816 solver.cpp:244]     Train net output #0: loss = 0.00507091 (* 1 = 0.00507091 loss)
I0730 01:46:23.492450 17816 sgd_solver.cpp:106] Iteration 12000, lr = 1e-07
I0730 01:47:56.679180 17816 solver.cpp:228] Iteration 12050, loss = 0.00210851
I0730 01:47:56.679309 17816 solver.cpp:244]     Train net output #0: loss = 0.00210848 (* 1 = 0.00210848 loss)
I0730 01:47:56.679327 17816 sgd_solver.cpp:106] Iteration 12050, lr = 1e-07
I0730 01:49:30.049928 17816 solver.cpp:228] Iteration 12100, loss = 0.00258853
I0730 01:49:30.050052 17816 solver.cpp:244]     Train net output #0: loss = 0.00258849 (* 1 = 0.00258849 loss)
I0730 01:49:30.050071 17816 sgd_solver.cpp:106] Iteration 12100, lr = 1e-07
I0730 01:51:03.337482 17816 solver.cpp:228] Iteration 12150, loss = 0.00758806
I0730 01:51:03.337612 17816 solver.cpp:244]     Train net output #0: loss = 0.00758802 (* 1 = 0.00758802 loss)
I0730 01:51:03.337631 17816 sgd_solver.cpp:106] Iteration 12150, lr = 1e-07
I0730 01:52:36.469804 17816 solver.cpp:228] Iteration 12200, loss = 0.000570066
I0730 01:52:36.469934 17816 solver.cpp:244]     Train net output #0: loss = 0.000570029 (* 1 = 0.000570029 loss)
I0730 01:52:36.469954 17816 sgd_solver.cpp:106] Iteration 12200, lr = 1e-07
I0730 01:54:09.920148 17816 solver.cpp:228] Iteration 12250, loss = 0.000387224
I0730 01:54:09.920305 17816 solver.cpp:244]     Train net output #0: loss = 0.000387182 (* 1 = 0.000387182 loss)
I0730 01:54:09.920323 17816 sgd_solver.cpp:106] Iteration 12250, lr = 1e-07
I0730 01:55:43.135495 17816 solver.cpp:228] Iteration 12300, loss = 0.000438415
I0730 01:55:43.135649 17816 solver.cpp:244]     Train net output #0: loss = 0.000438373 (* 1 = 0.000438373 loss)
I0730 01:55:43.135668 17816 sgd_solver.cpp:106] Iteration 12300, lr = 1e-07
I0730 01:57:16.490244 17816 solver.cpp:228] Iteration 12350, loss = 0.000603147
I0730 01:57:16.490366 17816 solver.cpp:244]     Train net output #0: loss = 0.000603106 (* 1 = 0.000603106 loss)
I0730 01:57:16.490386 17816 sgd_solver.cpp:106] Iteration 12350, lr = 1e-07
I0730 01:58:49.815688 17816 solver.cpp:228] Iteration 12400, loss = 0.00089061
I0730 01:58:49.815816 17816 solver.cpp:244]     Train net output #0: loss = 0.00089057 (* 1 = 0.00089057 loss)
I0730 01:58:49.815834 17816 sgd_solver.cpp:106] Iteration 12400, lr = 1e-07
I0730 02:00:23.075028 17816 solver.cpp:228] Iteration 12450, loss = 0.000230797
I0730 02:00:23.075152 17816 solver.cpp:244]     Train net output #0: loss = 0.00023076 (* 1 = 0.00023076 loss)
I0730 02:00:23.075171 17816 sgd_solver.cpp:106] Iteration 12450, lr = 1e-07
I0730 02:01:56.288713 17816 solver.cpp:228] Iteration 12500, loss = 0.000212991
I0730 02:01:56.288859 17816 solver.cpp:244]     Train net output #0: loss = 0.000212951 (* 1 = 0.000212951 loss)
I0730 02:01:56.288877 17816 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0730 02:03:29.459949 17816 solver.cpp:228] Iteration 12550, loss = 0.00742718
I0730 02:03:29.460196 17816 solver.cpp:244]     Train net output #0: loss = 0.00742715 (* 1 = 0.00742715 loss)
I0730 02:03:29.460216 17816 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0730 02:05:02.521255 17816 solver.cpp:228] Iteration 12600, loss = 0.00359473
I0730 02:05:02.521420 17816 solver.cpp:244]     Train net output #0: loss = 0.0035947 (* 1 = 0.0035947 loss)
I0730 02:05:02.521440 17816 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0730 02:06:35.545279 17816 solver.cpp:228] Iteration 12650, loss = 0.00430888
I0730 02:06:35.545435 17816 solver.cpp:244]     Train net output #0: loss = 0.00430885 (* 1 = 0.00430885 loss)
I0730 02:06:35.545454 17816 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0730 02:08:08.628062 17816 solver.cpp:228] Iteration 12700, loss = 0.00273577
I0730 02:08:08.628231 17816 solver.cpp:244]     Train net output #0: loss = 0.00273575 (* 1 = 0.00273575 loss)
I0730 02:08:08.628257 17816 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0730 02:09:41.486927 17816 solver.cpp:228] Iteration 12750, loss = 0.00384759
I0730 02:09:41.487056 17816 solver.cpp:244]     Train net output #0: loss = 0.00384756 (* 1 = 0.00384756 loss)
I0730 02:09:41.487076 17816 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0730 02:11:14.519829 17816 solver.cpp:228] Iteration 12800, loss = 0.00203821
I0730 02:11:14.519953 17816 solver.cpp:244]     Train net output #0: loss = 0.00203818 (* 1 = 0.00203818 loss)
I0730 02:11:14.519971 17816 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0730 02:12:47.634845 17816 solver.cpp:228] Iteration 12850, loss = 0.000851822
I0730 02:12:47.634968 17816 solver.cpp:244]     Train net output #0: loss = 0.000851793 (* 1 = 0.000851793 loss)
I0730 02:12:47.634987 17816 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0730 02:14:20.757545 17816 solver.cpp:228] Iteration 12900, loss = 0.00209605
I0730 02:14:20.757704 17816 solver.cpp:244]     Train net output #0: loss = 0.00209603 (* 1 = 0.00209603 loss)
I0730 02:14:20.757722 17816 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0730 02:15:53.865703 17816 solver.cpp:228] Iteration 12950, loss = 0.00237833
I0730 02:15:53.865885 17816 solver.cpp:244]     Train net output #0: loss = 0.00237831 (* 1 = 0.00237831 loss)
I0730 02:15:53.865903 17816 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0730 02:17:25.069782 17816 solver.cpp:337] Iteration 13000, Testing net (#0)
I0730 02:21:42.704368 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 02:21:42.704529 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 02:21:44.045578 17816 solver.cpp:228] Iteration 13000, loss = 0.000857081
I0730 02:21:44.045629 17816 solver.cpp:244]     Train net output #0: loss = 0.000857065 (* 1 = 0.000857065 loss)
I0730 02:21:44.045646 17816 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0730 02:23:17.175317 17816 solver.cpp:228] Iteration 13050, loss = 0.0083483
I0730 02:23:17.175467 17816 solver.cpp:244]     Train net output #0: loss = 0.00834828 (* 1 = 0.00834828 loss)
I0730 02:23:17.175485 17816 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0730 02:24:50.694365 17816 solver.cpp:228] Iteration 13100, loss = 0.0308804
I0730 02:24:50.694545 17816 solver.cpp:244]     Train net output #0: loss = 0.0308804 (* 1 = 0.0308804 loss)
I0730 02:24:50.694563 17816 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0730 02:26:23.936908 17816 solver.cpp:228] Iteration 13150, loss = 0.00640966
I0730 02:26:23.937026 17816 solver.cpp:244]     Train net output #0: loss = 0.00640965 (* 1 = 0.00640965 loss)
I0730 02:26:23.937055 17816 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0730 02:27:57.033221 17816 solver.cpp:228] Iteration 13200, loss = 0.00530156
I0730 02:27:57.033355 17816 solver.cpp:244]     Train net output #0: loss = 0.00530154 (* 1 = 0.00530154 loss)
I0730 02:27:57.033375 17816 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0730 02:29:30.085197 17816 solver.cpp:228] Iteration 13250, loss = 0.00246243
I0730 02:29:30.085326 17816 solver.cpp:244]     Train net output #0: loss = 0.00246241 (* 1 = 0.00246241 loss)
I0730 02:29:30.085345 17816 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0730 02:31:03.216650 17816 solver.cpp:228] Iteration 13300, loss = 0.00479733
I0730 02:31:03.216768 17816 solver.cpp:244]     Train net output #0: loss = 0.00479731 (* 1 = 0.00479731 loss)
I0730 02:31:03.216787 17816 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0730 02:32:36.254216 17816 solver.cpp:228] Iteration 13350, loss = 0.00431579
I0730 02:32:36.254343 17816 solver.cpp:244]     Train net output #0: loss = 0.00431577 (* 1 = 0.00431577 loss)
I0730 02:32:36.254364 17816 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0730 02:34:09.506860 17816 solver.cpp:228] Iteration 13400, loss = 0.00231455
I0730 02:34:09.507022 17816 solver.cpp:244]     Train net output #0: loss = 0.00231454 (* 1 = 0.00231454 loss)
I0730 02:34:09.507041 17816 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0730 02:35:42.807561 17816 solver.cpp:228] Iteration 13450, loss = 0.000544671
I0730 02:35:42.807692 17816 solver.cpp:244]     Train net output #0: loss = 0.000544657 (* 1 = 0.000544657 loss)
I0730 02:35:42.807710 17816 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0730 02:37:15.833113 17816 solver.cpp:228] Iteration 13500, loss = 0.00186346
I0730 02:37:15.833247 17816 solver.cpp:244]     Train net output #0: loss = 0.00186344 (* 1 = 0.00186344 loss)
I0730 02:37:15.833266 17816 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0730 02:38:48.930091 17816 solver.cpp:228] Iteration 13550, loss = 0.0180712
I0730 02:38:48.930218 17816 solver.cpp:244]     Train net output #0: loss = 0.0180712 (* 1 = 0.0180712 loss)
I0730 02:38:48.930236 17816 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0730 02:40:22.045799 17816 solver.cpp:228] Iteration 13600, loss = 0.0294398
I0730 02:40:22.045924 17816 solver.cpp:244]     Train net output #0: loss = 0.0294398 (* 1 = 0.0294398 loss)
I0730 02:40:22.045943 17816 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0730 02:41:55.384162 17816 solver.cpp:228] Iteration 13650, loss = 0.000640877
I0730 02:41:55.384326 17816 solver.cpp:244]     Train net output #0: loss = 0.000640861 (* 1 = 0.000640861 loss)
I0730 02:41:55.384346 17816 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0730 02:43:28.625531 17816 solver.cpp:228] Iteration 13700, loss = 0.00224114
I0730 02:43:28.625723 17816 solver.cpp:244]     Train net output #0: loss = 0.00224112 (* 1 = 0.00224112 loss)
I0730 02:43:28.625742 17816 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0730 02:45:01.813359 17816 solver.cpp:228] Iteration 13750, loss = 0.019927
I0730 02:45:01.813527 17816 solver.cpp:244]     Train net output #0: loss = 0.019927 (* 1 = 0.019927 loss)
I0730 02:45:01.813558 17816 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0730 02:46:34.986961 17816 solver.cpp:228] Iteration 13800, loss = 0.0057461
I0730 02:46:34.987090 17816 solver.cpp:244]     Train net output #0: loss = 0.00574608 (* 1 = 0.00574608 loss)
I0730 02:46:34.987109 17816 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0730 02:48:08.094328 17816 solver.cpp:228] Iteration 13850, loss = 0.00679949
I0730 02:48:08.094455 17816 solver.cpp:244]     Train net output #0: loss = 0.00679947 (* 1 = 0.00679947 loss)
I0730 02:48:08.094473 17816 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0730 02:49:41.226899 17816 solver.cpp:228] Iteration 13900, loss = 0.00181497
I0730 02:49:41.227031 17816 solver.cpp:244]     Train net output #0: loss = 0.00181494 (* 1 = 0.00181494 loss)
I0730 02:49:41.227051 17816 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0730 02:51:14.329903 17816 solver.cpp:228] Iteration 13950, loss = 0.00342727
I0730 02:51:14.330018 17816 solver.cpp:244]     Train net output #0: loss = 0.00342725 (* 1 = 0.00342725 loss)
I0730 02:51:14.330037 17816 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0730 02:52:45.715745 17816 solver.cpp:337] Iteration 14000, Testing net (#0)
I0730 02:57:02.734503 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 02:57:02.734632 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 02:57:04.075788 17816 solver.cpp:228] Iteration 14000, loss = 0.0023929
I0730 02:57:04.075839 17816 solver.cpp:244]     Train net output #0: loss = 0.00239289 (* 1 = 0.00239289 loss)
I0730 02:57:04.075855 17816 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0730 02:58:37.216028 17816 solver.cpp:228] Iteration 14050, loss = 0.00557774
I0730 02:58:37.216238 17816 solver.cpp:244]     Train net output #0: loss = 0.00557772 (* 1 = 0.00557772 loss)
I0730 02:58:37.216258 17816 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0730 03:00:10.344493 17816 solver.cpp:228] Iteration 14100, loss = 0.00102775
I0730 03:00:10.344624 17816 solver.cpp:244]     Train net output #0: loss = 0.00102773 (* 1 = 0.00102773 loss)
I0730 03:00:10.344642 17816 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0730 03:01:43.465219 17816 solver.cpp:228] Iteration 14150, loss = 4.39662e-05
I0730 03:01:43.465426 17816 solver.cpp:244]     Train net output #0: loss = 4.39447e-05 (* 1 = 4.39447e-05 loss)
I0730 03:01:43.465463 17816 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0730 03:03:16.532074 17816 solver.cpp:228] Iteration 14200, loss = 0.000730548
I0730 03:03:16.532243 17816 solver.cpp:244]     Train net output #0: loss = 0.000730525 (* 1 = 0.000730525 loss)
I0730 03:03:16.532261 17816 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0730 03:04:49.773308 17816 solver.cpp:228] Iteration 14250, loss = 0.0106861
I0730 03:04:49.773427 17816 solver.cpp:244]     Train net output #0: loss = 0.0106861 (* 1 = 0.0106861 loss)
I0730 03:04:49.773445 17816 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0730 03:06:22.905740 17816 solver.cpp:228] Iteration 14300, loss = 0.00261755
I0730 03:06:22.905866 17816 solver.cpp:244]     Train net output #0: loss = 0.00261753 (* 1 = 0.00261753 loss)
I0730 03:06:22.905885 17816 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0730 03:07:56.121374 17816 solver.cpp:228] Iteration 14350, loss = 0.0115759
I0730 03:07:56.121525 17816 solver.cpp:244]     Train net output #0: loss = 0.0115759 (* 1 = 0.0115759 loss)
I0730 03:07:56.121542 17816 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0730 03:09:29.192740 17816 solver.cpp:228] Iteration 14400, loss = 0.00366407
I0730 03:09:29.192867 17816 solver.cpp:244]     Train net output #0: loss = 0.00366405 (* 1 = 0.00366405 loss)
I0730 03:09:29.192885 17816 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0730 03:11:02.426187 17816 solver.cpp:228] Iteration 14450, loss = 0.000812888
I0730 03:11:02.426353 17816 solver.cpp:244]     Train net output #0: loss = 0.000812872 (* 1 = 0.000812872 loss)
I0730 03:11:02.426373 17816 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0730 03:12:35.503510 17816 solver.cpp:228] Iteration 14500, loss = 0.00103148
I0730 03:12:35.503643 17816 solver.cpp:244]     Train net output #0: loss = 0.00103146 (* 1 = 0.00103146 loss)
I0730 03:12:35.503664 17816 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0730 03:14:08.919021 17816 solver.cpp:228] Iteration 14550, loss = 0.00157098
I0730 03:14:08.919203 17816 solver.cpp:244]     Train net output #0: loss = 0.00157097 (* 1 = 0.00157097 loss)
I0730 03:14:08.919224 17816 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0730 03:15:42.051363 17816 solver.cpp:228] Iteration 14600, loss = 0.025551
I0730 03:15:42.051488 17816 solver.cpp:244]     Train net output #0: loss = 0.025551 (* 1 = 0.025551 loss)
I0730 03:15:42.051508 17816 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0730 03:17:15.471753 17816 solver.cpp:228] Iteration 14650, loss = 0.000790664
I0730 03:17:15.471886 17816 solver.cpp:244]     Train net output #0: loss = 0.000790649 (* 1 = 0.000790649 loss)
I0730 03:17:15.471906 17816 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0730 03:18:48.659333 17816 solver.cpp:228] Iteration 14700, loss = 0.000730219
I0730 03:18:48.659512 17816 solver.cpp:244]     Train net output #0: loss = 0.000730204 (* 1 = 0.000730204 loss)
I0730 03:18:48.659543 17816 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0730 03:20:21.808295 17816 solver.cpp:228] Iteration 14750, loss = 0.0019066
I0730 03:20:21.808414 17816 solver.cpp:244]     Train net output #0: loss = 0.00190659 (* 1 = 0.00190659 loss)
I0730 03:20:21.808432 17816 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0730 03:21:55.059062 17816 solver.cpp:228] Iteration 14800, loss = 0.0283009
I0730 03:21:55.059191 17816 solver.cpp:244]     Train net output #0: loss = 0.0283009 (* 1 = 0.0283009 loss)
I0730 03:21:55.059211 17816 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0730 03:23:28.311018 17816 solver.cpp:228] Iteration 14850, loss = 0.00193834
I0730 03:23:28.311215 17816 solver.cpp:244]     Train net output #0: loss = 0.00193832 (* 1 = 0.00193832 loss)
I0730 03:23:28.311234 17816 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0730 03:25:01.537475 17816 solver.cpp:228] Iteration 14900, loss = 0.00386746
I0730 03:25:01.537641 17816 solver.cpp:244]     Train net output #0: loss = 0.00386745 (* 1 = 0.00386745 loss)
I0730 03:25:01.537659 17816 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0730 03:26:34.624681 17816 solver.cpp:228] Iteration 14950, loss = 0.000480113
I0730 03:26:34.624843 17816 solver.cpp:244]     Train net output #0: loss = 0.000480099 (* 1 = 0.000480099 loss)
I0730 03:26:34.624861 17816 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0730 03:28:05.947890 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_15000.caffemodel
I0730 03:28:09.438587 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_15000.solverstate
I0730 03:28:13.624305 17816 solver.cpp:337] Iteration 15000, Testing net (#0)
I0730 03:32:26.635344 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 03:32:26.635506 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 03:32:27.977341 17816 solver.cpp:228] Iteration 15000, loss = 0.000451995
I0730 03:32:27.977398 17816 solver.cpp:244]     Train net output #0: loss = 0.000451982 (* 1 = 0.000451982 loss)
I0730 03:32:27.977419 17816 sgd_solver.cpp:106] Iteration 15000, lr = 1e-09
I0730 03:34:01.113492 17816 solver.cpp:228] Iteration 15050, loss = 0.00276843
I0730 03:34:01.113668 17816 solver.cpp:244]     Train net output #0: loss = 0.00276842 (* 1 = 0.00276842 loss)
I0730 03:34:01.113688 17816 sgd_solver.cpp:106] Iteration 15050, lr = 1e-09
I0730 03:35:34.469720 17816 solver.cpp:228] Iteration 15100, loss = 0.000312269
I0730 03:35:34.469902 17816 solver.cpp:244]     Train net output #0: loss = 0.000312266 (* 1 = 0.000312266 loss)
I0730 03:35:34.469923 17816 sgd_solver.cpp:106] Iteration 15100, lr = 1e-09
I0730 03:37:07.707945 17816 solver.cpp:228] Iteration 15150, loss = 0.0012967
I0730 03:37:07.708119 17816 solver.cpp:244]     Train net output #0: loss = 0.00129669 (* 1 = 0.00129669 loss)
I0730 03:37:07.708140 17816 sgd_solver.cpp:106] Iteration 15150, lr = 1e-09
I0730 03:38:40.844527 17816 solver.cpp:228] Iteration 15200, loss = 0.00131994
I0730 03:38:40.844645 17816 solver.cpp:244]     Train net output #0: loss = 0.00131995 (* 1 = 0.00131995 loss)
I0730 03:38:40.844665 17816 sgd_solver.cpp:106] Iteration 15200, lr = 1e-09
I0730 03:40:14.041317 17816 solver.cpp:228] Iteration 15250, loss = 0.0173398
I0730 03:40:14.041472 17816 solver.cpp:244]     Train net output #0: loss = 0.0173398 (* 1 = 0.0173398 loss)
I0730 03:40:14.041491 17816 sgd_solver.cpp:106] Iteration 15250, lr = 1e-09
I0730 03:41:47.120688 17816 solver.cpp:228] Iteration 15300, loss = 0.00269972
I0730 03:41:47.120940 17816 solver.cpp:244]     Train net output #0: loss = 0.00269973 (* 1 = 0.00269973 loss)
I0730 03:41:47.120965 17816 sgd_solver.cpp:106] Iteration 15300, lr = 1e-09
I0730 03:43:20.255431 17816 solver.cpp:228] Iteration 15350, loss = 0.00179515
I0730 03:43:20.255615 17816 solver.cpp:244]     Train net output #0: loss = 0.00179516 (* 1 = 0.00179516 loss)
I0730 03:43:20.255636 17816 sgd_solver.cpp:106] Iteration 15350, lr = 1e-09
I0730 03:44:53.289542 17816 solver.cpp:228] Iteration 15400, loss = 0.00219474
I0730 03:44:53.289688 17816 solver.cpp:244]     Train net output #0: loss = 0.00219475 (* 1 = 0.00219475 loss)
I0730 03:44:53.289710 17816 sgd_solver.cpp:106] Iteration 15400, lr = 1e-09
I0730 03:46:26.553037 17816 solver.cpp:228] Iteration 15450, loss = 0.000785199
I0730 03:46:26.553170 17816 solver.cpp:244]     Train net output #0: loss = 0.000785206 (* 1 = 0.000785206 loss)
I0730 03:46:26.553189 17816 sgd_solver.cpp:106] Iteration 15450, lr = 1e-09
I0730 03:47:59.651801 17816 solver.cpp:228] Iteration 15500, loss = 0.0059904
I0730 03:47:59.651932 17816 solver.cpp:244]     Train net output #0: loss = 0.00599041 (* 1 = 0.00599041 loss)
I0730 03:47:59.651950 17816 sgd_solver.cpp:106] Iteration 15500, lr = 1e-09
I0730 03:49:32.920927 17816 solver.cpp:228] Iteration 15550, loss = 0.00227704
I0730 03:49:32.921149 17816 solver.cpp:244]     Train net output #0: loss = 0.00227705 (* 1 = 0.00227705 loss)
I0730 03:49:32.921169 17816 sgd_solver.cpp:106] Iteration 15550, lr = 1e-09
I0730 03:51:06.009275 17816 solver.cpp:228] Iteration 15600, loss = 0.00507772
I0730 03:51:06.009459 17816 solver.cpp:244]     Train net output #0: loss = 0.00507773 (* 1 = 0.00507773 loss)
I0730 03:51:06.009477 17816 sgd_solver.cpp:106] Iteration 15600, lr = 1e-09
I0730 03:52:39.204746 17816 solver.cpp:228] Iteration 15650, loss = 0.00479626
I0730 03:52:39.204907 17816 solver.cpp:244]     Train net output #0: loss = 0.00479627 (* 1 = 0.00479627 loss)
I0730 03:52:39.204926 17816 sgd_solver.cpp:106] Iteration 15650, lr = 1e-09
I0730 03:54:12.342516 17816 solver.cpp:228] Iteration 15700, loss = 0.00360127
I0730 03:54:12.342649 17816 solver.cpp:244]     Train net output #0: loss = 0.00360127 (* 1 = 0.00360127 loss)
I0730 03:54:12.342669 17816 sgd_solver.cpp:106] Iteration 15700, lr = 1e-09
I0730 03:55:45.468709 17816 solver.cpp:228] Iteration 15750, loss = 0.000870737
I0730 03:55:45.468865 17816 solver.cpp:244]     Train net output #0: loss = 0.000870747 (* 1 = 0.000870747 loss)
I0730 03:55:45.468884 17816 sgd_solver.cpp:106] Iteration 15750, lr = 1e-09
I0730 03:57:18.771803 17816 solver.cpp:228] Iteration 15800, loss = 0.00120496
I0730 03:57:18.771953 17816 solver.cpp:244]     Train net output #0: loss = 0.00120497 (* 1 = 0.00120497 loss)
I0730 03:57:18.771972 17816 sgd_solver.cpp:106] Iteration 15800, lr = 1e-09
I0730 03:58:52.016752 17816 solver.cpp:228] Iteration 15850, loss = 0.00284407
I0730 03:58:52.016919 17816 solver.cpp:244]     Train net output #0: loss = 0.00284408 (* 1 = 0.00284408 loss)
I0730 03:58:52.016939 17816 sgd_solver.cpp:106] Iteration 15850, lr = 1e-09
I0730 04:00:25.205732 17816 solver.cpp:228] Iteration 15900, loss = 0.00554497
I0730 04:00:25.205909 17816 solver.cpp:244]     Train net output #0: loss = 0.00554498 (* 1 = 0.00554498 loss)
I0730 04:00:25.205929 17816 sgd_solver.cpp:106] Iteration 15900, lr = 1e-09
I0730 04:01:58.201951 17816 solver.cpp:228] Iteration 15950, loss = 0.0076022
I0730 04:01:58.202077 17816 solver.cpp:244]     Train net output #0: loss = 0.00760221 (* 1 = 0.00760221 loss)
I0730 04:01:58.202095 17816 sgd_solver.cpp:106] Iteration 15950, lr = 1e-09
I0730 04:03:29.607532 17816 solver.cpp:337] Iteration 16000, Testing net (#0)
I0730 04:07:47.171999 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 04:07:47.172127 17816 solver.cpp:404]     Test net output #1: loss = 0.0859051 (* 1 = 0.0859051 loss)
I0730 04:07:48.512576 17816 solver.cpp:228] Iteration 16000, loss = 0.0239861
I0730 04:07:48.512626 17816 solver.cpp:244]     Train net output #0: loss = 0.0239861 (* 1 = 0.0239861 loss)
I0730 04:07:48.512644 17816 sgd_solver.cpp:106] Iteration 16000, lr = 1e-09
I0730 04:09:21.796057 17816 solver.cpp:228] Iteration 16050, loss = 0.00127886
I0730 04:09:21.796216 17816 solver.cpp:244]     Train net output #0: loss = 0.00127887 (* 1 = 0.00127887 loss)
I0730 04:09:21.796247 17816 sgd_solver.cpp:106] Iteration 16050, lr = 1e-09
I0730 04:10:54.868229 17816 solver.cpp:228] Iteration 16100, loss = 0.000535481
I0730 04:10:54.868360 17816 solver.cpp:244]     Train net output #0: loss = 0.000535485 (* 1 = 0.000535485 loss)
I0730 04:10:54.868378 17816 sgd_solver.cpp:106] Iteration 16100, lr = 1e-09
I0730 04:12:28.055352 17816 solver.cpp:228] Iteration 16150, loss = 0.011915
I0730 04:12:28.055477 17816 solver.cpp:244]     Train net output #0: loss = 0.011915 (* 1 = 0.011915 loss)
I0730 04:12:28.055495 17816 sgd_solver.cpp:106] Iteration 16150, lr = 1e-09
I0730 04:14:01.195554 17816 solver.cpp:228] Iteration 16200, loss = 0.0282131
I0730 04:14:01.195731 17816 solver.cpp:244]     Train net output #0: loss = 0.0282131 (* 1 = 0.0282131 loss)
I0730 04:14:01.195751 17816 sgd_solver.cpp:106] Iteration 16200, lr = 1e-09
I0730 04:15:34.200768 17816 solver.cpp:228] Iteration 16250, loss = 0.0054667
I0730 04:15:34.200893 17816 solver.cpp:244]     Train net output #0: loss = 0.0054667 (* 1 = 0.0054667 loss)
I0730 04:15:34.200912 17816 sgd_solver.cpp:106] Iteration 16250, lr = 1e-09
I0730 04:17:07.388828 17816 solver.cpp:228] Iteration 16300, loss = 0.00867222
I0730 04:17:07.389000 17816 solver.cpp:244]     Train net output #0: loss = 0.00867222 (* 1 = 0.00867222 loss)
I0730 04:17:07.389024 17816 sgd_solver.cpp:106] Iteration 16300, lr = 1e-09
I0730 04:18:40.492597 17816 solver.cpp:228] Iteration 16350, loss = 0.0040961
I0730 04:18:40.521018 17816 solver.cpp:244]     Train net output #0: loss = 0.0040961 (* 1 = 0.0040961 loss)
I0730 04:18:40.521112 17816 sgd_solver.cpp:106] Iteration 16350, lr = 1e-09
I0730 04:20:13.833981 17816 solver.cpp:228] Iteration 16400, loss = 0.00322253
I0730 04:20:13.834107 17816 solver.cpp:244]     Train net output #0: loss = 0.00322253 (* 1 = 0.00322253 loss)
I0730 04:20:13.834126 17816 sgd_solver.cpp:106] Iteration 16400, lr = 1e-09
I0730 04:21:47.171668 17816 solver.cpp:228] Iteration 16450, loss = 0.000589583
I0730 04:21:47.171854 17816 solver.cpp:244]     Train net output #0: loss = 0.000589583 (* 1 = 0.000589583 loss)
I0730 04:21:47.171872 17816 sgd_solver.cpp:106] Iteration 16450, lr = 1e-09
I0730 04:23:20.461948 17816 solver.cpp:228] Iteration 16500, loss = 0.000899869
I0730 04:23:20.462080 17816 solver.cpp:244]     Train net output #0: loss = 0.000899869 (* 1 = 0.000899869 loss)
I0730 04:23:20.462100 17816 sgd_solver.cpp:106] Iteration 16500, lr = 1e-09
I0730 04:24:53.526733 17816 solver.cpp:228] Iteration 16550, loss = 0.00952504
I0730 04:24:53.526871 17816 solver.cpp:244]     Train net output #0: loss = 0.00952504 (* 1 = 0.00952504 loss)
I0730 04:24:53.526890 17816 sgd_solver.cpp:106] Iteration 16550, lr = 1e-09
I0730 04:26:26.780674 17816 solver.cpp:228] Iteration 16600, loss = 0.00202832
I0730 04:26:26.780804 17816 solver.cpp:244]     Train net output #0: loss = 0.00202832 (* 1 = 0.00202832 loss)
I0730 04:26:26.780822 17816 sgd_solver.cpp:106] Iteration 16600, lr = 1e-09
I0730 04:27:59.896061 17816 solver.cpp:228] Iteration 16650, loss = 0.00115603
I0730 04:27:59.896193 17816 solver.cpp:244]     Train net output #0: loss = 0.00115604 (* 1 = 0.00115604 loss)
I0730 04:27:59.896211 17816 sgd_solver.cpp:106] Iteration 16650, lr = 1e-09
I0730 04:29:33.045301 17816 solver.cpp:228] Iteration 16700, loss = 0.00104
I0730 04:29:33.045438 17816 solver.cpp:244]     Train net output #0: loss = 0.00104001 (* 1 = 0.00104001 loss)
I0730 04:29:33.045456 17816 sgd_solver.cpp:106] Iteration 16700, lr = 1e-09
I0730 04:31:06.322410 17816 solver.cpp:228] Iteration 16750, loss = 0.00171888
I0730 04:31:06.322546 17816 solver.cpp:244]     Train net output #0: loss = 0.00171888 (* 1 = 0.00171888 loss)
I0730 04:31:06.322566 17816 sgd_solver.cpp:106] Iteration 16750, lr = 1e-09
I0730 04:32:39.387588 17816 solver.cpp:228] Iteration 16800, loss = 0.000492144
I0730 04:32:39.387791 17816 solver.cpp:244]     Train net output #0: loss = 0.00049215 (* 1 = 0.00049215 loss)
I0730 04:32:39.387821 17816 sgd_solver.cpp:106] Iteration 16800, lr = 1e-09
I0730 04:34:12.502912 17816 solver.cpp:228] Iteration 16850, loss = 0.00435128
I0730 04:34:12.503070 17816 solver.cpp:244]     Train net output #0: loss = 0.00435129 (* 1 = 0.00435129 loss)
I0730 04:34:12.503089 17816 sgd_solver.cpp:106] Iteration 16850, lr = 1e-09
I0730 04:35:45.631906 17816 solver.cpp:228] Iteration 16900, loss = 0.00223821
I0730 04:35:45.632038 17816 solver.cpp:244]     Train net output #0: loss = 0.00223822 (* 1 = 0.00223822 loss)
I0730 04:35:45.632056 17816 sgd_solver.cpp:106] Iteration 16900, lr = 1e-09
I0730 04:37:18.838996 17816 solver.cpp:228] Iteration 16950, loss = 0.000227687
I0730 04:37:18.839133 17816 solver.cpp:244]     Train net output #0: loss = 0.000227699 (* 1 = 0.000227699 loss)
I0730 04:37:18.839157 17816 sgd_solver.cpp:106] Iteration 16950, lr = 1e-09
I0730 04:38:50.198650 17816 solver.cpp:337] Iteration 17000, Testing net (#0)
I0730 04:43:07.510550 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 04:43:07.510674 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 04:43:08.853219 17816 solver.cpp:228] Iteration 17000, loss = 0.00160825
I0730 04:43:08.853271 17816 solver.cpp:244]     Train net output #0: loss = 0.00160826 (* 1 = 0.00160826 loss)
I0730 04:43:08.853286 17816 sgd_solver.cpp:106] Iteration 17000, lr = 1e-09
I0730 04:44:42.042464 17816 solver.cpp:228] Iteration 17050, loss = 0.00217676
I0730 04:44:42.042659 17816 solver.cpp:244]     Train net output #0: loss = 0.00217677 (* 1 = 0.00217677 loss)
I0730 04:44:42.042678 17816 sgd_solver.cpp:106] Iteration 17050, lr = 1e-09
I0730 04:46:15.199030 17816 solver.cpp:228] Iteration 17100, loss = 0.00252089
I0730 04:46:15.199265 17816 solver.cpp:244]     Train net output #0: loss = 0.00252091 (* 1 = 0.00252091 loss)
I0730 04:46:15.199288 17816 sgd_solver.cpp:106] Iteration 17100, lr = 1e-09
I0730 04:47:48.569478 17816 solver.cpp:228] Iteration 17150, loss = 0.00237409
I0730 04:47:48.569627 17816 solver.cpp:244]     Train net output #0: loss = 0.0023741 (* 1 = 0.0023741 loss)
I0730 04:47:48.569645 17816 sgd_solver.cpp:106] Iteration 17150, lr = 1e-09
I0730 04:49:21.760422 17816 solver.cpp:228] Iteration 17200, loss = 0.000226093
I0730 04:49:21.760568 17816 solver.cpp:244]     Train net output #0: loss = 0.000226107 (* 1 = 0.000226107 loss)
I0730 04:49:21.760588 17816 sgd_solver.cpp:106] Iteration 17200, lr = 1e-09
I0730 04:50:53.926378 17816 solver.cpp:228] Iteration 17250, loss = 0.000762952
I0730 04:50:53.926506 17816 solver.cpp:244]     Train net output #0: loss = 0.000762967 (* 1 = 0.000762967 loss)
I0730 04:50:53.926525 17816 sgd_solver.cpp:106] Iteration 17250, lr = 1e-09
I0730 04:52:25.327667 17816 solver.cpp:228] Iteration 17300, loss = 0.000615697
I0730 04:52:25.327847 17816 solver.cpp:244]     Train net output #0: loss = 0.000615711 (* 1 = 0.000615711 loss)
I0730 04:52:25.327872 17816 sgd_solver.cpp:106] Iteration 17300, lr = 1e-09
I0730 04:53:56.789474 17816 solver.cpp:228] Iteration 17350, loss = 0.000180754
I0730 04:53:56.789649 17816 solver.cpp:244]     Train net output #0: loss = 0.000180767 (* 1 = 0.000180767 loss)
I0730 04:53:56.789669 17816 sgd_solver.cpp:106] Iteration 17350, lr = 1e-09
I0730 04:55:28.078789 17816 solver.cpp:228] Iteration 17400, loss = 0.0043357
I0730 04:55:28.078953 17816 solver.cpp:244]     Train net output #0: loss = 0.00433571 (* 1 = 0.00433571 loss)
I0730 04:55:28.078974 17816 sgd_solver.cpp:106] Iteration 17400, lr = 1e-09
I0730 04:56:59.256794 17816 solver.cpp:228] Iteration 17450, loss = 0.0171036
I0730 04:56:59.256956 17816 solver.cpp:244]     Train net output #0: loss = 0.0171036 (* 1 = 0.0171036 loss)
I0730 04:56:59.256975 17816 sgd_solver.cpp:106] Iteration 17450, lr = 1e-09
I0730 04:58:30.397917 17816 solver.cpp:228] Iteration 17500, loss = 0.00060035
I0730 04:58:30.398080 17816 solver.cpp:244]     Train net output #0: loss = 0.000600366 (* 1 = 0.000600366 loss)
I0730 04:58:30.398102 17816 sgd_solver.cpp:106] Iteration 17500, lr = 1e-10
I0730 05:00:01.737555 17816 solver.cpp:228] Iteration 17550, loss = 0.000627057
I0730 05:00:01.737711 17816 solver.cpp:244]     Train net output #0: loss = 0.000627078 (* 1 = 0.000627078 loss)
I0730 05:00:01.737730 17816 sgd_solver.cpp:106] Iteration 17550, lr = 1e-10
I0730 05:01:33.187360 17816 solver.cpp:228] Iteration 17600, loss = 0.0207798
I0730 05:01:33.187554 17816 solver.cpp:244]     Train net output #0: loss = 0.0207799 (* 1 = 0.0207799 loss)
I0730 05:01:33.187578 17816 sgd_solver.cpp:106] Iteration 17600, lr = 1e-10
I0730 05:03:04.580081 17816 solver.cpp:228] Iteration 17650, loss = 0.000453398
I0730 05:03:04.580250 17816 solver.cpp:244]     Train net output #0: loss = 0.000453419 (* 1 = 0.000453419 loss)
I0730 05:03:04.580271 17816 sgd_solver.cpp:106] Iteration 17650, lr = 1e-10
I0730 05:04:35.919049 17816 solver.cpp:228] Iteration 17700, loss = 0.000364396
I0730 05:04:35.919216 17816 solver.cpp:244]     Train net output #0: loss = 0.000364423 (* 1 = 0.000364423 loss)
I0730 05:04:35.919239 17816 sgd_solver.cpp:106] Iteration 17700, lr = 1e-10
I0730 05:06:07.381312 17816 solver.cpp:228] Iteration 17750, loss = 0.00453629
I0730 05:06:07.381516 17816 solver.cpp:244]     Train net output #0: loss = 0.00453631 (* 1 = 0.00453631 loss)
I0730 05:06:07.381536 17816 sgd_solver.cpp:106] Iteration 17750, lr = 1e-10
I0730 05:07:38.732715 17816 solver.cpp:228] Iteration 17800, loss = 0.00315909
I0730 05:07:38.755018 17816 solver.cpp:244]     Train net output #0: loss = 0.00315912 (* 1 = 0.00315912 loss)
I0730 05:07:38.755079 17816 sgd_solver.cpp:106] Iteration 17800, lr = 1e-10
I0730 05:09:10.087846 17816 solver.cpp:228] Iteration 17850, loss = 0.00124897
I0730 05:09:10.088027 17816 solver.cpp:244]     Train net output #0: loss = 0.00124899 (* 1 = 0.00124899 loss)
I0730 05:09:10.088047 17816 sgd_solver.cpp:106] Iteration 17850, lr = 1e-10
I0730 05:10:42.062737 17816 solver.cpp:228] Iteration 17900, loss = 0.00018952
I0730 05:10:42.062878 17816 solver.cpp:244]     Train net output #0: loss = 0.000189542 (* 1 = 0.000189542 loss)
I0730 05:10:42.062913 17816 sgd_solver.cpp:106] Iteration 17900, lr = 1e-10
I0730 05:12:15.203552 17816 solver.cpp:228] Iteration 17950, loss = 0.0018047
I0730 05:12:15.203703 17816 solver.cpp:244]     Train net output #0: loss = 0.00180472 (* 1 = 0.00180472 loss)
I0730 05:12:15.203722 17816 sgd_solver.cpp:106] Iteration 17950, lr = 1e-10
I0730 05:13:46.601604 17816 solver.cpp:337] Iteration 18000, Testing net (#0)
I0730 05:18:03.895771 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 05:18:03.895895 17816 solver.cpp:404]     Test net output #1: loss = 0.0859059 (* 1 = 0.0859059 loss)
I0730 05:18:05.247220 17816 solver.cpp:228] Iteration 18000, loss = 0.00929079
I0730 05:18:05.247274 17816 solver.cpp:244]     Train net output #0: loss = 0.00929081 (* 1 = 0.00929081 loss)
I0730 05:18:05.247290 17816 sgd_solver.cpp:106] Iteration 18000, lr = 1e-10
I0730 05:19:38.271121 17816 solver.cpp:228] Iteration 18050, loss = 0.00605971
I0730 05:19:38.271252 17816 solver.cpp:244]     Train net output #0: loss = 0.00605972 (* 1 = 0.00605972 loss)
I0730 05:19:38.271271 17816 sgd_solver.cpp:106] Iteration 18050, lr = 1e-10
I0730 05:21:11.581964 17816 solver.cpp:228] Iteration 18100, loss = 0.00427473
I0730 05:21:11.582092 17816 solver.cpp:244]     Train net output #0: loss = 0.00427474 (* 1 = 0.00427474 loss)
I0730 05:21:11.582110 17816 sgd_solver.cpp:106] Iteration 18100, lr = 1e-10
I0730 05:22:44.604863 17816 solver.cpp:228] Iteration 18150, loss = 0.00215518
I0730 05:22:44.605024 17816 solver.cpp:244]     Train net output #0: loss = 0.00215519 (* 1 = 0.00215519 loss)
I0730 05:22:44.605051 17816 sgd_solver.cpp:106] Iteration 18150, lr = 1e-10
I0730 05:24:17.685995 17816 solver.cpp:228] Iteration 18200, loss = 0.00167897
I0730 05:24:17.686158 17816 solver.cpp:244]     Train net output #0: loss = 0.00167898 (* 1 = 0.00167898 loss)
I0730 05:24:17.686177 17816 sgd_solver.cpp:106] Iteration 18200, lr = 1e-10
I0730 05:25:50.880480 17816 solver.cpp:228] Iteration 18250, loss = 0.000951808
I0730 05:25:50.880611 17816 solver.cpp:244]     Train net output #0: loss = 0.000951827 (* 1 = 0.000951827 loss)
I0730 05:25:50.880630 17816 sgd_solver.cpp:106] Iteration 18250, lr = 1e-10
I0730 05:27:24.179280 17816 solver.cpp:228] Iteration 18300, loss = 0.00173783
I0730 05:27:24.179407 17816 solver.cpp:244]     Train net output #0: loss = 0.00173784 (* 1 = 0.00173784 loss)
I0730 05:27:24.179426 17816 sgd_solver.cpp:106] Iteration 18300, lr = 1e-10
I0730 05:28:57.332680 17816 solver.cpp:228] Iteration 18350, loss = 0.00465627
I0730 05:28:57.332811 17816 solver.cpp:244]     Train net output #0: loss = 0.00465628 (* 1 = 0.00465628 loss)
I0730 05:28:57.332830 17816 sgd_solver.cpp:106] Iteration 18350, lr = 1e-10
I0730 05:30:30.619647 17816 solver.cpp:228] Iteration 18400, loss = 0.0233365
I0730 05:30:30.619781 17816 solver.cpp:244]     Train net output #0: loss = 0.0233365 (* 1 = 0.0233365 loss)
I0730 05:30:30.619799 17816 sgd_solver.cpp:106] Iteration 18400, lr = 1e-10
I0730 05:32:03.847407 17816 solver.cpp:228] Iteration 18450, loss = 0.00150917
I0730 05:32:03.847582 17816 solver.cpp:244]     Train net output #0: loss = 0.00150919 (* 1 = 0.00150919 loss)
I0730 05:32:03.847601 17816 sgd_solver.cpp:106] Iteration 18450, lr = 1e-10
I0730 05:33:37.029520 17816 solver.cpp:228] Iteration 18500, loss = 0.000221157
I0730 05:33:37.029681 17816 solver.cpp:244]     Train net output #0: loss = 0.000221172 (* 1 = 0.000221172 loss)
I0730 05:33:37.029701 17816 sgd_solver.cpp:106] Iteration 18500, lr = 1e-10
I0730 05:35:10.146636 17816 solver.cpp:228] Iteration 18550, loss = 0.000747225
I0730 05:35:10.146790 17816 solver.cpp:244]     Train net output #0: loss = 0.000747236 (* 1 = 0.000747236 loss)
I0730 05:35:10.146807 17816 sgd_solver.cpp:106] Iteration 18550, lr = 1e-10
I0730 05:36:43.454052 17816 solver.cpp:228] Iteration 18600, loss = 0.0041829
I0730 05:36:43.454190 17816 solver.cpp:244]     Train net output #0: loss = 0.00418291 (* 1 = 0.00418291 loss)
I0730 05:36:43.454210 17816 sgd_solver.cpp:106] Iteration 18600, lr = 1e-10
I0730 05:38:16.580334 17816 solver.cpp:228] Iteration 18650, loss = 0.0056544
I0730 05:38:16.580481 17816 solver.cpp:244]     Train net output #0: loss = 0.00565442 (* 1 = 0.00565442 loss)
I0730 05:38:16.580499 17816 sgd_solver.cpp:106] Iteration 18650, lr = 1e-10
I0730 05:39:49.711190 17816 solver.cpp:228] Iteration 18700, loss = 0.00672212
I0730 05:39:49.711336 17816 solver.cpp:244]     Train net output #0: loss = 0.00672213 (* 1 = 0.00672213 loss)
I0730 05:39:49.711355 17816 sgd_solver.cpp:106] Iteration 18700, lr = 1e-10
I0730 05:41:22.825531 17816 solver.cpp:228] Iteration 18750, loss = 0.000158549
I0730 05:41:22.825654 17816 solver.cpp:244]     Train net output #0: loss = 0.000158562 (* 1 = 0.000158562 loss)
I0730 05:41:22.825672 17816 sgd_solver.cpp:106] Iteration 18750, lr = 1e-10
I0730 05:42:55.962049 17816 solver.cpp:228] Iteration 18800, loss = 0.00618415
I0730 05:42:55.962224 17816 solver.cpp:244]     Train net output #0: loss = 0.00618416 (* 1 = 0.00618416 loss)
I0730 05:42:55.962242 17816 sgd_solver.cpp:106] Iteration 18800, lr = 1e-10
I0730 05:44:29.023017 17816 solver.cpp:228] Iteration 18850, loss = 0.0055792
I0730 05:44:29.023144 17816 solver.cpp:244]     Train net output #0: loss = 0.00557922 (* 1 = 0.00557922 loss)
I0730 05:44:29.023162 17816 sgd_solver.cpp:106] Iteration 18850, lr = 1e-10
I0730 05:46:02.152940 17816 solver.cpp:228] Iteration 18900, loss = 0.0125276
I0730 05:46:02.153071 17816 solver.cpp:244]     Train net output #0: loss = 0.0125276 (* 1 = 0.0125276 loss)
I0730 05:46:02.153090 17816 sgd_solver.cpp:106] Iteration 18900, lr = 1e-10
I0730 05:47:35.335753 17816 solver.cpp:228] Iteration 18950, loss = 0.00105605
I0730 05:47:35.335907 17816 solver.cpp:244]     Train net output #0: loss = 0.00105607 (* 1 = 0.00105607 loss)
I0730 05:47:35.335927 17816 sgd_solver.cpp:106] Iteration 18950, lr = 1e-10
I0730 05:49:06.702042 17816 solver.cpp:337] Iteration 19000, Testing net (#0)
I0730 05:53:23.698742 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 05:53:23.698868 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 05:53:25.047978 17816 solver.cpp:228] Iteration 19000, loss = 0.000490779
I0730 05:53:25.048028 17816 solver.cpp:244]     Train net output #0: loss = 0.000490795 (* 1 = 0.000490795 loss)
I0730 05:53:25.048045 17816 sgd_solver.cpp:106] Iteration 19000, lr = 1e-10
I0730 05:54:58.161902 17816 solver.cpp:228] Iteration 19050, loss = 0.000134247
I0730 05:54:58.162022 17816 solver.cpp:244]     Train net output #0: loss = 0.000134264 (* 1 = 0.000134264 loss)
I0730 05:54:58.162041 17816 sgd_solver.cpp:106] Iteration 19050, lr = 1e-10
I0730 05:56:31.073354 17816 solver.cpp:228] Iteration 19100, loss = 0.0025213
I0730 05:56:31.073509 17816 solver.cpp:244]     Train net output #0: loss = 0.00252132 (* 1 = 0.00252132 loss)
I0730 05:56:31.073528 17816 sgd_solver.cpp:106] Iteration 19100, lr = 1e-10
I0730 05:58:04.210839 17816 solver.cpp:228] Iteration 19150, loss = 0.014568
I0730 05:58:04.210976 17816 solver.cpp:244]     Train net output #0: loss = 0.014568 (* 1 = 0.014568 loss)
I0730 05:58:04.210995 17816 sgd_solver.cpp:106] Iteration 19150, lr = 1e-10
I0730 05:59:37.330713 17816 solver.cpp:228] Iteration 19200, loss = 0.00974907
I0730 05:59:37.330916 17816 solver.cpp:244]     Train net output #0: loss = 0.0097491 (* 1 = 0.0097491 loss)
I0730 05:59:37.330942 17816 sgd_solver.cpp:106] Iteration 19200, lr = 1e-10
I0730 06:01:10.497128 17816 solver.cpp:228] Iteration 19250, loss = 0.000975623
I0730 06:01:10.521049 17816 solver.cpp:244]     Train net output #0: loss = 0.000975647 (* 1 = 0.000975647 loss)
I0730 06:01:10.521097 17816 sgd_solver.cpp:106] Iteration 19250, lr = 1e-10
I0730 06:02:43.728152 17816 solver.cpp:228] Iteration 19300, loss = 0.0117935
I0730 06:02:43.728271 17816 solver.cpp:244]     Train net output #0: loss = 0.0117935 (* 1 = 0.0117935 loss)
I0730 06:02:43.728289 17816 sgd_solver.cpp:106] Iteration 19300, lr = 1e-10
I0730 06:04:16.904351 17816 solver.cpp:228] Iteration 19350, loss = 0.0111863
I0730 06:04:16.904512 17816 solver.cpp:244]     Train net output #0: loss = 0.0111863 (* 1 = 0.0111863 loss)
I0730 06:04:16.904531 17816 sgd_solver.cpp:106] Iteration 19350, lr = 1e-10
I0730 06:05:50.099602 17816 solver.cpp:228] Iteration 19400, loss = 0.00273459
I0730 06:05:50.099756 17816 solver.cpp:244]     Train net output #0: loss = 0.00273461 (* 1 = 0.00273461 loss)
I0730 06:05:50.099776 17816 sgd_solver.cpp:106] Iteration 19400, lr = 1e-10
I0730 06:07:23.392920 17816 solver.cpp:228] Iteration 19450, loss = 0.0062706
I0730 06:07:23.393055 17816 solver.cpp:244]     Train net output #0: loss = 0.00627062 (* 1 = 0.00627062 loss)
I0730 06:07:23.393075 17816 sgd_solver.cpp:106] Iteration 19450, lr = 1e-10
I0730 06:08:56.695725 17816 solver.cpp:228] Iteration 19500, loss = 0.000785073
I0730 06:08:56.695861 17816 solver.cpp:244]     Train net output #0: loss = 0.000785098 (* 1 = 0.000785098 loss)
I0730 06:08:56.695881 17816 sgd_solver.cpp:106] Iteration 19500, lr = 1e-10
I0730 06:10:30.149160 17816 solver.cpp:228] Iteration 19550, loss = 0.00653918
I0730 06:10:30.149284 17816 solver.cpp:244]     Train net output #0: loss = 0.0065392 (* 1 = 0.0065392 loss)
I0730 06:10:30.149303 17816 sgd_solver.cpp:106] Iteration 19550, lr = 1e-10
I0730 06:12:02.596890 17816 solver.cpp:228] Iteration 19600, loss = 0.00217587
I0730 06:12:02.597059 17816 solver.cpp:244]     Train net output #0: loss = 0.00217589 (* 1 = 0.00217589 loss)
I0730 06:12:02.597079 17816 sgd_solver.cpp:106] Iteration 19600, lr = 1e-10
I0730 06:13:34.019681 17816 solver.cpp:228] Iteration 19650, loss = 0.00681778
I0730 06:13:34.019834 17816 solver.cpp:244]     Train net output #0: loss = 0.0068178 (* 1 = 0.0068178 loss)
I0730 06:13:34.019855 17816 sgd_solver.cpp:106] Iteration 19650, lr = 1e-10
I0730 06:15:05.278342 17816 solver.cpp:228] Iteration 19700, loss = 0.00251411
I0730 06:15:05.278488 17816 solver.cpp:244]     Train net output #0: loss = 0.00251413 (* 1 = 0.00251413 loss)
I0730 06:15:05.278511 17816 sgd_solver.cpp:106] Iteration 19700, lr = 1e-10
I0730 06:16:36.587178 17816 solver.cpp:228] Iteration 19750, loss = 0.00168702
I0730 06:16:36.587360 17816 solver.cpp:244]     Train net output #0: loss = 0.00168703 (* 1 = 0.00168703 loss)
I0730 06:16:36.587383 17816 sgd_solver.cpp:106] Iteration 19750, lr = 1e-10
I0730 06:18:07.914055 17816 solver.cpp:228] Iteration 19800, loss = 0.00831094
I0730 06:18:07.914185 17816 solver.cpp:244]     Train net output #0: loss = 0.00831096 (* 1 = 0.00831096 loss)
I0730 06:18:07.914203 17816 sgd_solver.cpp:106] Iteration 19800, lr = 1e-10
I0730 06:19:39.325980 17816 solver.cpp:228] Iteration 19850, loss = 0.0020183
I0730 06:19:39.326113 17816 solver.cpp:244]     Train net output #0: loss = 0.00201831 (* 1 = 0.00201831 loss)
I0730 06:19:39.326134 17816 sgd_solver.cpp:106] Iteration 19850, lr = 1e-10
I0730 06:21:10.704069 17816 solver.cpp:228] Iteration 19900, loss = 0.00561695
I0730 06:21:10.704255 17816 solver.cpp:244]     Train net output #0: loss = 0.00561697 (* 1 = 0.00561697 loss)
I0730 06:21:10.704277 17816 sgd_solver.cpp:106] Iteration 19900, lr = 1e-10
I0730 06:22:42.174177 17816 solver.cpp:228] Iteration 19950, loss = 0.0153196
I0730 06:22:42.174370 17816 solver.cpp:244]     Train net output #0: loss = 0.0153196 (* 1 = 0.0153196 loss)
I0730 06:22:42.174389 17816 sgd_solver.cpp:106] Iteration 19950, lr = 1e-10
I0730 06:24:11.640914 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_20000.caffemodel
I0730 06:24:15.640385 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_20000.solverstate
I0730 06:24:18.700594 17816 solver.cpp:337] Iteration 20000, Testing net (#0)
I0730 06:24:20.430548 17816 blocking_queue.cpp:50] Data layer prefetch queue empty
I0730 06:28:33.247993 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 06:28:33.248175 17816 solver.cpp:404]     Test net output #1: loss = 0.0858853 (* 1 = 0.0858853 loss)
I0730 06:28:34.601049 17816 solver.cpp:228] Iteration 20000, loss = 0.00106773
I0730 06:28:34.601100 17816 solver.cpp:244]     Train net output #0: loss = 0.00106774 (* 1 = 0.00106774 loss)
I0730 06:28:34.601116 17816 sgd_solver.cpp:106] Iteration 20000, lr = 1e-11
I0730 06:30:07.701189 17816 solver.cpp:228] Iteration 20050, loss = 0.0020822
I0730 06:30:07.701320 17816 solver.cpp:244]     Train net output #0: loss = 0.00208221 (* 1 = 0.00208221 loss)
I0730 06:30:07.701339 17816 sgd_solver.cpp:106] Iteration 20050, lr = 1e-11
I0730 06:31:41.041635 17816 solver.cpp:228] Iteration 20100, loss = 0.00237481
I0730 06:31:41.041762 17816 solver.cpp:244]     Train net output #0: loss = 0.00237483 (* 1 = 0.00237483 loss)
I0730 06:31:41.041781 17816 sgd_solver.cpp:106] Iteration 20100, lr = 1e-11
I0730 06:33:14.347671 17816 solver.cpp:228] Iteration 20150, loss = 0.000393934
I0730 06:33:14.347806 17816 solver.cpp:244]     Train net output #0: loss = 0.000393949 (* 1 = 0.000393949 loss)
I0730 06:33:14.347826 17816 sgd_solver.cpp:106] Iteration 20150, lr = 1e-11
I0730 06:34:47.540331 17816 solver.cpp:228] Iteration 20200, loss = 0.00253131
I0730 06:34:47.540524 17816 solver.cpp:244]     Train net output #0: loss = 0.00253133 (* 1 = 0.00253133 loss)
I0730 06:34:47.540544 17816 sgd_solver.cpp:106] Iteration 20200, lr = 1e-11
I0730 06:36:20.728636 17816 solver.cpp:228] Iteration 20250, loss = 0.000142932
I0730 06:36:20.728762 17816 solver.cpp:244]     Train net output #0: loss = 0.000142946 (* 1 = 0.000142946 loss)
I0730 06:36:20.728781 17816 sgd_solver.cpp:106] Iteration 20250, lr = 1e-11
I0730 06:37:53.792419 17816 solver.cpp:228] Iteration 20300, loss = 0.00411823
I0730 06:37:53.792551 17816 solver.cpp:244]     Train net output #0: loss = 0.00411824 (* 1 = 0.00411824 loss)
I0730 06:37:53.792569 17816 sgd_solver.cpp:106] Iteration 20300, lr = 1e-11
I0730 06:39:27.140152 17816 solver.cpp:228] Iteration 20350, loss = 0.000268129
I0730 06:39:27.140285 17816 solver.cpp:244]     Train net output #0: loss = 0.000268139 (* 1 = 0.000268139 loss)
I0730 06:39:27.140302 17816 sgd_solver.cpp:106] Iteration 20350, lr = 1e-11
I0730 06:41:00.297196 17816 solver.cpp:228] Iteration 20400, loss = 0.00993249
I0730 06:41:00.297332 17816 solver.cpp:244]     Train net output #0: loss = 0.0099325 (* 1 = 0.0099325 loss)
I0730 06:41:00.297350 17816 sgd_solver.cpp:106] Iteration 20400, lr = 1e-11
I0730 06:42:33.476769 17816 solver.cpp:228] Iteration 20450, loss = 0.0160506
I0730 06:42:33.476897 17816 solver.cpp:244]     Train net output #0: loss = 0.0160506 (* 1 = 0.0160506 loss)
I0730 06:42:33.476915 17816 sgd_solver.cpp:106] Iteration 20450, lr = 1e-11
I0730 06:44:05.252902 17816 solver.cpp:228] Iteration 20500, loss = 0.0156466
I0730 06:44:05.253083 17816 solver.cpp:244]     Train net output #0: loss = 0.0156466 (* 1 = 0.0156466 loss)
I0730 06:44:05.253113 17816 sgd_solver.cpp:106] Iteration 20500, lr = 1e-11
I0730 06:45:36.727838 17816 solver.cpp:228] Iteration 20550, loss = 0.00460268
I0730 06:45:36.728003 17816 solver.cpp:244]     Train net output #0: loss = 0.00460269 (* 1 = 0.00460269 loss)
I0730 06:45:36.728031 17816 sgd_solver.cpp:106] Iteration 20550, lr = 1e-11
I0730 06:47:08.112249 17816 solver.cpp:228] Iteration 20600, loss = 0.0642658
I0730 06:47:08.112437 17816 solver.cpp:244]     Train net output #0: loss = 0.0642659 (* 1 = 0.0642659 loss)
I0730 06:47:08.112465 17816 sgd_solver.cpp:106] Iteration 20600, lr = 1e-11
I0730 06:48:39.468763 17816 solver.cpp:228] Iteration 20650, loss = 0.00015879
I0730 06:48:39.468960 17816 solver.cpp:244]     Train net output #0: loss = 0.000158797 (* 1 = 0.000158797 loss)
I0730 06:48:39.468991 17816 sgd_solver.cpp:106] Iteration 20650, lr = 1e-11
I0730 06:50:10.849793 17816 solver.cpp:228] Iteration 20700, loss = 0.00101572
I0730 06:50:10.849953 17816 solver.cpp:244]     Train net output #0: loss = 0.00101573 (* 1 = 0.00101573 loss)
I0730 06:50:10.849972 17816 sgd_solver.cpp:106] Iteration 20700, lr = 1e-11
I0730 06:51:42.210963 17816 solver.cpp:228] Iteration 20750, loss = 0.00046284
I0730 06:51:42.211094 17816 solver.cpp:244]     Train net output #0: loss = 0.000462848 (* 1 = 0.000462848 loss)
I0730 06:51:42.211112 17816 sgd_solver.cpp:106] Iteration 20750, lr = 1e-11
I0730 06:53:14.785105 17816 solver.cpp:228] Iteration 20800, loss = 0.00316141
I0730 06:53:14.785302 17816 solver.cpp:244]     Train net output #0: loss = 0.00316142 (* 1 = 0.00316142 loss)
I0730 06:53:14.785326 17816 sgd_solver.cpp:106] Iteration 20800, lr = 1e-11
I0730 06:54:48.075389 17816 solver.cpp:228] Iteration 20850, loss = 0.0157933
I0730 06:54:48.075563 17816 solver.cpp:244]     Train net output #0: loss = 0.0157933 (* 1 = 0.0157933 loss)
I0730 06:54:48.075585 17816 sgd_solver.cpp:106] Iteration 20850, lr = 1e-11
I0730 06:56:20.967037 17816 solver.cpp:228] Iteration 20900, loss = 0.002558
I0730 06:56:20.967278 17816 solver.cpp:244]     Train net output #0: loss = 0.002558 (* 1 = 0.002558 loss)
I0730 06:56:20.967301 17816 sgd_solver.cpp:106] Iteration 20900, lr = 1e-11
I0730 06:57:52.334277 17816 solver.cpp:228] Iteration 20950, loss = 0.00566934
I0730 06:57:52.334413 17816 solver.cpp:244]     Train net output #0: loss = 0.00566934 (* 1 = 0.00566934 loss)
I0730 06:57:52.334431 17816 sgd_solver.cpp:106] Iteration 20950, lr = 1e-11
I0730 06:59:21.902892 17816 solver.cpp:337] Iteration 21000, Testing net (#0)
I0730 07:03:33.518858 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 07:03:33.519024 17816 solver.cpp:404]     Test net output #1: loss = 0.0859011 (* 1 = 0.0859011 loss)
I0730 07:03:34.833427 17816 solver.cpp:228] Iteration 21000, loss = 0.00538772
I0730 07:03:34.833485 17816 solver.cpp:244]     Train net output #0: loss = 0.00538772 (* 1 = 0.00538772 loss)
I0730 07:03:34.833504 17816 sgd_solver.cpp:106] Iteration 21000, lr = 1e-11
I0730 07:05:06.183892 17816 solver.cpp:228] Iteration 21050, loss = 0.00121291
I0730 07:05:06.184064 17816 solver.cpp:244]     Train net output #0: loss = 0.00121291 (* 1 = 0.00121291 loss)
I0730 07:05:06.184087 17816 sgd_solver.cpp:106] Iteration 21050, lr = 1e-11
I0730 07:06:37.576182 17816 solver.cpp:228] Iteration 21100, loss = 0.00113515
I0730 07:06:37.576382 17816 solver.cpp:244]     Train net output #0: loss = 0.00113516 (* 1 = 0.00113516 loss)
I0730 07:06:37.576403 17816 sgd_solver.cpp:106] Iteration 21100, lr = 1e-11
I0730 07:08:08.978157 17816 solver.cpp:228] Iteration 21150, loss = 0.00210906
I0730 07:08:08.978410 17816 solver.cpp:244]     Train net output #0: loss = 0.00210905 (* 1 = 0.00210905 loss)
I0730 07:08:08.978432 17816 sgd_solver.cpp:106] Iteration 21150, lr = 1e-11
I0730 07:09:40.269237 17816 solver.cpp:228] Iteration 21200, loss = 0.00167315
I0730 07:09:40.269428 17816 solver.cpp:244]     Train net output #0: loss = 0.00167315 (* 1 = 0.00167315 loss)
I0730 07:09:40.269449 17816 sgd_solver.cpp:106] Iteration 21200, lr = 1e-11
I0730 07:11:11.561419 17816 solver.cpp:228] Iteration 21250, loss = 0.00204241
I0730 07:11:11.561576 17816 solver.cpp:244]     Train net output #0: loss = 0.0020424 (* 1 = 0.0020424 loss)
I0730 07:11:11.561596 17816 sgd_solver.cpp:106] Iteration 21250, lr = 1e-11
I0730 07:12:43.000280 17816 solver.cpp:228] Iteration 21300, loss = 0.000295669
I0730 07:12:43.000444 17816 solver.cpp:244]     Train net output #0: loss = 0.000295661 (* 1 = 0.000295661 loss)
I0730 07:12:43.000465 17816 sgd_solver.cpp:106] Iteration 21300, lr = 1e-11
I0730 07:14:14.328724 17816 solver.cpp:228] Iteration 21350, loss = 0.00252504
I0730 07:14:14.328866 17816 solver.cpp:244]     Train net output #0: loss = 0.00252503 (* 1 = 0.00252503 loss)
I0730 07:14:14.328889 17816 sgd_solver.cpp:106] Iteration 21350, lr = 1e-11
I0730 07:15:45.742738 17816 solver.cpp:228] Iteration 21400, loss = 0.00410652
I0730 07:15:45.742879 17816 solver.cpp:244]     Train net output #0: loss = 0.00410652 (* 1 = 0.00410652 loss)
I0730 07:15:45.742900 17816 sgd_solver.cpp:106] Iteration 21400, lr = 1e-11
I0730 07:17:17.137414 17816 solver.cpp:228] Iteration 21450, loss = 0.000554645
I0730 07:17:17.137545 17816 solver.cpp:244]     Train net output #0: loss = 0.000554641 (* 1 = 0.000554641 loss)
I0730 07:17:17.137565 17816 sgd_solver.cpp:106] Iteration 21450, lr = 1e-11
I0730 07:18:48.562048 17816 solver.cpp:228] Iteration 21500, loss = 0.00227933
I0730 07:18:48.562223 17816 solver.cpp:244]     Train net output #0: loss = 0.00227933 (* 1 = 0.00227933 loss)
I0730 07:18:48.562245 17816 sgd_solver.cpp:106] Iteration 21500, lr = 1e-11
I0730 07:20:19.831017 17816 solver.cpp:228] Iteration 21550, loss = 0.00418875
I0730 07:20:19.831189 17816 solver.cpp:244]     Train net output #0: loss = 0.00418875 (* 1 = 0.00418875 loss)
I0730 07:20:19.831212 17816 sgd_solver.cpp:106] Iteration 21550, lr = 1e-11
I0730 07:21:51.275781 17816 solver.cpp:228] Iteration 21600, loss = 0.000445581
I0730 07:21:51.275919 17816 solver.cpp:244]     Train net output #0: loss = 0.000445575 (* 1 = 0.000445575 loss)
I0730 07:21:51.275940 17816 sgd_solver.cpp:106] Iteration 21600, lr = 1e-11
I0730 07:23:22.575738 17816 solver.cpp:228] Iteration 21650, loss = 0.000348417
I0730 07:23:22.575878 17816 solver.cpp:244]     Train net output #0: loss = 0.000348411 (* 1 = 0.000348411 loss)
I0730 07:23:22.575901 17816 sgd_solver.cpp:106] Iteration 21650, lr = 1e-11
I0730 07:24:53.980377 17816 solver.cpp:228] Iteration 21700, loss = 0.00285271
I0730 07:24:53.980541 17816 solver.cpp:244]     Train net output #0: loss = 0.0028527 (* 1 = 0.0028527 loss)
I0730 07:24:53.980563 17816 sgd_solver.cpp:106] Iteration 21700, lr = 1e-11
I0730 07:26:25.268086 17816 solver.cpp:228] Iteration 21750, loss = 0.00259858
I0730 07:26:25.268259 17816 solver.cpp:244]     Train net output #0: loss = 0.00259857 (* 1 = 0.00259857 loss)
I0730 07:26:25.268281 17816 sgd_solver.cpp:106] Iteration 21750, lr = 1e-11
I0730 07:27:56.555444 17816 solver.cpp:228] Iteration 21800, loss = 0.00180556
I0730 07:27:56.555575 17816 solver.cpp:244]     Train net output #0: loss = 0.00180555 (* 1 = 0.00180555 loss)
I0730 07:27:56.555595 17816 sgd_solver.cpp:106] Iteration 21800, lr = 1e-11
I0730 07:29:27.917300 17816 solver.cpp:228] Iteration 21850, loss = 0.00071213
I0730 07:29:27.917469 17816 solver.cpp:244]     Train net output #0: loss = 0.00071212 (* 1 = 0.00071212 loss)
I0730 07:29:27.917490 17816 sgd_solver.cpp:106] Iteration 21850, lr = 1e-11
I0730 07:30:59.203299 17816 solver.cpp:228] Iteration 21900, loss = 0.0016753
I0730 07:30:59.203474 17816 solver.cpp:244]     Train net output #0: loss = 0.00167529 (* 1 = 0.00167529 loss)
I0730 07:30:59.203495 17816 sgd_solver.cpp:106] Iteration 21900, lr = 1e-11
I0730 07:32:30.613270 17816 solver.cpp:228] Iteration 21950, loss = 0.00793595
I0730 07:32:30.613436 17816 solver.cpp:244]     Train net output #0: loss = 0.00793594 (* 1 = 0.00793594 loss)
I0730 07:32:30.613461 17816 sgd_solver.cpp:106] Iteration 21950, lr = 1e-11
I0730 07:34:00.302680 17816 solver.cpp:337] Iteration 22000, Testing net (#0)
I0730 07:38:12.275390 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 07:38:12.275535 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 07:38:13.601949 17816 solver.cpp:228] Iteration 22000, loss = 0.00156356
I0730 07:38:13.602005 17816 solver.cpp:244]     Train net output #0: loss = 0.00156355 (* 1 = 0.00156355 loss)
I0730 07:38:13.602025 17816 sgd_solver.cpp:106] Iteration 22000, lr = 1e-11
I0730 07:39:45.083370 17816 solver.cpp:228] Iteration 22050, loss = 0.00329085
I0730 07:39:45.083590 17816 solver.cpp:244]     Train net output #0: loss = 0.00329084 (* 1 = 0.00329084 loss)
I0730 07:39:45.083613 17816 sgd_solver.cpp:106] Iteration 22050, lr = 1e-11
I0730 07:41:16.473809 17816 solver.cpp:228] Iteration 22100, loss = 0.0345942
I0730 07:41:16.493818 17816 solver.cpp:244]     Train net output #0: loss = 0.0345942 (* 1 = 0.0345942 loss)
I0730 07:41:16.493845 17816 sgd_solver.cpp:106] Iteration 22100, lr = 1e-11
I0730 07:42:47.962064 17816 solver.cpp:228] Iteration 22150, loss = 0.0033508
I0730 07:42:47.962254 17816 solver.cpp:244]     Train net output #0: loss = 0.00335081 (* 1 = 0.00335081 loss)
I0730 07:42:47.962275 17816 sgd_solver.cpp:106] Iteration 22150, lr = 1e-11
I0730 07:43:12.903761 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:43:46.998088 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:44:20.225230 17816 solver.cpp:228] Iteration 22200, loss = 0.00857472
I0730 07:44:20.225359 17816 solver.cpp:244]     Train net output #0: loss = 0.00857472 (* 1 = 0.00857472 loss)
I0730 07:44:20.225378 17816 sgd_solver.cpp:106] Iteration 22200, lr = 1e-11
I0730 07:44:20.998461 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:44:54.943122 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:45:29.636595 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:45:51.608930 17816 solver.cpp:228] Iteration 22250, loss = 0.010707
I0730 07:45:51.608976 17816 solver.cpp:244]     Train net output #0: loss = 0.010707 (* 1 = 0.010707 loss)
I0730 07:45:51.608994 17816 sgd_solver.cpp:106] Iteration 22250, lr = 1e-11
I0730 07:46:03.190739 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:46:36.571007 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:47:23.047672 17816 solver.cpp:228] Iteration 22300, loss = 0.00277423
I0730 07:47:23.047788 17816 solver.cpp:244]     Train net output #0: loss = 0.00277423 (* 1 = 0.00277423 loss)
I0730 07:47:23.047806 17816 sgd_solver.cpp:106] Iteration 22300, lr = 1e-11
I0730 07:47:43.362103 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:48:17.963827 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:48:55.441117 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:48:55.664978 17816 solver.cpp:228] Iteration 22350, loss = 0.00114587
I0730 07:48:55.665037 17816 solver.cpp:244]     Train net output #0: loss = 0.00114587 (* 1 = 0.00114587 loss)
I0730 07:48:55.665056 17816 sgd_solver.cpp:106] Iteration 22350, lr = 1e-11
I0730 07:49:29.994174 17823 blocking_queue.cpp:50] Waiting for data
I0730 07:50:29.268417 17816 solver.cpp:228] Iteration 22400, loss = 0.00658996
I0730 07:50:29.268563 17816 solver.cpp:244]     Train net output #0: loss = 0.00658996 (* 1 = 0.00658996 loss)
I0730 07:50:29.268585 17816 sgd_solver.cpp:106] Iteration 22400, lr = 1e-11
I0730 07:52:00.583670 17816 solver.cpp:228] Iteration 22450, loss = 0.00202252
I0730 07:52:00.583844 17816 solver.cpp:244]     Train net output #0: loss = 0.00202252 (* 1 = 0.00202252 loss)
I0730 07:52:00.583866 17816 sgd_solver.cpp:106] Iteration 22450, lr = 1e-11
I0730 07:53:31.995595 17816 solver.cpp:228] Iteration 22500, loss = 0.00142336
I0730 07:53:31.995750 17816 solver.cpp:244]     Train net output #0: loss = 0.00142335 (* 1 = 0.00142335 loss)
I0730 07:53:31.995779 17816 sgd_solver.cpp:106] Iteration 22500, lr = 1e-12
I0730 07:55:03.452955 17816 solver.cpp:228] Iteration 22550, loss = 0.00130283
I0730 07:55:03.453091 17816 solver.cpp:244]     Train net output #0: loss = 0.00130283 (* 1 = 0.00130283 loss)
I0730 07:55:03.453110 17816 sgd_solver.cpp:106] Iteration 22550, lr = 1e-12
I0730 07:56:34.794371 17816 solver.cpp:228] Iteration 22600, loss = 0.00100616
I0730 07:56:34.794541 17816 solver.cpp:244]     Train net output #0: loss = 0.00100615 (* 1 = 0.00100615 loss)
I0730 07:56:34.794561 17816 sgd_solver.cpp:106] Iteration 22600, lr = 1e-12
I0730 07:58:06.288689 17816 solver.cpp:228] Iteration 22650, loss = 0.00496573
I0730 07:58:06.288902 17816 solver.cpp:244]     Train net output #0: loss = 0.00496573 (* 1 = 0.00496573 loss)
I0730 07:58:06.288925 17816 sgd_solver.cpp:106] Iteration 22650, lr = 1e-12
I0730 07:59:37.774957 17816 solver.cpp:228] Iteration 22700, loss = 0.00125111
I0730 07:59:37.799818 17816 solver.cpp:244]     Train net output #0: loss = 0.00125111 (* 1 = 0.00125111 loss)
I0730 07:59:37.799890 17816 sgd_solver.cpp:106] Iteration 22700, lr = 1e-12
I0730 08:01:09.209307 17816 solver.cpp:228] Iteration 22750, loss = 0.00360329
I0730 08:01:09.209501 17816 solver.cpp:244]     Train net output #0: loss = 0.00360328 (* 1 = 0.00360328 loss)
I0730 08:01:09.209527 17816 sgd_solver.cpp:106] Iteration 22750, lr = 1e-12
I0730 08:02:40.749130 17816 solver.cpp:228] Iteration 22800, loss = 0.000794347
I0730 08:02:40.749264 17816 solver.cpp:244]     Train net output #0: loss = 0.00079434 (* 1 = 0.00079434 loss)
I0730 08:02:40.749284 17816 sgd_solver.cpp:106] Iteration 22800, lr = 1e-12
I0730 08:04:12.152426 17816 solver.cpp:228] Iteration 22850, loss = 0.000679796
I0730 08:04:12.152592 17816 solver.cpp:244]     Train net output #0: loss = 0.000679789 (* 1 = 0.000679789 loss)
I0730 08:04:12.152613 17816 sgd_solver.cpp:106] Iteration 22850, lr = 1e-12
I0730 08:05:43.548354 17816 solver.cpp:228] Iteration 22900, loss = 0.00591755
I0730 08:05:43.548527 17816 solver.cpp:244]     Train net output #0: loss = 0.00591754 (* 1 = 0.00591754 loss)
I0730 08:05:43.548560 17816 sgd_solver.cpp:106] Iteration 22900, lr = 1e-12
I0730 08:07:14.922083 17816 solver.cpp:228] Iteration 22950, loss = 0.00116848
I0730 08:07:14.922260 17816 solver.cpp:244]     Train net output #0: loss = 0.00116847 (* 1 = 0.00116847 loss)
I0730 08:07:14.922288 17816 sgd_solver.cpp:106] Iteration 22950, lr = 1e-12
I0730 08:08:44.478142 17816 solver.cpp:337] Iteration 23000, Testing net (#0)
I0730 08:12:59.584266 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 08:12:59.584394 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 08:13:00.929049 17816 solver.cpp:228] Iteration 23000, loss = 0.00406373
I0730 08:13:00.929100 17816 solver.cpp:244]     Train net output #0: loss = 0.00406372 (* 1 = 0.00406372 loss)
I0730 08:13:00.929116 17816 sgd_solver.cpp:106] Iteration 23000, lr = 1e-12
I0730 08:14:34.284550 17816 solver.cpp:228] Iteration 23050, loss = 0.0216095
I0730 08:14:34.284684 17816 solver.cpp:244]     Train net output #0: loss = 0.0216095 (* 1 = 0.0216095 loss)
I0730 08:14:34.284703 17816 sgd_solver.cpp:106] Iteration 23050, lr = 1e-12
I0730 08:16:07.519336 17816 solver.cpp:228] Iteration 23100, loss = 0.00571374
I0730 08:16:07.519464 17816 solver.cpp:244]     Train net output #0: loss = 0.00571374 (* 1 = 0.00571374 loss)
I0730 08:16:07.519482 17816 sgd_solver.cpp:106] Iteration 23100, lr = 1e-12
I0730 08:17:40.723737 17816 solver.cpp:228] Iteration 23150, loss = 0.000496834
I0730 08:17:40.723950 17816 solver.cpp:244]     Train net output #0: loss = 0.000496836 (* 1 = 0.000496836 loss)
I0730 08:17:40.723984 17816 sgd_solver.cpp:106] Iteration 23150, lr = 1e-12
I0730 08:19:13.907788 17816 solver.cpp:228] Iteration 23200, loss = 0.00114092
I0730 08:19:13.907920 17816 solver.cpp:244]     Train net output #0: loss = 0.00114092 (* 1 = 0.00114092 loss)
I0730 08:19:13.907939 17816 sgd_solver.cpp:106] Iteration 23200, lr = 1e-12
I0730 08:20:47.032027 17816 solver.cpp:228] Iteration 23250, loss = 0.000276631
I0730 08:20:47.032193 17816 solver.cpp:244]     Train net output #0: loss = 0.000276641 (* 1 = 0.000276641 loss)
I0730 08:20:47.032212 17816 sgd_solver.cpp:106] Iteration 23250, lr = 1e-12
I0730 08:22:20.343374 17816 solver.cpp:228] Iteration 23300, loss = 0.00742058
I0730 08:22:20.343564 17816 solver.cpp:244]     Train net output #0: loss = 0.00742059 (* 1 = 0.00742059 loss)
I0730 08:22:20.343606 17816 sgd_solver.cpp:106] Iteration 23300, lr = 1e-12
I0730 08:23:53.550505 17816 solver.cpp:228] Iteration 23350, loss = 0.00185066
I0730 08:23:53.550628 17816 solver.cpp:244]     Train net output #0: loss = 0.00185067 (* 1 = 0.00185067 loss)
I0730 08:23:53.550647 17816 sgd_solver.cpp:106] Iteration 23350, lr = 1e-12
I0730 08:25:26.814648 17816 solver.cpp:228] Iteration 23400, loss = 0.000686147
I0730 08:25:26.814813 17816 solver.cpp:244]     Train net output #0: loss = 0.000686162 (* 1 = 0.000686162 loss)
I0730 08:25:26.814833 17816 sgd_solver.cpp:106] Iteration 23400, lr = 1e-12
I0730 08:26:59.672778 17816 solver.cpp:228] Iteration 23450, loss = 0.00630308
I0730 08:26:59.672943 17816 solver.cpp:244]     Train net output #0: loss = 0.00630309 (* 1 = 0.00630309 loss)
I0730 08:26:59.672963 17816 sgd_solver.cpp:106] Iteration 23450, lr = 1e-12
I0730 08:28:31.246660 17816 solver.cpp:228] Iteration 23500, loss = 0.0082066
I0730 08:28:31.246788 17816 solver.cpp:244]     Train net output #0: loss = 0.00820663 (* 1 = 0.00820663 loss)
I0730 08:28:31.246806 17816 sgd_solver.cpp:106] Iteration 23500, lr = 1e-12
I0730 08:30:02.497740 17816 solver.cpp:228] Iteration 23550, loss = 0.000389046
I0730 08:30:02.497869 17816 solver.cpp:244]     Train net output #0: loss = 0.000389063 (* 1 = 0.000389063 loss)
I0730 08:30:02.497887 17816 sgd_solver.cpp:106] Iteration 23550, lr = 1e-12
I0730 08:31:33.818239 17816 solver.cpp:228] Iteration 23600, loss = 0.00159439
I0730 08:31:33.818370 17816 solver.cpp:244]     Train net output #0: loss = 0.0015944 (* 1 = 0.0015944 loss)
I0730 08:31:33.818388 17816 sgd_solver.cpp:106] Iteration 23600, lr = 1e-12
I0730 08:33:05.171890 17816 solver.cpp:228] Iteration 23650, loss = 0.00101429
I0730 08:33:05.172054 17816 solver.cpp:244]     Train net output #0: loss = 0.00101431 (* 1 = 0.00101431 loss)
I0730 08:33:05.172072 17816 sgd_solver.cpp:106] Iteration 23650, lr = 1e-12
I0730 08:34:36.672785 17816 solver.cpp:228] Iteration 23700, loss = 0.000439769
I0730 08:34:36.672919 17816 solver.cpp:244]     Train net output #0: loss = 0.000439785 (* 1 = 0.000439785 loss)
I0730 08:34:36.672936 17816 sgd_solver.cpp:106] Iteration 23700, lr = 1e-12
I0730 08:36:08.065472 17816 solver.cpp:228] Iteration 23750, loss = 0.0051711
I0730 08:36:08.065626 17816 solver.cpp:244]     Train net output #0: loss = 0.00517111 (* 1 = 0.00517111 loss)
I0730 08:36:08.065645 17816 sgd_solver.cpp:106] Iteration 23750, lr = 1e-12
I0730 08:37:40.374771 17816 solver.cpp:228] Iteration 23800, loss = 0.00704026
I0730 08:37:40.374898 17816 solver.cpp:244]     Train net output #0: loss = 0.00704027 (* 1 = 0.00704027 loss)
I0730 08:37:40.374917 17816 sgd_solver.cpp:106] Iteration 23800, lr = 1e-12
I0730 08:39:13.633148 17816 solver.cpp:228] Iteration 23850, loss = 0.000727917
I0730 08:39:13.633291 17816 solver.cpp:244]     Train net output #0: loss = 0.000727933 (* 1 = 0.000727933 loss)
I0730 08:39:13.633318 17816 sgd_solver.cpp:106] Iteration 23850, lr = 1e-12
I0730 08:40:46.964784 17816 solver.cpp:228] Iteration 23900, loss = 0.00149625
I0730 08:40:46.964913 17816 solver.cpp:244]     Train net output #0: loss = 0.00149627 (* 1 = 0.00149627 loss)
I0730 08:40:46.964932 17816 sgd_solver.cpp:106] Iteration 23900, lr = 1e-12
I0730 08:42:20.126920 17816 solver.cpp:228] Iteration 23950, loss = 0.015009
I0730 08:42:20.127043 17816 solver.cpp:244]     Train net output #0: loss = 0.015009 (* 1 = 0.015009 loss)
I0730 08:42:20.127061 17816 sgd_solver.cpp:106] Iteration 23950, lr = 1e-12
I0730 08:43:51.484797 17816 solver.cpp:337] Iteration 24000, Testing net (#0)
I0730 08:48:08.709010 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 08:48:08.709175 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 08:48:10.050763 17816 solver.cpp:228] Iteration 24000, loss = 0.00311996
I0730 08:48:10.050815 17816 solver.cpp:244]     Train net output #0: loss = 0.00311999 (* 1 = 0.00311999 loss)
I0730 08:48:10.050832 17816 sgd_solver.cpp:106] Iteration 24000, lr = 1e-12
I0730 08:49:43.066388 17816 solver.cpp:228] Iteration 24050, loss = 0.00436771
I0730 08:49:43.066522 17816 solver.cpp:244]     Train net output #0: loss = 0.00436774 (* 1 = 0.00436774 loss)
I0730 08:49:43.066541 17816 sgd_solver.cpp:106] Iteration 24050, lr = 1e-12
I0730 08:51:16.342530 17816 solver.cpp:228] Iteration 24100, loss = 0.00504407
I0730 08:51:16.342670 17816 solver.cpp:244]     Train net output #0: loss = 0.0050441 (* 1 = 0.0050441 loss)
I0730 08:51:16.342689 17816 sgd_solver.cpp:106] Iteration 24100, lr = 1e-12
I0730 08:52:49.717960 17816 solver.cpp:228] Iteration 24150, loss = 0.0013034
I0730 08:52:49.730072 17816 solver.cpp:244]     Train net output #0: loss = 0.00130343 (* 1 = 0.00130343 loss)
I0730 08:52:49.730142 17816 sgd_solver.cpp:106] Iteration 24150, lr = 1e-12
I0730 08:54:23.061282 17816 solver.cpp:228] Iteration 24200, loss = 0.00360089
I0730 08:54:23.061434 17816 solver.cpp:244]     Train net output #0: loss = 0.00360092 (* 1 = 0.00360092 loss)
I0730 08:54:23.061456 17816 sgd_solver.cpp:106] Iteration 24200, lr = 1e-12
I0730 08:55:56.315575 17816 solver.cpp:228] Iteration 24250, loss = 0.00258916
I0730 08:55:56.315765 17816 solver.cpp:244]     Train net output #0: loss = 0.00258919 (* 1 = 0.00258919 loss)
I0730 08:55:56.315788 17816 sgd_solver.cpp:106] Iteration 24250, lr = 1e-12
I0730 08:57:28.033740 17816 solver.cpp:228] Iteration 24300, loss = 0.00823321
I0730 08:57:28.033905 17816 solver.cpp:244]     Train net output #0: loss = 0.00823324 (* 1 = 0.00823324 loss)
I0730 08:57:28.033924 17816 sgd_solver.cpp:106] Iteration 24300, lr = 1e-12
I0730 08:58:59.404978 17816 solver.cpp:228] Iteration 24350, loss = 0.000667177
I0730 08:58:59.405169 17816 solver.cpp:244]     Train net output #0: loss = 0.000667203 (* 1 = 0.000667203 loss)
I0730 08:58:59.405192 17816 sgd_solver.cpp:106] Iteration 24350, lr = 1e-12
I0730 09:00:30.700525 17816 solver.cpp:228] Iteration 24400, loss = 0.00138503
I0730 09:00:30.700680 17816 solver.cpp:244]     Train net output #0: loss = 0.00138506 (* 1 = 0.00138506 loss)
I0730 09:00:30.700700 17816 sgd_solver.cpp:106] Iteration 24400, lr = 1e-12
I0730 09:02:02.022949 17816 solver.cpp:228] Iteration 24450, loss = 0.000589362
I0730 09:02:02.023092 17816 solver.cpp:244]     Train net output #0: loss = 0.000589394 (* 1 = 0.000589394 loss)
I0730 09:02:02.023111 17816 sgd_solver.cpp:106] Iteration 24450, lr = 1e-12
I0730 09:03:33.565560 17816 solver.cpp:228] Iteration 24500, loss = 0.00797582
I0730 09:03:33.565693 17816 solver.cpp:244]     Train net output #0: loss = 0.00797585 (* 1 = 0.00797585 loss)
I0730 09:03:33.565712 17816 sgd_solver.cpp:106] Iteration 24500, lr = 1e-12
I0730 09:05:05.025629 17816 solver.cpp:228] Iteration 24550, loss = 0.0112224
I0730 09:05:05.025791 17816 solver.cpp:244]     Train net output #0: loss = 0.0112224 (* 1 = 0.0112224 loss)
I0730 09:05:05.025812 17816 sgd_solver.cpp:106] Iteration 24550, lr = 1e-12
I0730 09:06:36.508009 17816 solver.cpp:228] Iteration 24600, loss = 0.00104159
I0730 09:06:36.508199 17816 solver.cpp:244]     Train net output #0: loss = 0.00104162 (* 1 = 0.00104162 loss)
I0730 09:06:36.508220 17816 sgd_solver.cpp:106] Iteration 24600, lr = 1e-12
I0730 09:08:07.955634 17816 solver.cpp:228] Iteration 24650, loss = 0.00430567
I0730 09:08:07.955796 17816 solver.cpp:244]     Train net output #0: loss = 0.00430571 (* 1 = 0.00430571 loss)
I0730 09:08:07.955814 17816 sgd_solver.cpp:106] Iteration 24650, lr = 1e-12
I0730 09:09:39.400233 17816 solver.cpp:228] Iteration 24700, loss = 0.00226398
I0730 09:09:39.400368 17816 solver.cpp:244]     Train net output #0: loss = 0.00226402 (* 1 = 0.00226402 loss)
I0730 09:09:39.400389 17816 sgd_solver.cpp:106] Iteration 24700, lr = 1e-12
I0730 09:11:10.799931 17816 solver.cpp:228] Iteration 24750, loss = 0.00437688
I0730 09:11:10.800091 17816 solver.cpp:244]     Train net output #0: loss = 0.00437692 (* 1 = 0.00437692 loss)
I0730 09:11:10.800109 17816 sgd_solver.cpp:106] Iteration 24750, lr = 1e-12
I0730 09:12:42.180822 17816 solver.cpp:228] Iteration 24800, loss = 0.000314584
I0730 09:12:42.180975 17816 solver.cpp:244]     Train net output #0: loss = 0.000314617 (* 1 = 0.000314617 loss)
I0730 09:12:42.180994 17816 sgd_solver.cpp:106] Iteration 24800, lr = 1e-12
I0730 09:14:13.593147 17816 solver.cpp:228] Iteration 24850, loss = 0.00816778
I0730 09:14:13.593277 17816 solver.cpp:244]     Train net output #0: loss = 0.00816781 (* 1 = 0.00816781 loss)
I0730 09:14:13.593296 17816 sgd_solver.cpp:106] Iteration 24850, lr = 1e-12
I0730 09:15:45.075933 17816 solver.cpp:228] Iteration 24900, loss = 0.000728525
I0730 09:15:45.076104 17816 solver.cpp:244]     Train net output #0: loss = 0.000728553 (* 1 = 0.000728553 loss)
I0730 09:15:45.076128 17816 sgd_solver.cpp:106] Iteration 24900, lr = 1e-12
I0730 09:17:16.282045 17816 solver.cpp:228] Iteration 24950, loss = 0.00410513
I0730 09:17:16.312216 17816 solver.cpp:244]     Train net output #0: loss = 0.00410516 (* 1 = 0.00410516 loss)
I0730 09:17:16.312242 17816 sgd_solver.cpp:106] Iteration 24950, lr = 1e-12
I0730 09:18:45.785821 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_25000.caffemodel
I0730 09:18:50.368482 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_25000.solverstate
I0730 09:18:53.532795 17816 solver.cpp:337] Iteration 25000, Testing net (#0)
I0730 09:23:05.640524 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 09:23:05.640698 17816 solver.cpp:404]     Test net output #1: loss = 0.0859028 (* 1 = 0.0859028 loss)
I0730 09:23:06.981560 17816 solver.cpp:228] Iteration 25000, loss = 0.00109812
I0730 09:23:06.981611 17816 solver.cpp:244]     Train net output #0: loss = 0.00109815 (* 1 = 0.00109815 loss)
I0730 09:23:06.981629 17816 sgd_solver.cpp:106] Iteration 25000, lr = 1e-13
I0730 09:24:40.064594 17816 solver.cpp:228] Iteration 25050, loss = 0.000817576
I0730 09:24:40.064723 17816 solver.cpp:244]     Train net output #0: loss = 0.000817608 (* 1 = 0.000817608 loss)
I0730 09:24:40.064740 17816 sgd_solver.cpp:106] Iteration 25050, lr = 1e-13
I0730 09:26:13.501225 17816 solver.cpp:228] Iteration 25100, loss = 0.00153183
I0730 09:26:13.501355 17816 solver.cpp:244]     Train net output #0: loss = 0.00153187 (* 1 = 0.00153187 loss)
I0730 09:26:13.501374 17816 sgd_solver.cpp:106] Iteration 25100, lr = 1e-13
I0730 09:27:46.764184 17816 solver.cpp:228] Iteration 25150, loss = 0.00376876
I0730 09:27:46.764312 17816 solver.cpp:244]     Train net output #0: loss = 0.00376879 (* 1 = 0.00376879 loss)
I0730 09:27:46.764331 17816 sgd_solver.cpp:106] Iteration 25150, lr = 1e-13
I0730 09:29:20.001158 17816 solver.cpp:228] Iteration 25200, loss = 0.00311647
I0730 09:29:20.001287 17816 solver.cpp:244]     Train net output #0: loss = 0.00311651 (* 1 = 0.00311651 loss)
I0730 09:29:20.001307 17816 sgd_solver.cpp:106] Iteration 25200, lr = 1e-13
I0730 09:30:51.982220 17816 solver.cpp:228] Iteration 25250, loss = 0.000787474
I0730 09:30:51.982347 17816 solver.cpp:244]     Train net output #0: loss = 0.000787507 (* 1 = 0.000787507 loss)
I0730 09:30:51.982367 17816 sgd_solver.cpp:106] Iteration 25250, lr = 1e-13
I0730 09:32:23.327565 17816 solver.cpp:228] Iteration 25300, loss = 0.00210741
I0730 09:32:23.327725 17816 solver.cpp:244]     Train net output #0: loss = 0.00210744 (* 1 = 0.00210744 loss)
I0730 09:32:23.327744 17816 sgd_solver.cpp:106] Iteration 25300, lr = 1e-13
I0730 09:33:54.795931 17816 solver.cpp:228] Iteration 25350, loss = 0.0036223
I0730 09:33:54.796092 17816 solver.cpp:244]     Train net output #0: loss = 0.00362234 (* 1 = 0.00362234 loss)
I0730 09:33:54.796110 17816 sgd_solver.cpp:106] Iteration 25350, lr = 1e-13
I0730 09:35:26.087817 17816 solver.cpp:228] Iteration 25400, loss = 0.00173302
I0730 09:35:26.087945 17816 solver.cpp:244]     Train net output #0: loss = 0.00173305 (* 1 = 0.00173305 loss)
I0730 09:35:26.087963 17816 sgd_solver.cpp:106] Iteration 25400, lr = 1e-13
I0730 09:36:57.650861 17816 solver.cpp:228] Iteration 25450, loss = 0.000477677
I0730 09:36:57.651021 17816 solver.cpp:244]     Train net output #0: loss = 0.000477711 (* 1 = 0.000477711 loss)
I0730 09:36:57.651039 17816 sgd_solver.cpp:106] Iteration 25450, lr = 1e-13
I0730 09:38:29.075815 17816 solver.cpp:228] Iteration 25500, loss = 0.00682677
I0730 09:38:29.076014 17816 solver.cpp:244]     Train net output #0: loss = 0.00682681 (* 1 = 0.00682681 loss)
I0730 09:38:29.076033 17816 sgd_solver.cpp:106] Iteration 25500, lr = 1e-13
I0730 09:40:00.463449 17816 solver.cpp:228] Iteration 25550, loss = 0.000194594
I0730 09:40:00.463574 17816 solver.cpp:244]     Train net output #0: loss = 0.000194636 (* 1 = 0.000194636 loss)
I0730 09:40:00.463593 17816 sgd_solver.cpp:106] Iteration 25550, lr = 1e-13
I0730 09:41:31.869379 17816 solver.cpp:228] Iteration 25600, loss = 0.0055751
I0730 09:41:31.869539 17816 solver.cpp:244]     Train net output #0: loss = 0.00557515 (* 1 = 0.00557515 loss)
I0730 09:41:31.869560 17816 sgd_solver.cpp:106] Iteration 25600, lr = 1e-13
I0730 09:43:03.384452 17816 solver.cpp:228] Iteration 25650, loss = 7.27791e-05
I0730 09:43:03.384582 17816 solver.cpp:244]     Train net output #0: loss = 7.2828e-05 (* 1 = 7.2828e-05 loss)
I0730 09:43:03.384600 17816 sgd_solver.cpp:106] Iteration 25650, lr = 1e-13
I0730 09:44:34.649314 17816 solver.cpp:228] Iteration 25700, loss = 0.010957
I0730 09:44:34.649492 17816 solver.cpp:244]     Train net output #0: loss = 0.010957 (* 1 = 0.010957 loss)
I0730 09:44:34.649512 17816 sgd_solver.cpp:106] Iteration 25700, lr = 1e-13
I0730 09:46:05.938756 17816 solver.cpp:228] Iteration 25750, loss = 0.000245753
I0730 09:46:05.938886 17816 solver.cpp:244]     Train net output #0: loss = 0.000245801 (* 1 = 0.000245801 loss)
I0730 09:46:05.938905 17816 sgd_solver.cpp:106] Iteration 25750, lr = 1e-13
I0730 09:47:37.301897 17816 solver.cpp:228] Iteration 25800, loss = 0.0103454
I0730 09:47:37.302031 17816 solver.cpp:244]     Train net output #0: loss = 0.0103454 (* 1 = 0.0103454 loss)
I0730 09:47:37.302052 17816 sgd_solver.cpp:106] Iteration 25800, lr = 1e-13
I0730 09:49:08.455768 17816 solver.cpp:228] Iteration 25850, loss = 0.057463
I0730 09:49:08.455899 17816 solver.cpp:244]     Train net output #0: loss = 0.0574631 (* 1 = 0.0574631 loss)
I0730 09:49:08.455917 17816 sgd_solver.cpp:106] Iteration 25850, lr = 1e-13
I0730 09:50:39.932128 17816 solver.cpp:228] Iteration 25900, loss = 0.00103033
I0730 09:50:39.932260 17816 solver.cpp:244]     Train net output #0: loss = 0.00103038 (* 1 = 0.00103038 loss)
I0730 09:50:39.932279 17816 sgd_solver.cpp:106] Iteration 25900, lr = 1e-13
I0730 09:52:11.291555 17816 solver.cpp:228] Iteration 25950, loss = 0.000326089
I0730 09:52:11.291690 17816 solver.cpp:244]     Train net output #0: loss = 0.000326139 (* 1 = 0.000326139 loss)
I0730 09:52:11.291709 17816 sgd_solver.cpp:106] Iteration 25950, lr = 1e-13
I0730 09:53:40.959379 17816 solver.cpp:337] Iteration 26000, Testing net (#0)
I0730 09:57:52.941862 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972683
I0730 09:57:52.942028 17816 solver.cpp:404]     Test net output #1: loss = 0.085863 (* 1 = 0.085863 loss)
I0730 09:57:54.282344 17816 solver.cpp:228] Iteration 26000, loss = 0.00135913
I0730 09:57:54.282399 17816 solver.cpp:244]     Train net output #0: loss = 0.00135918 (* 1 = 0.00135918 loss)
I0730 09:57:54.282418 17816 sgd_solver.cpp:106] Iteration 26000, lr = 1e-13
I0730 09:59:27.427739 17816 solver.cpp:228] Iteration 26050, loss = 0.00759871
I0730 09:59:27.427868 17816 solver.cpp:244]     Train net output #0: loss = 0.00759876 (* 1 = 0.00759876 loss)
I0730 09:59:27.427888 17816 sgd_solver.cpp:106] Iteration 26050, lr = 1e-13
I0730 10:01:00.653264 17816 solver.cpp:228] Iteration 26100, loss = 0.00298653
I0730 10:01:00.653383 17816 solver.cpp:244]     Train net output #0: loss = 0.00298659 (* 1 = 0.00298659 loss)
I0730 10:01:00.653403 17816 sgd_solver.cpp:106] Iteration 26100, lr = 1e-13
I0730 10:02:33.790639 17816 solver.cpp:228] Iteration 26150, loss = 0.00450678
I0730 10:02:33.790801 17816 solver.cpp:244]     Train net output #0: loss = 0.00450683 (* 1 = 0.00450683 loss)
I0730 10:02:33.790819 17816 sgd_solver.cpp:106] Iteration 26150, lr = 1e-13
I0730 10:04:06.937973 17816 solver.cpp:228] Iteration 26200, loss = 0.00337518
I0730 10:04:06.938127 17816 solver.cpp:244]     Train net output #0: loss = 0.00337524 (* 1 = 0.00337524 loss)
I0730 10:04:06.938146 17816 sgd_solver.cpp:106] Iteration 26200, lr = 1e-13
I0730 10:05:40.183140 17816 solver.cpp:228] Iteration 26250, loss = 0.0111394
I0730 10:05:40.183300 17816 solver.cpp:244]     Train net output #0: loss = 0.0111394 (* 1 = 0.0111394 loss)
I0730 10:05:40.183320 17816 sgd_solver.cpp:106] Iteration 26250, lr = 1e-13
I0730 10:07:13.538136 17816 solver.cpp:228] Iteration 26300, loss = 0.00133024
I0730 10:07:13.538290 17816 solver.cpp:244]     Train net output #0: loss = 0.0013303 (* 1 = 0.0013303 loss)
I0730 10:07:13.538307 17816 sgd_solver.cpp:106] Iteration 26300, lr = 1e-13
I0730 10:08:46.850219 17816 solver.cpp:228] Iteration 26350, loss = 0.00441931
I0730 10:08:46.850347 17816 solver.cpp:244]     Train net output #0: loss = 0.00441936 (* 1 = 0.00441936 loss)
I0730 10:08:46.850364 17816 sgd_solver.cpp:106] Iteration 26350, lr = 1e-13
I0730 10:10:20.039672 17816 solver.cpp:228] Iteration 26400, loss = 0.00119548
I0730 10:10:20.039799 17816 solver.cpp:244]     Train net output #0: loss = 0.00119553 (* 1 = 0.00119553 loss)
I0730 10:10:20.039818 17816 sgd_solver.cpp:106] Iteration 26400, lr = 1e-13
I0730 10:11:53.254988 17816 solver.cpp:228] Iteration 26450, loss = 0.00625386
I0730 10:11:53.255118 17816 solver.cpp:244]     Train net output #0: loss = 0.00625391 (* 1 = 0.00625391 loss)
I0730 10:11:53.255137 17816 sgd_solver.cpp:106] Iteration 26450, lr = 1e-13
I0730 10:13:26.469856 17816 solver.cpp:228] Iteration 26500, loss = 0.00121008
I0730 10:13:26.470013 17816 solver.cpp:244]     Train net output #0: loss = 0.00121013 (* 1 = 0.00121013 loss)
I0730 10:13:26.470046 17816 sgd_solver.cpp:106] Iteration 26500, lr = 1e-13
I0730 10:14:59.742532 17816 solver.cpp:228] Iteration 26550, loss = 0.00388258
I0730 10:14:59.742682 17816 solver.cpp:244]     Train net output #0: loss = 0.00388263 (* 1 = 0.00388263 loss)
I0730 10:14:59.742702 17816 sgd_solver.cpp:106] Iteration 26550, lr = 1e-13
I0730 10:16:33.084244 17816 solver.cpp:228] Iteration 26600, loss = 0.000559999
I0730 10:16:33.084403 17816 solver.cpp:244]     Train net output #0: loss = 0.000560048 (* 1 = 0.000560048 loss)
I0730 10:16:33.084429 17816 sgd_solver.cpp:106] Iteration 26600, lr = 1e-13
I0730 10:18:06.226276 17816 solver.cpp:228] Iteration 26650, loss = 0.00149996
I0730 10:18:06.226438 17816 solver.cpp:244]     Train net output #0: loss = 0.00150001 (* 1 = 0.00150001 loss)
I0730 10:18:06.226455 17816 sgd_solver.cpp:106] Iteration 26650, lr = 1e-13
I0730 10:19:39.438382 17816 solver.cpp:228] Iteration 26700, loss = 0.010569
I0730 10:19:39.438503 17816 solver.cpp:244]     Train net output #0: loss = 0.0105691 (* 1 = 0.0105691 loss)
I0730 10:19:39.438522 17816 sgd_solver.cpp:106] Iteration 26700, lr = 1e-13
I0730 10:21:12.574744 17816 solver.cpp:228] Iteration 26750, loss = 0.0182253
I0730 10:21:12.574874 17816 solver.cpp:244]     Train net output #0: loss = 0.0182253 (* 1 = 0.0182253 loss)
I0730 10:21:12.574892 17816 sgd_solver.cpp:106] Iteration 26750, lr = 1e-13
I0730 10:22:45.821483 17816 solver.cpp:228] Iteration 26800, loss = 0.000341323
I0730 10:22:45.821610 17816 solver.cpp:244]     Train net output #0: loss = 0.000341372 (* 1 = 0.000341372 loss)
I0730 10:22:45.821630 17816 sgd_solver.cpp:106] Iteration 26800, lr = 1e-13
I0730 10:24:19.032465 17816 solver.cpp:228] Iteration 26850, loss = 0.00035455
I0730 10:24:19.032656 17816 solver.cpp:244]     Train net output #0: loss = 0.0003546 (* 1 = 0.0003546 loss)
I0730 10:24:19.032675 17816 sgd_solver.cpp:106] Iteration 26850, lr = 1e-13
I0730 10:25:52.063132 17816 solver.cpp:228] Iteration 26900, loss = 0.000416129
I0730 10:25:52.063263 17816 solver.cpp:244]     Train net output #0: loss = 0.000416178 (* 1 = 0.000416178 loss)
I0730 10:25:52.063282 17816 sgd_solver.cpp:106] Iteration 26900, lr = 1e-13
I0730 10:27:25.192827 17816 solver.cpp:228] Iteration 26950, loss = 0.00305829
I0730 10:27:25.192946 17816 solver.cpp:244]     Train net output #0: loss = 0.00305834 (* 1 = 0.00305834 loss)
I0730 10:27:25.192965 17816 sgd_solver.cpp:106] Iteration 26950, lr = 1e-13
I0730 10:28:56.452867 17816 solver.cpp:337] Iteration 27000, Testing net (#0)
I0730 10:33:14.544903 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 10:33:14.545033 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 10:33:15.885846 17816 solver.cpp:228] Iteration 27000, loss = 0.00454073
I0730 10:33:15.885897 17816 solver.cpp:244]     Train net output #0: loss = 0.00454078 (* 1 = 0.00454078 loss)
I0730 10:33:15.885915 17816 sgd_solver.cpp:106] Iteration 27000, lr = 1e-13
I0730 10:34:48.917263 17816 solver.cpp:228] Iteration 27050, loss = 0.00153707
I0730 10:34:48.917384 17816 solver.cpp:244]     Train net output #0: loss = 0.00153712 (* 1 = 0.00153712 loss)
I0730 10:34:48.917403 17816 sgd_solver.cpp:106] Iteration 27050, lr = 1e-13
I0730 10:36:22.033254 17816 solver.cpp:228] Iteration 27100, loss = 0.000822118
I0730 10:36:22.033404 17816 solver.cpp:244]     Train net output #0: loss = 0.000822173 (* 1 = 0.000822173 loss)
I0730 10:36:22.033423 17816 sgd_solver.cpp:106] Iteration 27100, lr = 1e-13
I0730 10:37:55.326069 17816 solver.cpp:228] Iteration 27150, loss = 0.00747228
I0730 10:37:55.326197 17816 solver.cpp:244]     Train net output #0: loss = 0.00747234 (* 1 = 0.00747234 loss)
I0730 10:37:55.326216 17816 sgd_solver.cpp:106] Iteration 27150, lr = 1e-13
I0730 10:39:28.445181 17816 solver.cpp:228] Iteration 27200, loss = 0.000393722
I0730 10:39:28.445317 17816 solver.cpp:244]     Train net output #0: loss = 0.000393782 (* 1 = 0.000393782 loss)
I0730 10:39:28.445335 17816 sgd_solver.cpp:106] Iteration 27200, lr = 1e-13
I0730 10:41:01.347203 17816 solver.cpp:228] Iteration 27250, loss = 0.00185217
I0730 10:41:01.347333 17816 solver.cpp:244]     Train net output #0: loss = 0.00185223 (* 1 = 0.00185223 loss)
I0730 10:41:01.347352 17816 sgd_solver.cpp:106] Iteration 27250, lr = 1e-13
I0730 10:42:32.790402 17816 solver.cpp:228] Iteration 27300, loss = 0.000194211
I0730 10:42:32.790565 17816 solver.cpp:244]     Train net output #0: loss = 0.000194269 (* 1 = 0.000194269 loss)
I0730 10:42:32.790585 17816 sgd_solver.cpp:106] Iteration 27300, lr = 1e-13
I0730 10:44:04.333613 17816 solver.cpp:228] Iteration 27350, loss = 0.00384143
I0730 10:44:04.333745 17816 solver.cpp:244]     Train net output #0: loss = 0.00384149 (* 1 = 0.00384149 loss)
I0730 10:44:04.333763 17816 sgd_solver.cpp:106] Iteration 27350, lr = 1e-13
I0730 10:45:35.639886 17816 solver.cpp:228] Iteration 27400, loss = 0.021493
I0730 10:45:35.640096 17816 solver.cpp:244]     Train net output #0: loss = 0.021493 (* 1 = 0.021493 loss)
I0730 10:45:35.640139 17816 sgd_solver.cpp:106] Iteration 27400, lr = 1e-13
I0730 10:47:07.013510 17816 solver.cpp:228] Iteration 27450, loss = 0.00216109
I0730 10:47:07.013638 17816 solver.cpp:244]     Train net output #0: loss = 0.00216115 (* 1 = 0.00216115 loss)
I0730 10:47:07.013656 17816 sgd_solver.cpp:106] Iteration 27450, lr = 1e-13
I0730 10:48:38.490878 17816 solver.cpp:228] Iteration 27500, loss = 0.000308069
I0730 10:48:38.491016 17816 solver.cpp:244]     Train net output #0: loss = 0.000308128 (* 1 = 0.000308128 loss)
I0730 10:48:38.491037 17816 sgd_solver.cpp:106] Iteration 27500, lr = 1e-14
I0730 10:50:09.995908 17816 solver.cpp:228] Iteration 27550, loss = 0.00604798
I0730 10:50:09.996070 17816 solver.cpp:244]     Train net output #0: loss = 0.00604804 (* 1 = 0.00604804 loss)
I0730 10:50:09.996089 17816 sgd_solver.cpp:106] Iteration 27550, lr = 1e-14
I0730 10:51:41.531517 17816 solver.cpp:228] Iteration 27600, loss = 0.000863514
I0730 10:51:41.531698 17816 solver.cpp:244]     Train net output #0: loss = 0.000863574 (* 1 = 0.000863574 loss)
I0730 10:51:41.531719 17816 sgd_solver.cpp:106] Iteration 27600, lr = 1e-14
I0730 10:53:13.011837 17816 solver.cpp:228] Iteration 27650, loss = 0.00105664
I0730 10:53:13.011965 17816 solver.cpp:244]     Train net output #0: loss = 0.0010567 (* 1 = 0.0010567 loss)
I0730 10:53:13.011983 17816 sgd_solver.cpp:106] Iteration 27650, lr = 1e-14
I0730 10:54:44.509418 17816 solver.cpp:228] Iteration 27700, loss = 0.000497566
I0730 10:54:44.509549 17816 solver.cpp:244]     Train net output #0: loss = 0.000497626 (* 1 = 0.000497626 loss)
I0730 10:54:44.509567 17816 sgd_solver.cpp:106] Iteration 27700, lr = 1e-14
I0730 10:56:16.213630 17816 solver.cpp:228] Iteration 27750, loss = 0.00142206
I0730 10:56:16.213800 17816 solver.cpp:244]     Train net output #0: loss = 0.00142213 (* 1 = 0.00142213 loss)
I0730 10:56:16.213820 17816 sgd_solver.cpp:106] Iteration 27750, lr = 1e-14
I0730 10:57:49.325605 17816 solver.cpp:228] Iteration 27800, loss = 0.000641611
I0730 10:57:49.325767 17816 solver.cpp:244]     Train net output #0: loss = 0.000641674 (* 1 = 0.000641674 loss)
I0730 10:57:49.325785 17816 sgd_solver.cpp:106] Iteration 27800, lr = 1e-14
I0730 10:59:22.445613 17816 solver.cpp:228] Iteration 27850, loss = 0.00265565
I0730 10:59:22.445770 17816 solver.cpp:244]     Train net output #0: loss = 0.00265572 (* 1 = 0.00265572 loss)
I0730 10:59:22.445788 17816 sgd_solver.cpp:106] Iteration 27850, lr = 1e-14
I0730 11:00:55.615857 17816 solver.cpp:228] Iteration 27900, loss = 0.00636808
I0730 11:00:55.615979 17816 solver.cpp:244]     Train net output #0: loss = 0.00636813 (* 1 = 0.00636813 loss)
I0730 11:00:55.615998 17816 sgd_solver.cpp:106] Iteration 27900, lr = 1e-14
I0730 11:02:28.790356 17816 solver.cpp:228] Iteration 27950, loss = 0.000665884
I0730 11:02:28.790485 17816 solver.cpp:244]     Train net output #0: loss = 0.000665941 (* 1 = 0.000665941 loss)
I0730 11:02:28.790504 17816 sgd_solver.cpp:106] Iteration 27950, lr = 1e-14
I0730 11:04:00.160122 17816 solver.cpp:337] Iteration 28000, Testing net (#0)
I0730 11:08:17.620208 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 11:08:17.620327 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 11:08:18.961931 17816 solver.cpp:228] Iteration 28000, loss = 0.00457479
I0730 11:08:18.961983 17816 solver.cpp:244]     Train net output #0: loss = 0.00457485 (* 1 = 0.00457485 loss)
I0730 11:08:18.961999 17816 sgd_solver.cpp:106] Iteration 28000, lr = 1e-14
I0730 11:09:52.319717 17816 solver.cpp:228] Iteration 28050, loss = 0.0171773
I0730 11:09:52.319874 17816 solver.cpp:244]     Train net output #0: loss = 0.0171773 (* 1 = 0.0171773 loss)
I0730 11:09:52.319892 17816 sgd_solver.cpp:106] Iteration 28050, lr = 1e-14
I0730 11:11:25.376541 17816 solver.cpp:228] Iteration 28100, loss = 0.0104819
I0730 11:11:25.376664 17816 solver.cpp:244]     Train net output #0: loss = 0.010482 (* 1 = 0.010482 loss)
I0730 11:11:25.376682 17816 sgd_solver.cpp:106] Iteration 28100, lr = 1e-14
I0730 11:12:58.686563 17816 solver.cpp:228] Iteration 28150, loss = 0.000364948
I0730 11:12:58.686692 17816 solver.cpp:244]     Train net output #0: loss = 0.000365008 (* 1 = 0.000365008 loss)
I0730 11:12:58.686710 17816 sgd_solver.cpp:106] Iteration 28150, lr = 1e-14
I0730 11:14:32.050871 17816 solver.cpp:228] Iteration 28200, loss = 0.00278504
I0730 11:14:32.051002 17816 solver.cpp:244]     Train net output #0: loss = 0.0027851 (* 1 = 0.0027851 loss)
I0730 11:14:32.051021 17816 sgd_solver.cpp:106] Iteration 28200, lr = 1e-14
I0730 11:16:05.325608 17816 solver.cpp:228] Iteration 28250, loss = 0.000989966
I0730 11:16:05.325768 17816 solver.cpp:244]     Train net output #0: loss = 0.00099003 (* 1 = 0.00099003 loss)
I0730 11:16:05.325788 17816 sgd_solver.cpp:106] Iteration 28250, lr = 1e-14
I0730 11:17:38.650696 17816 solver.cpp:228] Iteration 28300, loss = 0.00259542
I0730 11:17:38.650877 17816 solver.cpp:244]     Train net output #0: loss = 0.00259548 (* 1 = 0.00259548 loss)
I0730 11:17:38.650897 17816 sgd_solver.cpp:106] Iteration 28300, lr = 1e-14
I0730 11:19:11.829782 17816 solver.cpp:228] Iteration 28350, loss = 0.010282
I0730 11:19:11.829906 17816 solver.cpp:244]     Train net output #0: loss = 0.0102821 (* 1 = 0.0102821 loss)
I0730 11:19:11.829924 17816 sgd_solver.cpp:106] Iteration 28350, lr = 1e-14
I0730 11:20:44.950875 17816 solver.cpp:228] Iteration 28400, loss = 0.00868281
I0730 11:20:44.951006 17816 solver.cpp:244]     Train net output #0: loss = 0.00868286 (* 1 = 0.00868286 loss)
I0730 11:20:44.951025 17816 sgd_solver.cpp:106] Iteration 28400, lr = 1e-14
I0730 11:22:18.115598 17816 solver.cpp:228] Iteration 28450, loss = 0.00499265
I0730 11:22:18.115792 17816 solver.cpp:244]     Train net output #0: loss = 0.00499271 (* 1 = 0.00499271 loss)
I0730 11:22:18.115810 17816 sgd_solver.cpp:106] Iteration 28450, lr = 1e-14
I0730 11:23:51.226148 17816 solver.cpp:228] Iteration 28500, loss = 0.000645582
I0730 11:23:51.226295 17816 solver.cpp:244]     Train net output #0: loss = 0.00064564 (* 1 = 0.00064564 loss)
I0730 11:23:51.226313 17816 sgd_solver.cpp:106] Iteration 28500, lr = 1e-14
I0730 11:25:22.747180 17816 solver.cpp:228] Iteration 28550, loss = 0.00120169
I0730 11:25:22.747304 17816 solver.cpp:244]     Train net output #0: loss = 0.00120175 (* 1 = 0.00120175 loss)
I0730 11:25:22.747323 17816 sgd_solver.cpp:106] Iteration 28550, lr = 1e-14
I0730 11:26:54.091383 17816 solver.cpp:228] Iteration 28600, loss = 0.0069838
I0730 11:26:54.091505 17816 solver.cpp:244]     Train net output #0: loss = 0.00698386 (* 1 = 0.00698386 loss)
I0730 11:26:54.091522 17816 sgd_solver.cpp:106] Iteration 28600, lr = 1e-14
I0730 11:28:25.459223 17816 solver.cpp:228] Iteration 28650, loss = 0.00171816
I0730 11:28:25.459347 17816 solver.cpp:244]     Train net output #0: loss = 0.00171822 (* 1 = 0.00171822 loss)
I0730 11:28:25.459365 17816 sgd_solver.cpp:106] Iteration 28650, lr = 1e-14
I0730 11:29:56.684756 17816 solver.cpp:228] Iteration 28700, loss = 0.00917362
I0730 11:29:56.684917 17816 solver.cpp:244]     Train net output #0: loss = 0.00917368 (* 1 = 0.00917368 loss)
I0730 11:29:56.684936 17816 sgd_solver.cpp:106] Iteration 28700, lr = 1e-14
I0730 11:31:28.204596 17816 solver.cpp:228] Iteration 28750, loss = 0.000733264
I0730 11:31:28.204726 17816 solver.cpp:244]     Train net output #0: loss = 0.000733321 (* 1 = 0.000733321 loss)
I0730 11:31:28.204746 17816 sgd_solver.cpp:106] Iteration 28750, lr = 1e-14
I0730 11:32:59.670707 17816 solver.cpp:228] Iteration 28800, loss = 0.00116159
I0730 11:32:59.670863 17816 solver.cpp:244]     Train net output #0: loss = 0.00116164 (* 1 = 0.00116164 loss)
I0730 11:32:59.670881 17816 sgd_solver.cpp:106] Iteration 28800, lr = 1e-14
I0730 11:34:31.075594 17816 solver.cpp:228] Iteration 28850, loss = 0.00470573
I0730 11:34:31.075753 17816 solver.cpp:244]     Train net output #0: loss = 0.00470578 (* 1 = 0.00470578 loss)
I0730 11:34:31.075773 17816 sgd_solver.cpp:106] Iteration 28850, lr = 1e-14
I0730 11:36:02.547410 17816 solver.cpp:228] Iteration 28900, loss = 0.00182542
I0730 11:36:02.547538 17816 solver.cpp:244]     Train net output #0: loss = 0.00182548 (* 1 = 0.00182548 loss)
I0730 11:36:02.547557 17816 sgd_solver.cpp:106] Iteration 28900, lr = 1e-14
I0730 11:37:34.093549 17816 solver.cpp:228] Iteration 28950, loss = 0.0012343
I0730 11:37:34.093675 17816 solver.cpp:244]     Train net output #0: loss = 0.00123436 (* 1 = 0.00123436 loss)
I0730 11:37:34.093693 17816 sgd_solver.cpp:106] Iteration 28950, lr = 1e-14
I0730 11:39:03.588522 17816 solver.cpp:337] Iteration 29000, Testing net (#0)
I0730 11:43:19.735443 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 11:43:19.735569 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 11:43:21.074687 17816 solver.cpp:228] Iteration 29000, loss = 0.0528972
I0730 11:43:21.074735 17816 solver.cpp:244]     Train net output #0: loss = 0.0528973 (* 1 = 0.0528973 loss)
I0730 11:43:21.074753 17816 sgd_solver.cpp:106] Iteration 29000, lr = 1e-14
I0730 11:44:54.293936 17816 solver.cpp:228] Iteration 29050, loss = 0.0101375
I0730 11:44:54.294069 17816 solver.cpp:244]     Train net output #0: loss = 0.0101376 (* 1 = 0.0101376 loss)
I0730 11:44:54.294087 17816 sgd_solver.cpp:106] Iteration 29050, lr = 1e-14
I0730 11:46:27.293308 17816 solver.cpp:228] Iteration 29100, loss = 0.00208059
I0730 11:46:27.293472 17816 solver.cpp:244]     Train net output #0: loss = 0.00208064 (* 1 = 0.00208064 loss)
I0730 11:46:27.293490 17816 sgd_solver.cpp:106] Iteration 29100, lr = 1e-14
I0730 11:48:00.643255 17816 solver.cpp:228] Iteration 29150, loss = 0.0262259
I0730 11:48:00.643425 17816 solver.cpp:244]     Train net output #0: loss = 0.026226 (* 1 = 0.026226 loss)
I0730 11:48:00.643445 17816 sgd_solver.cpp:106] Iteration 29150, lr = 1e-14
I0730 11:49:33.802049 17816 solver.cpp:228] Iteration 29200, loss = 0.00148499
I0730 11:49:33.802204 17816 solver.cpp:244]     Train net output #0: loss = 0.00148505 (* 1 = 0.00148505 loss)
I0730 11:49:33.802224 17816 sgd_solver.cpp:106] Iteration 29200, lr = 1e-14
I0730 11:51:07.055244 17816 solver.cpp:228] Iteration 29250, loss = 0.0019757
I0730 11:51:07.055375 17816 solver.cpp:244]     Train net output #0: loss = 0.00197575 (* 1 = 0.00197575 loss)
I0730 11:51:07.055394 17816 sgd_solver.cpp:106] Iteration 29250, lr = 1e-14
I0730 11:52:40.352260 17816 solver.cpp:228] Iteration 29300, loss = 0.00220896
I0730 11:52:40.352397 17816 solver.cpp:244]     Train net output #0: loss = 0.00220901 (* 1 = 0.00220901 loss)
I0730 11:52:40.352416 17816 sgd_solver.cpp:106] Iteration 29300, lr = 1e-14
I0730 11:54:13.474783 17816 solver.cpp:228] Iteration 29350, loss = 0.00297971
I0730 11:54:13.474936 17816 solver.cpp:244]     Train net output #0: loss = 0.00297976 (* 1 = 0.00297976 loss)
I0730 11:54:13.474956 17816 sgd_solver.cpp:106] Iteration 29350, lr = 1e-14
I0730 11:55:46.834615 17816 solver.cpp:228] Iteration 29400, loss = 0.000539857
I0730 11:55:46.834784 17816 solver.cpp:244]     Train net output #0: loss = 0.00053991 (* 1 = 0.00053991 loss)
I0730 11:55:46.834803 17816 sgd_solver.cpp:106] Iteration 29400, lr = 1e-14
I0730 11:57:19.999402 17816 solver.cpp:228] Iteration 29450, loss = 0.00604891
I0730 11:57:19.999528 17816 solver.cpp:244]     Train net output #0: loss = 0.00604897 (* 1 = 0.00604897 loss)
I0730 11:57:19.999547 17816 sgd_solver.cpp:106] Iteration 29450, lr = 1e-14
I0730 11:58:53.018757 17816 solver.cpp:228] Iteration 29500, loss = 0.00413736
I0730 11:58:53.018884 17816 solver.cpp:244]     Train net output #0: loss = 0.00413742 (* 1 = 0.00413742 loss)
I0730 11:58:53.018903 17816 sgd_solver.cpp:106] Iteration 29500, lr = 1e-14
I0730 12:00:26.352421 17816 solver.cpp:228] Iteration 29550, loss = 0.00446433
I0730 12:00:26.352553 17816 solver.cpp:244]     Train net output #0: loss = 0.00446438 (* 1 = 0.00446438 loss)
I0730 12:00:26.352579 17816 sgd_solver.cpp:106] Iteration 29550, lr = 1e-14
I0730 12:01:59.484696 17816 solver.cpp:228] Iteration 29600, loss = 0.00524817
I0730 12:01:59.484827 17816 solver.cpp:244]     Train net output #0: loss = 0.00524822 (* 1 = 0.00524822 loss)
I0730 12:01:59.484845 17816 sgd_solver.cpp:106] Iteration 29600, lr = 1e-14
I0730 12:03:32.844741 17816 solver.cpp:228] Iteration 29650, loss = 0.00653584
I0730 12:03:32.844899 17816 solver.cpp:244]     Train net output #0: loss = 0.0065359 (* 1 = 0.0065359 loss)
I0730 12:03:32.844918 17816 sgd_solver.cpp:106] Iteration 29650, lr = 1e-14
I0730 12:05:06.053299 17816 solver.cpp:228] Iteration 29700, loss = 0.00895603
I0730 12:05:06.053460 17816 solver.cpp:244]     Train net output #0: loss = 0.00895609 (* 1 = 0.00895609 loss)
I0730 12:05:06.053479 17816 sgd_solver.cpp:106] Iteration 29700, lr = 1e-14
I0730 12:06:39.177968 17816 solver.cpp:228] Iteration 29750, loss = 0.000987396
I0730 12:06:39.178134 17816 solver.cpp:244]     Train net output #0: loss = 0.000987458 (* 1 = 0.000987458 loss)
I0730 12:06:39.178154 17816 sgd_solver.cpp:106] Iteration 29750, lr = 1e-14
I0730 12:08:12.193606 17816 solver.cpp:228] Iteration 29800, loss = 0.0192486
I0730 12:08:12.193783 17816 solver.cpp:244]     Train net output #0: loss = 0.0192487 (* 1 = 0.0192487 loss)
I0730 12:08:12.193820 17816 sgd_solver.cpp:106] Iteration 29800, lr = 1e-14
I0730 12:09:45.426756 17816 solver.cpp:228] Iteration 29850, loss = 0.0102945
I0730 12:09:45.426898 17816 solver.cpp:244]     Train net output #0: loss = 0.0102946 (* 1 = 0.0102946 loss)
I0730 12:09:45.426916 17816 sgd_solver.cpp:106] Iteration 29850, lr = 1e-14
I0730 12:11:18.672024 17816 solver.cpp:228] Iteration 29900, loss = 0.00889029
I0730 12:11:18.672204 17816 solver.cpp:244]     Train net output #0: loss = 0.00889036 (* 1 = 0.00889036 loss)
I0730 12:11:18.672224 17816 sgd_solver.cpp:106] Iteration 29900, lr = 1e-14
I0730 12:12:51.705047 17816 solver.cpp:228] Iteration 29950, loss = 0.00325895
I0730 12:12:51.705201 17816 solver.cpp:244]     Train net output #0: loss = 0.00325901 (* 1 = 0.00325901 loss)
I0730 12:12:51.705220 17816 sgd_solver.cpp:106] Iteration 29950, lr = 1e-14
I0730 12:14:21.666414 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_30000.caffemodel
I0730 12:14:24.802242 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_30000.solverstate
I0730 12:14:28.581475 17816 solver.cpp:337] Iteration 30000, Testing net (#0)
I0730 12:18:37.869777 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 12:18:37.897261 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 12:18:39.215111 17816 solver.cpp:228] Iteration 30000, loss = 0.00112215
I0730 12:18:39.215162 17816 solver.cpp:244]     Train net output #0: loss = 0.00112221 (* 1 = 0.00112221 loss)
I0730 12:18:39.215178 17816 sgd_solver.cpp:106] Iteration 30000, lr = 1e-15
I0730 12:20:10.316136 17816 solver.cpp:228] Iteration 30050, loss = 0.00230361
I0730 12:20:10.316301 17816 solver.cpp:244]     Train net output #0: loss = 0.00230368 (* 1 = 0.00230368 loss)
I0730 12:20:10.316319 17816 sgd_solver.cpp:106] Iteration 30050, lr = 1e-15
I0730 12:21:41.635442 17816 solver.cpp:228] Iteration 30100, loss = 0.000343153
I0730 12:21:41.635588 17816 solver.cpp:244]     Train net output #0: loss = 0.000343221 (* 1 = 0.000343221 loss)
I0730 12:21:41.635607 17816 sgd_solver.cpp:106] Iteration 30100, lr = 1e-15
I0730 12:23:12.974405 17816 solver.cpp:228] Iteration 30150, loss = 0.00818591
I0730 12:23:12.974540 17816 solver.cpp:244]     Train net output #0: loss = 0.00818598 (* 1 = 0.00818598 loss)
I0730 12:23:12.974563 17816 sgd_solver.cpp:106] Iteration 30150, lr = 1e-15
I0730 12:24:44.343539 17816 solver.cpp:228] Iteration 30200, loss = 0.00900191
I0730 12:24:44.343667 17816 solver.cpp:244]     Train net output #0: loss = 0.00900198 (* 1 = 0.00900198 loss)
I0730 12:24:44.343686 17816 sgd_solver.cpp:106] Iteration 30200, lr = 1e-15
I0730 12:26:15.812655 17816 solver.cpp:228] Iteration 30250, loss = 0.00369864
I0730 12:26:15.812784 17816 solver.cpp:244]     Train net output #0: loss = 0.00369871 (* 1 = 0.00369871 loss)
I0730 12:26:15.812803 17816 sgd_solver.cpp:106] Iteration 30250, lr = 1e-15
I0730 12:27:47.415909 17816 solver.cpp:228] Iteration 30300, loss = 0.0110797
I0730 12:27:47.416071 17816 solver.cpp:244]     Train net output #0: loss = 0.0110798 (* 1 = 0.0110798 loss)
I0730 12:27:47.416090 17816 sgd_solver.cpp:106] Iteration 30300, lr = 1e-15
I0730 12:29:21.042759 17816 solver.cpp:228] Iteration 30350, loss = 0.00282673
I0730 12:29:21.042889 17816 solver.cpp:244]     Train net output #0: loss = 0.0028268 (* 1 = 0.0028268 loss)
I0730 12:29:21.042908 17816 sgd_solver.cpp:106] Iteration 30350, lr = 1e-15
I0730 12:30:54.474879 17816 solver.cpp:228] Iteration 30400, loss = 0.00150906
I0730 12:30:54.475003 17816 solver.cpp:244]     Train net output #0: loss = 0.00150914 (* 1 = 0.00150914 loss)
I0730 12:30:54.475021 17816 sgd_solver.cpp:106] Iteration 30400, lr = 1e-15
I0730 12:32:33.057236 17816 solver.cpp:228] Iteration 30450, loss = 0.0134301
I0730 12:32:33.057394 17816 solver.cpp:244]     Train net output #0: loss = 0.0134301 (* 1 = 0.0134301 loss)
I0730 12:32:33.057435 17816 sgd_solver.cpp:106] Iteration 30450, lr = 1e-15
I0730 12:34:11.540267 17816 solver.cpp:228] Iteration 30500, loss = 0.00233073
I0730 12:34:11.540421 17816 solver.cpp:244]     Train net output #0: loss = 0.0023308 (* 1 = 0.0023308 loss)
I0730 12:34:11.540446 17816 sgd_solver.cpp:106] Iteration 30500, lr = 1e-15
I0730 12:35:51.982677 17816 solver.cpp:228] Iteration 30550, loss = 0.00173848
I0730 12:35:51.982836 17816 solver.cpp:244]     Train net output #0: loss = 0.00173856 (* 1 = 0.00173856 loss)
I0730 12:35:51.982867 17816 sgd_solver.cpp:106] Iteration 30550, lr = 1e-15
I0730 12:37:32.985046 17816 solver.cpp:228] Iteration 30600, loss = 0.00176606
I0730 12:37:32.985247 17816 solver.cpp:244]     Train net output #0: loss = 0.00176613 (* 1 = 0.00176613 loss)
I0730 12:37:32.985275 17816 sgd_solver.cpp:106] Iteration 30600, lr = 1e-15
I0730 12:39:14.555658 17816 solver.cpp:228] Iteration 30650, loss = 0.00240394
I0730 12:39:14.577523 17816 solver.cpp:244]     Train net output #0: loss = 0.00240401 (* 1 = 0.00240401 loss)
I0730 12:39:14.577579 17816 sgd_solver.cpp:106] Iteration 30650, lr = 1e-15
I0730 12:40:56.321470 17816 solver.cpp:228] Iteration 30700, loss = 0.000876874
I0730 12:40:56.349177 17816 solver.cpp:244]     Train net output #0: loss = 0.000876951 (* 1 = 0.000876951 loss)
I0730 12:40:56.349226 17816 sgd_solver.cpp:106] Iteration 30700, lr = 1e-15
I0730 12:42:38.080780 17816 solver.cpp:228] Iteration 30750, loss = 0.00285337
I0730 12:42:38.109871 17816 solver.cpp:244]     Train net output #0: loss = 0.00285345 (* 1 = 0.00285345 loss)
I0730 12:42:38.109916 17816 sgd_solver.cpp:106] Iteration 30750, lr = 1e-15
I0730 12:44:19.725735 17816 solver.cpp:228] Iteration 30800, loss = 0.012443
I0730 12:44:19.748530 17816 solver.cpp:244]     Train net output #0: loss = 0.0124431 (* 1 = 0.0124431 loss)
I0730 12:44:19.748567 17816 sgd_solver.cpp:106] Iteration 30800, lr = 1e-15
I0730 12:46:01.034333 17816 solver.cpp:228] Iteration 30850, loss = 0.00369153
I0730 12:46:01.065455 17816 solver.cpp:244]     Train net output #0: loss = 0.00369161 (* 1 = 0.00369161 loss)
I0730 12:46:01.065505 17816 sgd_solver.cpp:106] Iteration 30850, lr = 1e-15
I0730 12:47:41.680811 17816 solver.cpp:228] Iteration 30900, loss = 0.00266135
I0730 12:47:41.705785 17816 solver.cpp:244]     Train net output #0: loss = 0.00266142 (* 1 = 0.00266142 loss)
I0730 12:47:41.705817 17816 sgd_solver.cpp:106] Iteration 30900, lr = 1e-15
I0730 12:49:17.138455 17816 solver.cpp:228] Iteration 30950, loss = 0.000136154
I0730 12:49:17.165242 17816 solver.cpp:244]     Train net output #0: loss = 0.000136229 (* 1 = 0.000136229 loss)
I0730 12:49:17.165289 17816 sgd_solver.cpp:106] Iteration 30950, lr = 1e-15
I0730 12:50:53.760265 17816 solver.cpp:337] Iteration 31000, Testing net (#0)
I0730 12:55:35.162209 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 12:55:35.209100 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 12:55:36.687016 17816 solver.cpp:228] Iteration 31000, loss = 0.0199528
I0730 12:55:36.687079 17816 solver.cpp:244]     Train net output #0: loss = 0.0199529 (* 1 = 0.0199529 loss)
I0730 12:55:36.687100 17816 sgd_solver.cpp:106] Iteration 31000, lr = 1e-15
I0730 12:57:20.083997 17816 solver.cpp:228] Iteration 31050, loss = 0.00235743
I0730 12:57:20.098114 17816 solver.cpp:244]     Train net output #0: loss = 0.0023575 (* 1 = 0.0023575 loss)
I0730 12:57:20.098187 17816 sgd_solver.cpp:106] Iteration 31050, lr = 1e-15
I0730 12:59:03.419180 17816 solver.cpp:228] Iteration 31100, loss = 0.00142334
I0730 12:59:03.419332 17816 solver.cpp:244]     Train net output #0: loss = 0.00142342 (* 1 = 0.00142342 loss)
I0730 12:59:03.419354 17816 sgd_solver.cpp:106] Iteration 31100, lr = 1e-15
I0730 13:00:46.875272 17816 solver.cpp:228] Iteration 31150, loss = 0.00171076
I0730 13:00:46.875406 17816 solver.cpp:244]     Train net output #0: loss = 0.00171084 (* 1 = 0.00171084 loss)
I0730 13:00:46.875427 17816 sgd_solver.cpp:106] Iteration 31150, lr = 1e-15
I0730 13:02:26.370860 17816 solver.cpp:228] Iteration 31200, loss = 0.0156611
I0730 13:02:26.371016 17816 solver.cpp:244]     Train net output #0: loss = 0.0156611 (* 1 = 0.0156611 loss)
I0730 13:02:26.371068 17816 sgd_solver.cpp:106] Iteration 31200, lr = 1e-15
I0730 13:04:02.439906 17816 solver.cpp:228] Iteration 31250, loss = 0.00345382
I0730 13:04:02.440070 17816 solver.cpp:244]     Train net output #0: loss = 0.0034539 (* 1 = 0.0034539 loss)
I0730 13:04:02.440090 17816 sgd_solver.cpp:106] Iteration 31250, lr = 1e-15
I0730 13:05:37.693342 17816 solver.cpp:228] Iteration 31300, loss = 0.000319185
I0730 13:05:37.693544 17816 solver.cpp:244]     Train net output #0: loss = 0.000319268 (* 1 = 0.000319268 loss)
I0730 13:05:37.693588 17816 sgd_solver.cpp:106] Iteration 31300, lr = 1e-15
I0730 13:07:11.430660 17816 solver.cpp:228] Iteration 31350, loss = 0.00597825
I0730 13:07:11.448114 17816 solver.cpp:244]     Train net output #0: loss = 0.00597834 (* 1 = 0.00597834 loss)
I0730 13:07:11.448166 17816 sgd_solver.cpp:106] Iteration 31350, lr = 1e-15
I0730 13:08:52.837258 17816 solver.cpp:228] Iteration 31400, loss = 9.42876e-05
I0730 13:08:52.887162 17816 solver.cpp:244]     Train net output #0: loss = 9.43764e-05 (* 1 = 9.43764e-05 loss)
I0730 13:08:52.887217 17816 sgd_solver.cpp:106] Iteration 31400, lr = 1e-15
I0730 13:10:37.694329 17816 solver.cpp:228] Iteration 31450, loss = 0.00118985
I0730 13:10:37.809252 17816 solver.cpp:244]     Train net output #0: loss = 0.00118994 (* 1 = 0.00118994 loss)
I0730 13:10:37.809303 17816 sgd_solver.cpp:106] Iteration 31450, lr = 1e-15
I0730 13:12:22.865082 17816 solver.cpp:228] Iteration 31500, loss = 0.00137989
I0730 13:12:22.886865 17816 solver.cpp:244]     Train net output #0: loss = 0.00137998 (* 1 = 0.00137998 loss)
I0730 13:12:22.886909 17816 sgd_solver.cpp:106] Iteration 31500, lr = 1e-15
I0730 13:14:07.273710 17816 solver.cpp:228] Iteration 31550, loss = 0.00738335
I0730 13:14:07.287835 17816 solver.cpp:244]     Train net output #0: loss = 0.00738344 (* 1 = 0.00738344 loss)
I0730 13:14:07.287889 17816 sgd_solver.cpp:106] Iteration 31550, lr = 1e-15
I0730 13:15:48.759415 17816 solver.cpp:228] Iteration 31600, loss = 0.00652049
I0730 13:15:48.759599 17816 solver.cpp:244]     Train net output #0: loss = 0.00652057 (* 1 = 0.00652057 loss)
I0730 13:15:48.759632 17816 sgd_solver.cpp:106] Iteration 31600, lr = 1e-15
I0730 13:17:29.563069 17816 solver.cpp:228] Iteration 31650, loss = 0.0005362
I0730 13:17:29.563297 17816 solver.cpp:244]     Train net output #0: loss = 0.000536288 (* 1 = 0.000536288 loss)
I0730 13:17:29.563326 17816 sgd_solver.cpp:106] Iteration 31650, lr = 1e-15
I0730 13:19:10.595820 17816 solver.cpp:228] Iteration 31700, loss = 0.0011604
I0730 13:19:10.595980 17816 solver.cpp:244]     Train net output #0: loss = 0.00116049 (* 1 = 0.00116049 loss)
I0730 13:19:10.596020 17816 sgd_solver.cpp:106] Iteration 31700, lr = 1e-15
I0730 13:20:51.320576 17816 solver.cpp:228] Iteration 31750, loss = 0.00211182
I0730 13:20:51.320760 17816 solver.cpp:244]     Train net output #0: loss = 0.0021119 (* 1 = 0.0021119 loss)
I0730 13:20:51.320790 17816 sgd_solver.cpp:106] Iteration 31750, lr = 1e-15
I0730 13:22:31.948631 17816 solver.cpp:228] Iteration 31800, loss = 0.00627938
I0730 13:22:31.948809 17816 solver.cpp:244]     Train net output #0: loss = 0.00627946 (* 1 = 0.00627946 loss)
I0730 13:22:31.948837 17816 sgd_solver.cpp:106] Iteration 31800, lr = 1e-15
I0730 13:24:16.062279 17816 solver.cpp:228] Iteration 31850, loss = 0.00510189
I0730 13:24:16.062441 17816 solver.cpp:244]     Train net output #0: loss = 0.00510197 (* 1 = 0.00510197 loss)
I0730 13:24:16.062466 17816 sgd_solver.cpp:106] Iteration 31850, lr = 1e-15
I0730 13:26:02.831950 17816 solver.cpp:228] Iteration 31900, loss = 0.0196844
I0730 13:26:02.832114 17816 solver.cpp:244]     Train net output #0: loss = 0.0196845 (* 1 = 0.0196845 loss)
I0730 13:26:02.832135 17816 sgd_solver.cpp:106] Iteration 31900, lr = 1e-15
I0730 13:27:46.245918 17816 solver.cpp:228] Iteration 31950, loss = 0.019706
I0730 13:27:46.246085 17816 solver.cpp:244]     Train net output #0: loss = 0.0197061 (* 1 = 0.0197061 loss)
I0730 13:27:46.246112 17816 sgd_solver.cpp:106] Iteration 31950, lr = 1e-15
I0730 13:29:26.859210 17816 solver.cpp:337] Iteration 32000, Testing net (#0)
I0730 13:34:17.371281 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 13:34:17.371423 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 13:34:18.898690 17816 solver.cpp:228] Iteration 32000, loss = 0.00110677
I0730 13:34:18.898749 17816 solver.cpp:244]     Train net output #0: loss = 0.00110685 (* 1 = 0.00110685 loss)
I0730 13:34:18.898768 17816 sgd_solver.cpp:106] Iteration 32000, lr = 1e-15
I0730 13:36:05.283427 17816 solver.cpp:228] Iteration 32050, loss = 0.00555764
I0730 13:36:05.293021 17816 solver.cpp:244]     Train net output #0: loss = 0.00555772 (* 1 = 0.00555772 loss)
I0730 13:36:05.293066 17816 sgd_solver.cpp:106] Iteration 32050, lr = 1e-15
I0730 13:37:51.554752 17816 solver.cpp:228] Iteration 32100, loss = 0.00224981
I0730 13:37:51.570838 17816 solver.cpp:244]     Train net output #0: loss = 0.00224989 (* 1 = 0.00224989 loss)
I0730 13:37:51.570874 17816 sgd_solver.cpp:106] Iteration 32100, lr = 1e-15
I0730 13:39:35.125813 17816 solver.cpp:228] Iteration 32150, loss = 0.00493426
I0730 13:39:35.139760 17816 solver.cpp:244]     Train net output #0: loss = 0.00493434 (* 1 = 0.00493434 loss)
I0730 13:39:35.139801 17816 sgd_solver.cpp:106] Iteration 32150, lr = 1e-15
I0730 13:41:13.235479 17816 solver.cpp:228] Iteration 32200, loss = 0.00566334
I0730 13:41:13.261801 17816 solver.cpp:244]     Train net output #0: loss = 0.00566342 (* 1 = 0.00566342 loss)
I0730 13:41:13.261848 17816 sgd_solver.cpp:106] Iteration 32200, lr = 1e-15
I0730 13:42:57.978463 17816 solver.cpp:228] Iteration 32250, loss = 0.00665865
I0730 13:42:58.006695 17816 solver.cpp:244]     Train net output #0: loss = 0.00665873 (* 1 = 0.00665873 loss)
I0730 13:42:58.006777 17816 sgd_solver.cpp:106] Iteration 32250, lr = 1e-15
I0730 13:44:43.126307 17816 solver.cpp:228] Iteration 32300, loss = 0.00700107
I0730 13:44:43.139708 17816 solver.cpp:244]     Train net output #0: loss = 0.00700115 (* 1 = 0.00700115 loss)
I0730 13:44:43.139757 17816 sgd_solver.cpp:106] Iteration 32300, lr = 1e-15
I0730 13:46:26.773483 17816 solver.cpp:228] Iteration 32350, loss = 0.00446725
I0730 13:46:26.797379 17816 solver.cpp:244]     Train net output #0: loss = 0.00446733 (* 1 = 0.00446733 loss)
I0730 13:46:26.797399 17816 sgd_solver.cpp:106] Iteration 32350, lr = 1e-15
I0730 13:48:05.516758 17816 solver.cpp:228] Iteration 32400, loss = 0.000754874
I0730 13:48:05.551734 17816 solver.cpp:244]     Train net output #0: loss = 0.000754953 (* 1 = 0.000754953 loss)
I0730 13:48:05.551789 17816 sgd_solver.cpp:106] Iteration 32400, lr = 1e-15
I0730 13:49:47.919349 17816 solver.cpp:228] Iteration 32450, loss = 0.00106199
I0730 13:49:47.944835 17816 solver.cpp:244]     Train net output #0: loss = 0.00106207 (* 1 = 0.00106207 loss)
I0730 13:49:47.944878 17816 sgd_solver.cpp:106] Iteration 32450, lr = 1e-15
I0730 13:51:31.407574 17816 solver.cpp:228] Iteration 32500, loss = 0.0106019
I0730 13:51:31.436295 17816 solver.cpp:244]     Train net output #0: loss = 0.010602 (* 1 = 0.010602 loss)
I0730 13:51:31.436332 17816 sgd_solver.cpp:106] Iteration 32500, lr = 1e-16
I0730 13:53:14.712728 17816 solver.cpp:228] Iteration 32550, loss = 0.00902004
I0730 13:53:14.739073 17816 solver.cpp:244]     Train net output #0: loss = 0.00902012 (* 1 = 0.00902012 loss)
I0730 13:53:14.739120 17816 sgd_solver.cpp:106] Iteration 32550, lr = 1e-16
I0730 13:54:58.102849 17816 solver.cpp:228] Iteration 32600, loss = 0.00225753
I0730 13:54:58.130280 17816 solver.cpp:244]     Train net output #0: loss = 0.0022576 (* 1 = 0.0022576 loss)
I0730 13:54:58.130328 17816 sgd_solver.cpp:106] Iteration 32600, lr = 1e-16
I0730 13:56:40.507287 17816 solver.cpp:228] Iteration 32650, loss = 0.000436444
I0730 13:56:40.556506 17816 solver.cpp:244]     Train net output #0: loss = 0.00043652 (* 1 = 0.00043652 loss)
I0730 13:56:40.556571 17816 sgd_solver.cpp:106] Iteration 32650, lr = 1e-16
I0730 13:58:23.800706 17816 solver.cpp:228] Iteration 32700, loss = 0.00687181
I0730 13:58:23.826061 17816 solver.cpp:244]     Train net output #0: loss = 0.00687189 (* 1 = 0.00687189 loss)
I0730 13:58:23.826133 17816 sgd_solver.cpp:106] Iteration 32700, lr = 1e-16
I0730 14:00:04.680173 17816 solver.cpp:228] Iteration 32750, loss = 0.00190828
I0730 14:00:04.710122 17816 solver.cpp:244]     Train net output #0: loss = 0.00190836 (* 1 = 0.00190836 loss)
I0730 14:00:04.710142 17816 sgd_solver.cpp:106] Iteration 32750, lr = 1e-16
I0730 14:01:41.442765 17816 solver.cpp:228] Iteration 32800, loss = 0.00118395
I0730 14:01:41.467993 17816 solver.cpp:244]     Train net output #0: loss = 0.00118404 (* 1 = 0.00118404 loss)
I0730 14:01:41.468088 17816 sgd_solver.cpp:106] Iteration 32800, lr = 1e-16
I0730 14:03:16.816545 17816 solver.cpp:228] Iteration 32850, loss = 0.00388028
I0730 14:03:16.838709 17816 solver.cpp:244]     Train net output #0: loss = 0.00388036 (* 1 = 0.00388036 loss)
I0730 14:03:16.838755 17816 sgd_solver.cpp:106] Iteration 32850, lr = 1e-16
I0730 14:04:52.071972 17816 solver.cpp:228] Iteration 32900, loss = 0.0128205
I0730 14:04:52.098516 17816 solver.cpp:244]     Train net output #0: loss = 0.0128205 (* 1 = 0.0128205 loss)
I0730 14:04:52.098546 17816 sgd_solver.cpp:106] Iteration 32900, lr = 1e-16
I0730 14:06:25.442365 17816 solver.cpp:228] Iteration 32950, loss = 0.000701712
I0730 14:06:25.472650 17816 solver.cpp:244]     Train net output #0: loss = 0.000701795 (* 1 = 0.000701795 loss)
I0730 14:06:25.472700 17816 sgd_solver.cpp:106] Iteration 32950, lr = 1e-16
I0730 14:07:56.699894 17816 solver.cpp:337] Iteration 33000, Testing net (#0)
I0730 14:12:14.367089 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 14:12:14.396168 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 14:12:15.733909 17816 solver.cpp:228] Iteration 33000, loss = 0.000801298
I0730 14:12:15.733961 17816 solver.cpp:244]     Train net output #0: loss = 0.00080138 (* 1 = 0.00080138 loss)
I0730 14:12:15.733981 17816 sgd_solver.cpp:106] Iteration 33000, lr = 1e-16
I0730 14:13:49.079442 17816 solver.cpp:228] Iteration 33050, loss = 0.00209277
I0730 14:13:49.123529 17816 solver.cpp:244]     Train net output #0: loss = 0.00209285 (* 1 = 0.00209285 loss)
I0730 14:13:49.123574 17816 sgd_solver.cpp:106] Iteration 33050, lr = 1e-16
I0730 14:15:22.044214 17816 solver.cpp:228] Iteration 33100, loss = 0.00501378
I0730 14:15:22.064870 17816 solver.cpp:244]     Train net output #0: loss = 0.00501386 (* 1 = 0.00501386 loss)
I0730 14:15:22.064900 17816 sgd_solver.cpp:106] Iteration 33100, lr = 1e-16
I0730 14:16:55.114815 17816 solver.cpp:228] Iteration 33150, loss = 0.00899884
I0730 14:16:55.272497 17816 solver.cpp:244]     Train net output #0: loss = 0.00899893 (* 1 = 0.00899893 loss)
I0730 14:16:55.272534 17816 sgd_solver.cpp:106] Iteration 33150, lr = 1e-16
I0730 14:18:35.131732 17816 solver.cpp:228] Iteration 33200, loss = 0.00717581
I0730 14:18:35.131891 17816 solver.cpp:244]     Train net output #0: loss = 0.00717589 (* 1 = 0.00717589 loss)
I0730 14:18:35.131914 17816 sgd_solver.cpp:106] Iteration 33200, lr = 1e-16
I0730 14:20:18.234659 17816 solver.cpp:228] Iteration 33250, loss = 0.000749526
I0730 14:20:18.234797 17816 solver.cpp:244]     Train net output #0: loss = 0.000749616 (* 1 = 0.000749616 loss)
I0730 14:20:18.234818 17816 sgd_solver.cpp:106] Iteration 33250, lr = 1e-16
I0730 14:22:01.720298 17816 solver.cpp:228] Iteration 33300, loss = 0.00218224
I0730 14:22:01.720433 17816 solver.cpp:244]     Train net output #0: loss = 0.00218234 (* 1 = 0.00218234 loss)
I0730 14:22:01.720453 17816 sgd_solver.cpp:106] Iteration 33300, lr = 1e-16
I0730 14:23:45.129727 17816 solver.cpp:228] Iteration 33350, loss = 0.000761569
I0730 14:23:45.129871 17816 solver.cpp:244]     Train net output #0: loss = 0.000761662 (* 1 = 0.000761662 loss)
I0730 14:23:45.129892 17816 sgd_solver.cpp:106] Iteration 33350, lr = 1e-16
I0730 14:25:28.591730 17816 solver.cpp:228] Iteration 33400, loss = 0.0174334
I0730 14:25:28.591886 17816 solver.cpp:244]     Train net output #0: loss = 0.0174335 (* 1 = 0.0174335 loss)
I0730 14:25:28.591910 17816 sgd_solver.cpp:106] Iteration 33400, lr = 1e-16
I0730 14:27:09.837056 17816 solver.cpp:228] Iteration 33450, loss = 0.00353068
I0730 14:27:09.837183 17816 solver.cpp:244]     Train net output #0: loss = 0.00353077 (* 1 = 0.00353077 loss)
I0730 14:27:09.837201 17816 sgd_solver.cpp:106] Iteration 33450, lr = 1e-16
I0730 14:28:46.045004 17816 solver.cpp:228] Iteration 33500, loss = 0.0027014
I0730 14:28:46.063555 17816 solver.cpp:244]     Train net output #0: loss = 0.00270149 (* 1 = 0.00270149 loss)
I0730 14:28:46.063623 17816 sgd_solver.cpp:106] Iteration 33500, lr = 1e-16
I0730 14:30:21.520596 17816 solver.cpp:228] Iteration 33550, loss = 0.0188764
I0730 14:30:21.547448 17816 solver.cpp:244]     Train net output #0: loss = 0.0188765 (* 1 = 0.0188765 loss)
I0730 14:30:21.547497 17816 sgd_solver.cpp:106] Iteration 33550, lr = 1e-16
I0730 14:31:55.297004 17816 solver.cpp:228] Iteration 33600, loss = 0.00521451
I0730 14:31:55.320868 17816 solver.cpp:244]     Train net output #0: loss = 0.0052146 (* 1 = 0.0052146 loss)
I0730 14:31:55.320912 17816 sgd_solver.cpp:106] Iteration 33600, lr = 1e-16
I0730 14:33:28.396307 17816 solver.cpp:228] Iteration 33650, loss = 0.000246185
I0730 14:33:28.396433 17816 solver.cpp:244]     Train net output #0: loss = 0.000246275 (* 1 = 0.000246275 loss)
I0730 14:33:28.396452 17816 sgd_solver.cpp:106] Iteration 33650, lr = 1e-16
I0730 14:35:01.523437 17816 solver.cpp:228] Iteration 33700, loss = 0.00333132
I0730 14:35:01.523557 17816 solver.cpp:244]     Train net output #0: loss = 0.00333141 (* 1 = 0.00333141 loss)
I0730 14:35:01.523576 17816 sgd_solver.cpp:106] Iteration 33700, lr = 1e-16
I0730 14:36:34.627780 17816 solver.cpp:228] Iteration 33750, loss = 0.00569391
I0730 14:36:34.627903 17816 solver.cpp:244]     Train net output #0: loss = 0.005694 (* 1 = 0.005694 loss)
I0730 14:36:34.627923 17816 sgd_solver.cpp:106] Iteration 33750, lr = 1e-16
I0730 14:38:07.859611 17816 solver.cpp:228] Iteration 33800, loss = 0.00599757
I0730 14:38:07.859732 17816 solver.cpp:244]     Train net output #0: loss = 0.00599765 (* 1 = 0.00599765 loss)
I0730 14:38:07.859751 17816 sgd_solver.cpp:106] Iteration 33800, lr = 1e-16
I0730 14:39:41.175752 17816 solver.cpp:228] Iteration 33850, loss = 0.00094026
I0730 14:39:41.175928 17816 solver.cpp:244]     Train net output #0: loss = 0.000940349 (* 1 = 0.000940349 loss)
I0730 14:39:41.175948 17816 sgd_solver.cpp:106] Iteration 33850, lr = 1e-16
I0730 14:41:14.312695 17816 solver.cpp:228] Iteration 33900, loss = 0.0035032
I0730 14:41:14.312856 17816 solver.cpp:244]     Train net output #0: loss = 0.00350329 (* 1 = 0.00350329 loss)
I0730 14:41:14.312875 17816 sgd_solver.cpp:106] Iteration 33900, lr = 1e-16
I0730 14:42:48.169592 17816 solver.cpp:228] Iteration 33950, loss = 0.00113213
I0730 14:42:48.169728 17816 solver.cpp:244]     Train net output #0: loss = 0.00113223 (* 1 = 0.00113223 loss)
I0730 14:42:48.169755 17816 sgd_solver.cpp:106] Iteration 33950, lr = 1e-16
I0730 14:44:28.477499 17816 solver.cpp:337] Iteration 34000, Testing net (#0)
I0730 14:49:16.026916 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 14:49:16.027053 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 14:49:17.506518 17816 solver.cpp:228] Iteration 34000, loss = 0.00318449
I0730 14:49:17.506583 17816 solver.cpp:244]     Train net output #0: loss = 0.00318458 (* 1 = 0.00318458 loss)
I0730 14:49:17.506604 17816 sgd_solver.cpp:106] Iteration 34000, lr = 1e-16
I0730 14:51:00.856436 17816 solver.cpp:228] Iteration 34050, loss = 0.000939363
I0730 14:51:00.856567 17816 solver.cpp:244]     Train net output #0: loss = 0.000939459 (* 1 = 0.000939459 loss)
I0730 14:51:00.856587 17816 sgd_solver.cpp:106] Iteration 34050, lr = 1e-16
I0730 14:52:46.667851 17816 solver.cpp:228] Iteration 34100, loss = 0.0021322
I0730 14:52:46.667994 17816 solver.cpp:244]     Train net output #0: loss = 0.0021323 (* 1 = 0.0021323 loss)
I0730 14:52:46.668016 17816 sgd_solver.cpp:106] Iteration 34100, lr = 1e-16
I0730 14:54:29.104418 17816 solver.cpp:228] Iteration 34150, loss = 0.00229996
I0730 14:54:29.104593 17816 solver.cpp:244]     Train net output #0: loss = 0.00230005 (* 1 = 0.00230005 loss)
I0730 14:54:29.104614 17816 sgd_solver.cpp:106] Iteration 34150, lr = 1e-16
I0730 14:56:12.174067 17816 solver.cpp:228] Iteration 34200, loss = 0.00225789
I0730 14:56:12.174211 17816 solver.cpp:244]     Train net output #0: loss = 0.00225799 (* 1 = 0.00225799 loss)
I0730 14:56:12.174232 17816 sgd_solver.cpp:106] Iteration 34200, lr = 1e-16
I0730 14:57:55.412287 17816 solver.cpp:228] Iteration 34250, loss = 0.00323733
I0730 14:57:55.412504 17816 solver.cpp:244]     Train net output #0: loss = 0.00323743 (* 1 = 0.00323743 loss)
I0730 14:57:55.412533 17816 sgd_solver.cpp:106] Iteration 34250, lr = 1e-16
I0730 14:59:38.452549 17816 solver.cpp:228] Iteration 34300, loss = 0.00135928
I0730 14:59:38.482990 17816 solver.cpp:244]     Train net output #0: loss = 0.00135936 (* 1 = 0.00135936 loss)
I0730 14:59:38.483096 17816 sgd_solver.cpp:106] Iteration 34300, lr = 1e-16
I0730 15:01:21.879870 17816 solver.cpp:228] Iteration 34350, loss = 0.000307859
I0730 15:01:21.905397 17816 solver.cpp:244]     Train net output #0: loss = 0.000307945 (* 1 = 0.000307945 loss)
I0730 15:01:21.905474 17816 sgd_solver.cpp:106] Iteration 34350, lr = 1e-16
I0730 15:03:04.390431 17816 solver.cpp:228] Iteration 34400, loss = 0.000447092
I0730 15:03:04.420294 17816 solver.cpp:244]     Train net output #0: loss = 0.000447176 (* 1 = 0.000447176 loss)
I0730 15:03:04.420328 17816 sgd_solver.cpp:106] Iteration 34400, lr = 1e-16
I0730 15:04:47.397768 17816 solver.cpp:228] Iteration 34450, loss = 0.00259374
I0730 15:04:47.412286 17816 solver.cpp:244]     Train net output #0: loss = 0.00259382 (* 1 = 0.00259382 loss)
I0730 15:04:47.412305 17816 sgd_solver.cpp:106] Iteration 34450, lr = 1e-16
I0730 15:06:28.656013 17816 solver.cpp:228] Iteration 34500, loss = 0.00351804
I0730 15:06:28.673836 17816 solver.cpp:244]     Train net output #0: loss = 0.00351813 (* 1 = 0.00351813 loss)
I0730 15:06:28.673877 17816 sgd_solver.cpp:106] Iteration 34500, lr = 1e-16
I0730 15:08:13.836587 17816 solver.cpp:228] Iteration 34550, loss = 0.000866509
I0730 15:08:13.862561 17816 solver.cpp:244]     Train net output #0: loss = 0.000866593 (* 1 = 0.000866593 loss)
I0730 15:08:13.862633 17816 sgd_solver.cpp:106] Iteration 34550, lr = 1e-16
I0730 15:09:59.732756 17816 solver.cpp:228] Iteration 34600, loss = 0.00483219
I0730 15:09:59.760932 17816 solver.cpp:244]     Train net output #0: loss = 0.00483227 (* 1 = 0.00483227 loss)
I0730 15:09:59.760982 17816 sgd_solver.cpp:106] Iteration 34600, lr = 1e-16
I0730 15:11:43.091442 17816 solver.cpp:228] Iteration 34650, loss = 0.00583459
I0730 15:11:43.130168 17816 solver.cpp:244]     Train net output #0: loss = 0.00583468 (* 1 = 0.00583468 loss)
I0730 15:11:43.130209 17816 sgd_solver.cpp:106] Iteration 34650, lr = 1e-16
I0730 15:13:26.025965 17816 solver.cpp:228] Iteration 34700, loss = 0.0019627
I0730 15:13:26.044591 17816 solver.cpp:244]     Train net output #0: loss = 0.00196278 (* 1 = 0.00196278 loss)
I0730 15:13:26.044634 17816 sgd_solver.cpp:106] Iteration 34700, lr = 1e-16
I0730 15:15:09.040894 17816 solver.cpp:228] Iteration 34750, loss = 0.0134451
I0730 15:15:09.081096 17816 solver.cpp:244]     Train net output #0: loss = 0.0134452 (* 1 = 0.0134452 loss)
I0730 15:15:09.081140 17816 sgd_solver.cpp:106] Iteration 34750, lr = 1e-16
I0730 15:16:52.064698 17816 solver.cpp:228] Iteration 34800, loss = 0.00416014
I0730 15:16:52.095316 17816 solver.cpp:244]     Train net output #0: loss = 0.00416023 (* 1 = 0.00416023 loss)
I0730 15:16:52.095355 17816 sgd_solver.cpp:106] Iteration 34800, lr = 1e-16
I0730 15:18:35.010388 17816 solver.cpp:228] Iteration 34850, loss = 0.00223159
I0730 15:18:35.031941 17816 solver.cpp:244]     Train net output #0: loss = 0.00223167 (* 1 = 0.00223167 loss)
I0730 15:18:35.031980 17816 sgd_solver.cpp:106] Iteration 34850, lr = 1e-16
I0730 15:20:17.942698 17816 solver.cpp:228] Iteration 34900, loss = 0.00204964
I0730 15:20:17.968534 17816 solver.cpp:244]     Train net output #0: loss = 0.00204972 (* 1 = 0.00204972 loss)
I0730 15:20:17.968571 17816 sgd_solver.cpp:106] Iteration 34900, lr = 1e-16
I0730 15:22:00.843652 17816 solver.cpp:228] Iteration 34950, loss = 0.00100327
I0730 15:22:00.871873 17816 solver.cpp:244]     Train net output #0: loss = 0.00100335 (* 1 = 0.00100335 loss)
I0730 15:22:00.871914 17816 sgd_solver.cpp:106] Iteration 34950, lr = 1e-16
I0730 15:23:40.992163 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_35000.caffemodel
I0730 15:23:47.205426 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_35000.solverstate
I0730 15:23:50.893918 17816 solver.cpp:337] Iteration 35000, Testing net (#0)
I0730 15:28:18.139084 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 15:28:18.172744 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 15:28:19.624300 17816 solver.cpp:228] Iteration 35000, loss = 0.000272278
I0730 15:28:19.624361 17816 solver.cpp:244]     Train net output #0: loss = 0.000272358 (* 1 = 0.000272358 loss)
I0730 15:28:19.624382 17816 sgd_solver.cpp:106] Iteration 35000, lr = 1e-17
I0730 15:30:01.696252 17816 solver.cpp:228] Iteration 35050, loss = 0.00353335
I0730 15:30:01.719542 17816 solver.cpp:244]     Train net output #0: loss = 0.00353343 (* 1 = 0.00353343 loss)
I0730 15:30:01.719599 17816 sgd_solver.cpp:106] Iteration 35050, lr = 1e-17
I0730 15:31:44.804955 17816 solver.cpp:228] Iteration 35100, loss = 0.00236619
I0730 15:31:44.833597 17816 solver.cpp:244]     Train net output #0: loss = 0.00236627 (* 1 = 0.00236627 loss)
I0730 15:31:44.833639 17816 sgd_solver.cpp:106] Iteration 35100, lr = 1e-17
I0730 15:33:27.877950 17816 solver.cpp:228] Iteration 35150, loss = 0.00702682
I0730 15:33:27.878206 17816 solver.cpp:244]     Train net output #0: loss = 0.0070269 (* 1 = 0.0070269 loss)
I0730 15:33:27.878238 17816 sgd_solver.cpp:106] Iteration 35150, lr = 1e-17
I0730 15:35:10.944365 17816 solver.cpp:228] Iteration 35200, loss = 0.000617194
I0730 15:35:10.944505 17816 solver.cpp:244]     Train net output #0: loss = 0.00061728 (* 1 = 0.00061728 loss)
I0730 15:35:10.944527 17816 sgd_solver.cpp:106] Iteration 35200, lr = 1e-17
I0730 15:36:54.059916 17816 solver.cpp:228] Iteration 35250, loss = 0.000757445
I0730 15:36:54.060065 17816 solver.cpp:244]     Train net output #0: loss = 0.000757533 (* 1 = 0.000757533 loss)
I0730 15:36:54.060087 17816 sgd_solver.cpp:106] Iteration 35250, lr = 1e-17
I0730 15:38:37.198137 17816 solver.cpp:228] Iteration 35300, loss = 0.00679272
I0730 15:38:37.198292 17816 solver.cpp:244]     Train net output #0: loss = 0.00679281 (* 1 = 0.00679281 loss)
I0730 15:38:37.198315 17816 sgd_solver.cpp:106] Iteration 35300, lr = 1e-17
I0730 15:40:18.679077 17816 solver.cpp:228] Iteration 35350, loss = 0.00140733
I0730 15:40:18.679214 17816 solver.cpp:244]     Train net output #0: loss = 0.00140743 (* 1 = 0.00140743 loss)
I0730 15:40:18.679234 17816 sgd_solver.cpp:106] Iteration 35350, lr = 1e-17
I0730 15:42:01.459938 17816 solver.cpp:228] Iteration 35400, loss = 0.00496501
I0730 15:42:01.460067 17816 solver.cpp:244]     Train net output #0: loss = 0.0049651 (* 1 = 0.0049651 loss)
I0730 15:42:01.460089 17816 sgd_solver.cpp:106] Iteration 35400, lr = 1e-17
I0730 15:43:43.936388 17816 solver.cpp:228] Iteration 35450, loss = 0.00510291
I0730 15:43:43.936534 17816 solver.cpp:244]     Train net output #0: loss = 0.005103 (* 1 = 0.005103 loss)
I0730 15:43:43.936558 17816 sgd_solver.cpp:106] Iteration 35450, lr = 1e-17
I0730 15:45:27.164436 17816 solver.cpp:228] Iteration 35500, loss = 0.00245244
I0730 15:45:27.164607 17816 solver.cpp:244]     Train net output #0: loss = 0.00245253 (* 1 = 0.00245253 loss)
I0730 15:45:27.164690 17816 sgd_solver.cpp:106] Iteration 35500, lr = 1e-17
I0730 15:47:10.533257 17816 solver.cpp:228] Iteration 35550, loss = 0.00326161
I0730 15:47:10.533408 17816 solver.cpp:244]     Train net output #0: loss = 0.0032617 (* 1 = 0.0032617 loss)
I0730 15:47:10.533432 17816 sgd_solver.cpp:106] Iteration 35550, lr = 1e-17
I0730 15:48:53.692739 17816 solver.cpp:228] Iteration 35600, loss = 0.00189139
I0730 15:48:53.692864 17816 solver.cpp:244]     Train net output #0: loss = 0.00189148 (* 1 = 0.00189148 loss)
I0730 15:48:53.692883 17816 sgd_solver.cpp:106] Iteration 35600, lr = 1e-17
I0730 15:50:36.792348 17816 solver.cpp:228] Iteration 35650, loss = 0.000925291
I0730 15:50:36.792560 17816 solver.cpp:244]     Train net output #0: loss = 0.000925382 (* 1 = 0.000925382 loss)
I0730 15:50:36.792654 17816 sgd_solver.cpp:106] Iteration 35650, lr = 1e-17
I0730 15:52:19.993803 17816 solver.cpp:228] Iteration 35700, loss = 0.000828051
I0730 15:52:20.017352 17816 solver.cpp:244]     Train net output #0: loss = 0.000828145 (* 1 = 0.000828145 loss)
I0730 15:52:20.017400 17816 sgd_solver.cpp:106] Iteration 35700, lr = 1e-17
I0730 15:54:02.557024 17816 solver.cpp:228] Iteration 35750, loss = 0.00177026
I0730 15:54:02.587896 17816 solver.cpp:244]     Train net output #0: loss = 0.00177036 (* 1 = 0.00177036 loss)
I0730 15:54:02.587941 17816 sgd_solver.cpp:106] Iteration 35750, lr = 1e-17
I0730 15:55:43.384132 17816 solver.cpp:228] Iteration 35800, loss = 0.00042206
I0730 15:55:43.405727 17816 solver.cpp:244]     Train net output #0: loss = 0.000422142 (* 1 = 0.000422142 loss)
I0730 15:55:43.405773 17816 sgd_solver.cpp:106] Iteration 35800, lr = 1e-17
I0730 15:57:18.686404 17816 solver.cpp:228] Iteration 35850, loss = 0.00094535
I0730 15:57:18.709949 17816 solver.cpp:244]     Train net output #0: loss = 0.000945426 (* 1 = 0.000945426 loss)
I0730 15:57:18.710018 17816 sgd_solver.cpp:106] Iteration 35850, lr = 1e-17
I0730 15:58:53.043666 17816 solver.cpp:228] Iteration 35900, loss = 0.011445
I0730 15:58:53.094007 17816 solver.cpp:244]     Train net output #0: loss = 0.0114451 (* 1 = 0.0114451 loss)
I0730 15:58:53.094230 17816 sgd_solver.cpp:106] Iteration 35900, lr = 1e-17
I0730 16:00:30.811249 17816 solver.cpp:228] Iteration 35950, loss = 0.00315518
I0730 16:00:30.811401 17816 solver.cpp:244]     Train net output #0: loss = 0.00315525 (* 1 = 0.00315525 loss)
I0730 16:00:30.811426 17816 sgd_solver.cpp:106] Iteration 35950, lr = 1e-17
I0730 16:02:13.566535 17816 solver.cpp:337] Iteration 36000, Testing net (#0)
I0730 16:07:01.471683 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 16:07:01.471840 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 16:07:02.848356 17816 solver.cpp:228] Iteration 36000, loss = 0.000406365
I0730 16:07:02.848422 17816 solver.cpp:244]     Train net output #0: loss = 0.000406437 (* 1 = 0.000406437 loss)
I0730 16:07:02.848444 17816 sgd_solver.cpp:106] Iteration 36000, lr = 1e-17
I0730 16:08:39.619431 17816 solver.cpp:228] Iteration 36050, loss = 0.00280669
I0730 16:08:39.619571 17816 solver.cpp:244]     Train net output #0: loss = 0.00280677 (* 1 = 0.00280677 loss)
I0730 16:08:39.619591 17816 sgd_solver.cpp:106] Iteration 36050, lr = 1e-17
I0730 16:10:16.587231 17816 solver.cpp:228] Iteration 36100, loss = 0.00140871
I0730 16:10:16.587374 17816 solver.cpp:244]     Train net output #0: loss = 0.00140878 (* 1 = 0.00140878 loss)
I0730 16:10:16.587396 17816 sgd_solver.cpp:106] Iteration 36100, lr = 1e-17
I0730 16:11:52.069005 17816 solver.cpp:228] Iteration 36150, loss = 0.00334301
I0730 16:11:52.069156 17816 solver.cpp:244]     Train net output #0: loss = 0.00334308 (* 1 = 0.00334308 loss)
I0730 16:11:52.069175 17816 sgd_solver.cpp:106] Iteration 36150, lr = 1e-17
I0730 16:13:27.300249 17816 solver.cpp:228] Iteration 36200, loss = 0.00027113
I0730 16:13:27.300410 17816 solver.cpp:244]     Train net output #0: loss = 0.000271212 (* 1 = 0.000271212 loss)
I0730 16:13:27.300431 17816 sgd_solver.cpp:106] Iteration 36200, lr = 1e-17
I0730 16:15:02.699653 17816 solver.cpp:228] Iteration 36250, loss = 0.00178101
I0730 16:15:02.699781 17816 solver.cpp:244]     Train net output #0: loss = 0.00178109 (* 1 = 0.00178109 loss)
I0730 16:15:02.699800 17816 sgd_solver.cpp:106] Iteration 36250, lr = 1e-17
I0730 16:16:37.972331 17816 solver.cpp:228] Iteration 36300, loss = 0.00047525
I0730 16:16:37.972461 17816 solver.cpp:244]     Train net output #0: loss = 0.000475334 (* 1 = 0.000475334 loss)
I0730 16:16:37.972481 17816 sgd_solver.cpp:106] Iteration 36300, lr = 1e-17
I0730 16:18:13.479029 17816 solver.cpp:228] Iteration 36350, loss = 0.0064444
I0730 16:18:13.479204 17816 solver.cpp:244]     Train net output #0: loss = 0.00644449 (* 1 = 0.00644449 loss)
I0730 16:18:13.479223 17816 sgd_solver.cpp:106] Iteration 36350, lr = 1e-17
I0730 16:19:48.654706 17816 solver.cpp:228] Iteration 36400, loss = 0.0104773
I0730 16:19:48.654837 17816 solver.cpp:244]     Train net output #0: loss = 0.0104774 (* 1 = 0.0104774 loss)
I0730 16:19:48.654856 17816 sgd_solver.cpp:106] Iteration 36400, lr = 1e-17
I0730 16:21:25.920215 17816 solver.cpp:228] Iteration 36450, loss = 0.00666223
I0730 16:21:25.920406 17816 solver.cpp:244]     Train net output #0: loss = 0.00666232 (* 1 = 0.00666232 loss)
I0730 16:21:25.920441 17816 sgd_solver.cpp:106] Iteration 36450, lr = 1e-17
I0730 16:23:10.099218 17816 solver.cpp:228] Iteration 36500, loss = 0.00369141
I0730 16:23:10.099349 17816 solver.cpp:244]     Train net output #0: loss = 0.00369149 (* 1 = 0.00369149 loss)
I0730 16:23:10.099371 17816 sgd_solver.cpp:106] Iteration 36500, lr = 1e-17
I0730 16:24:49.496644 17816 solver.cpp:228] Iteration 36550, loss = 0.0549718
I0730 16:24:49.496778 17816 solver.cpp:244]     Train net output #0: loss = 0.0549719 (* 1 = 0.0549719 loss)
I0730 16:24:49.496873 17816 sgd_solver.cpp:106] Iteration 36550, lr = 1e-17
I0730 16:26:30.167575 17816 solver.cpp:228] Iteration 36600, loss = 0.000605316
I0730 16:26:30.167747 17816 solver.cpp:244]     Train net output #0: loss = 0.000605402 (* 1 = 0.000605402 loss)
I0730 16:26:30.167774 17816 sgd_solver.cpp:106] Iteration 36600, lr = 1e-17
I0730 16:28:11.092470 17816 solver.cpp:228] Iteration 36650, loss = 0.0120895
I0730 16:28:11.092620 17816 solver.cpp:244]     Train net output #0: loss = 0.0120896 (* 1 = 0.0120896 loss)
I0730 16:28:11.092648 17816 sgd_solver.cpp:106] Iteration 36650, lr = 1e-17
I0730 16:29:51.844439 17816 solver.cpp:228] Iteration 36700, loss = 0.00422541
I0730 16:29:51.844574 17816 solver.cpp:244]     Train net output #0: loss = 0.0042255 (* 1 = 0.0042255 loss)
I0730 16:29:51.844599 17816 sgd_solver.cpp:106] Iteration 36700, lr = 1e-17
I0730 16:31:34.861533 17816 solver.cpp:228] Iteration 36750, loss = 0.00208897
I0730 16:31:34.861673 17816 solver.cpp:244]     Train net output #0: loss = 0.00208906 (* 1 = 0.00208906 loss)
I0730 16:31:34.861697 17816 sgd_solver.cpp:106] Iteration 36750, lr = 1e-17
I0730 16:33:17.757861 17816 solver.cpp:228] Iteration 36800, loss = 0.00544509
I0730 16:33:17.758050 17816 solver.cpp:244]     Train net output #0: loss = 0.00544519 (* 1 = 0.00544519 loss)
I0730 16:33:17.758080 17816 sgd_solver.cpp:106] Iteration 36800, lr = 1e-17
I0730 16:35:00.795730 17816 solver.cpp:228] Iteration 36850, loss = 0.00117893
I0730 16:35:00.795930 17816 solver.cpp:244]     Train net output #0: loss = 0.00117902 (* 1 = 0.00117902 loss)
I0730 16:35:00.795964 17816 sgd_solver.cpp:106] Iteration 36850, lr = 1e-17
I0730 16:36:44.508126 17816 solver.cpp:228] Iteration 36900, loss = 0.00216911
I0730 16:36:44.508641 17816 solver.cpp:244]     Train net output #0: loss = 0.0021692 (* 1 = 0.0021692 loss)
I0730 16:36:44.508725 17816 sgd_solver.cpp:106] Iteration 36900, lr = 1e-17
I0730 16:38:24.419947 17816 solver.cpp:228] Iteration 36950, loss = 0.00330754
I0730 16:38:24.420099 17816 solver.cpp:244]     Train net output #0: loss = 0.00330763 (* 1 = 0.00330763 loss)
I0730 16:38:24.420120 17816 sgd_solver.cpp:106] Iteration 36950, lr = 1e-17
I0730 16:39:59.934484 17816 solver.cpp:337] Iteration 37000, Testing net (#0)
I0730 16:44:26.827191 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0730 16:44:26.827321 17816 solver.cpp:404]     Test net output #1: loss = 0.0859061 (* 1 = 0.0859061 loss)
I0730 16:44:28.213273 17816 solver.cpp:228] Iteration 37000, loss = 0.00959103
I0730 16:44:28.213331 17816 solver.cpp:244]     Train net output #0: loss = 0.00959111 (* 1 = 0.00959111 loss)
I0730 16:44:28.213357 17816 sgd_solver.cpp:106] Iteration 37000, lr = 1e-17
I0730 16:46:04.129673 17816 solver.cpp:228] Iteration 37050, loss = 0.00232349
I0730 16:46:04.129837 17816 solver.cpp:244]     Train net output #0: loss = 0.00232358 (* 1 = 0.00232358 loss)
I0730 16:46:04.129856 17816 sgd_solver.cpp:106] Iteration 37050, lr = 1e-17
I0730 16:47:40.076221 17816 solver.cpp:228] Iteration 37100, loss = 0.00115915
I0730 16:47:40.076426 17816 solver.cpp:244]     Train net output #0: loss = 0.00115924 (* 1 = 0.00115924 loss)
I0730 16:47:40.076444 17816 sgd_solver.cpp:106] Iteration 37100, lr = 1e-17
I0730 16:49:15.912714 17816 solver.cpp:228] Iteration 37150, loss = 0.000243496
I0730 16:49:15.939328 17816 solver.cpp:244]     Train net output #0: loss = 0.000243583 (* 1 = 0.000243583 loss)
I0730 16:49:15.939348 17816 sgd_solver.cpp:106] Iteration 37150, lr = 1e-17
I0730 16:50:51.766945 17816 solver.cpp:228] Iteration 37200, loss = 0.000450826
I0730 16:50:51.787276 17816 solver.cpp:244]     Train net output #0: loss = 0.000450912 (* 1 = 0.000450912 loss)
I0730 16:50:51.787295 17816 sgd_solver.cpp:106] Iteration 37200, lr = 1e-17
I0730 16:52:28.333057 17816 solver.cpp:228] Iteration 37250, loss = 0.00331058
I0730 16:52:28.356400 17816 solver.cpp:244]     Train net output #0: loss = 0.00331066 (* 1 = 0.00331066 loss)
I0730 16:52:28.356442 17816 sgd_solver.cpp:106] Iteration 37250, lr = 1e-17
I0730 16:54:04.945729 17816 solver.cpp:228] Iteration 37300, loss = 0.00103427
I0730 16:54:04.969738 17816 solver.cpp:244]     Train net output #0: loss = 0.00103435 (* 1 = 0.00103435 loss)
I0730 16:54:04.969781 17816 sgd_solver.cpp:106] Iteration 37300, lr = 1e-17
I0730 16:55:41.235330 17816 solver.cpp:228] Iteration 37350, loss = 0.00335314
I0730 16:55:41.250216 17816 solver.cpp:244]     Train net output #0: loss = 0.00335322 (* 1 = 0.00335322 loss)
I0730 16:55:41.250252 17816 sgd_solver.cpp:106] Iteration 37350, lr = 1e-17
I0730 16:57:17.251626 17816 solver.cpp:228] Iteration 37400, loss = 0.0022141
I0730 16:57:17.275652 17816 solver.cpp:244]     Train net output #0: loss = 0.00221419 (* 1 = 0.00221419 loss)
I0730 16:57:17.275686 17816 sgd_solver.cpp:106] Iteration 37400, lr = 1e-17
I0730 16:58:53.005012 17816 solver.cpp:228] Iteration 37450, loss = 0.00244243
I0730 16:58:53.034651 17816 solver.cpp:244]     Train net output #0: loss = 0.00244252 (* 1 = 0.00244252 loss)
I0730 16:58:53.034670 17816 sgd_solver.cpp:106] Iteration 37450, lr = 1e-17
I0730 17:00:28.923921 17816 solver.cpp:228] Iteration 37500, loss = 0.000620476
I0730 17:00:28.949198 17816 solver.cpp:244]     Train net output #0: loss = 0.000620561 (* 1 = 0.000620561 loss)
I0730 17:00:28.949242 17816 sgd_solver.cpp:106] Iteration 37500, lr = 1e-18
I0730 17:02:04.827762 17816 solver.cpp:228] Iteration 37550, loss = 0.00124455
I0730 17:02:04.852460 17816 solver.cpp:244]     Train net output #0: loss = 0.00124463 (* 1 = 0.00124463 loss)
I0730 17:02:04.852530 17816 sgd_solver.cpp:106] Iteration 37550, lr = 1e-18
I0730 17:03:40.973717 17816 solver.cpp:228] Iteration 37600, loss = 0.00119724
I0730 17:03:40.973845 17816 solver.cpp:244]     Train net output #0: loss = 0.00119732 (* 1 = 0.00119732 loss)
I0730 17:03:40.973875 17816 sgd_solver.cpp:106] Iteration 37600, lr = 1e-18
I0730 17:05:21.105427 17816 solver.cpp:228] Iteration 37650, loss = 0.00105131
I0730 17:05:21.105600 17816 solver.cpp:244]     Train net output #0: loss = 0.00105139 (* 1 = 0.00105139 loss)
I0730 17:05:21.105630 17816 sgd_solver.cpp:106] Iteration 37650, lr = 1e-18
I0730 17:07:03.333748 17816 solver.cpp:228] Iteration 37700, loss = 0.000773303
I0730 17:07:03.333945 17816 solver.cpp:244]     Train net output #0: loss = 0.000773386 (* 1 = 0.000773386 loss)
I0730 17:07:03.333969 17816 sgd_solver.cpp:106] Iteration 37700, lr = 1e-18
I0730 17:08:42.973155 17816 solver.cpp:228] Iteration 37750, loss = 0.00587609
I0730 17:08:42.973304 17816 solver.cpp:244]     Train net output #0: loss = 0.00587618 (* 1 = 0.00587618 loss)
I0730 17:08:42.973326 17816 sgd_solver.cpp:106] Iteration 37750, lr = 1e-18
I0730 17:10:26.034165 17816 solver.cpp:228] Iteration 37800, loss = 0.00129561
I0730 17:10:26.034282 17816 solver.cpp:244]     Train net output #0: loss = 0.0012957 (* 1 = 0.0012957 loss)
I0730 17:10:26.034301 17816 sgd_solver.cpp:106] Iteration 37800, lr = 1e-18
I0730 17:12:09.812016 17816 solver.cpp:228] Iteration 37850, loss = 0.00178549
I0730 17:12:09.812326 17816 solver.cpp:244]     Train net output #0: loss = 0.00178558 (* 1 = 0.00178558 loss)
I0730 17:12:09.812407 17816 sgd_solver.cpp:106] Iteration 37850, lr = 1e-18
I0730 17:13:52.865224 17816 solver.cpp:228] Iteration 37900, loss = 0.000980038
I0730 17:13:52.878159 17816 solver.cpp:244]     Train net output #0: loss = 0.000980127 (* 1 = 0.000980127 loss)
I0730 17:13:52.878201 17816 sgd_solver.cpp:106] Iteration 37900, lr = 1e-18
I0730 17:15:36.273200 17816 solver.cpp:228] Iteration 37950, loss = 0.000444037
I0730 17:15:36.273382 17816 solver.cpp:244]     Train net output #0: loss = 0.000444128 (* 1 = 0.000444128 loss)
I0730 17:15:36.273417 17816 sgd_solver.cpp:106] Iteration 37950, lr = 1e-18
I0730 17:17:14.689054 17816 solver.cpp:337] Iteration 38000, Testing net (#0)
I0730 17:22:00.563199 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 17:22:00.563356 17816 solver.cpp:404]     Test net output #1: loss = 0.0859059 (* 1 = 0.0859059 loss)
I0730 17:22:02.089862 17816 solver.cpp:228] Iteration 38000, loss = 0.00673661
I0730 17:22:02.089927 17816 solver.cpp:244]     Train net output #0: loss = 0.00673671 (* 1 = 0.00673671 loss)
I0730 17:22:02.089948 17816 sgd_solver.cpp:106] Iteration 38000, lr = 1e-18
I0730 17:23:48.121811 17816 solver.cpp:228] Iteration 38050, loss = 0.00478127
I0730 17:23:48.121965 17816 solver.cpp:244]     Train net output #0: loss = 0.00478136 (* 1 = 0.00478136 loss)
I0730 17:23:48.121989 17816 sgd_solver.cpp:106] Iteration 38050, lr = 1e-18
I0730 17:25:33.049998 17816 solver.cpp:228] Iteration 38100, loss = 0.00220007
I0730 17:25:33.050158 17816 solver.cpp:244]     Train net output #0: loss = 0.00220016 (* 1 = 0.00220016 loss)
I0730 17:25:33.050185 17816 sgd_solver.cpp:106] Iteration 38100, lr = 1e-18
I0730 17:27:16.159371 17816 solver.cpp:228] Iteration 38150, loss = 0.0059487
I0730 17:27:16.159526 17816 solver.cpp:244]     Train net output #0: loss = 0.00594879 (* 1 = 0.00594879 loss)
I0730 17:27:16.159551 17816 sgd_solver.cpp:106] Iteration 38150, lr = 1e-18
I0730 17:28:58.717468 17816 solver.cpp:228] Iteration 38200, loss = 0.00580491
I0730 17:28:58.717656 17816 solver.cpp:244]     Train net output #0: loss = 0.005805 (* 1 = 0.005805 loss)
I0730 17:28:58.717682 17816 sgd_solver.cpp:106] Iteration 38200, lr = 1e-18
I0730 17:30:36.738605 17816 solver.cpp:228] Iteration 38250, loss = 0.000859621
I0730 17:30:36.738742 17816 solver.cpp:244]     Train net output #0: loss = 0.000859714 (* 1 = 0.000859714 loss)
I0730 17:30:36.738761 17816 sgd_solver.cpp:106] Iteration 38250, lr = 1e-18
I0730 17:32:12.103996 17816 solver.cpp:228] Iteration 38300, loss = 0.00568605
I0730 17:32:12.104130 17816 solver.cpp:244]     Train net output #0: loss = 0.00568614 (* 1 = 0.00568614 loss)
I0730 17:32:12.104149 17816 sgd_solver.cpp:106] Iteration 38300, lr = 1e-18
I0730 17:33:51.415913 17816 solver.cpp:228] Iteration 38350, loss = 0.00992788
I0730 17:33:51.416024 17816 solver.cpp:244]     Train net output #0: loss = 0.00992797 (* 1 = 0.00992797 loss)
I0730 17:33:51.416043 17816 sgd_solver.cpp:106] Iteration 38350, lr = 1e-18
I0730 17:35:28.916120 17816 solver.cpp:228] Iteration 38400, loss = 0.00587627
I0730 17:35:28.916322 17816 solver.cpp:244]     Train net output #0: loss = 0.00587635 (* 1 = 0.00587635 loss)
I0730 17:35:28.916365 17816 sgd_solver.cpp:106] Iteration 38400, lr = 1e-18
I0730 17:37:07.215008 17816 solver.cpp:228] Iteration 38450, loss = 0.00532766
I0730 17:37:07.215162 17816 solver.cpp:244]     Train net output #0: loss = 0.00532775 (* 1 = 0.00532775 loss)
I0730 17:37:07.215188 17816 sgd_solver.cpp:106] Iteration 38450, lr = 1e-18
I0730 17:38:52.312131 17816 solver.cpp:228] Iteration 38500, loss = 0.00257857
I0730 17:38:52.312288 17816 solver.cpp:244]     Train net output #0: loss = 0.00257866 (* 1 = 0.00257866 loss)
I0730 17:38:52.312309 17816 sgd_solver.cpp:106] Iteration 38500, lr = 1e-18
I0730 17:40:31.131170 17816 solver.cpp:228] Iteration 38550, loss = 0.0130959
I0730 17:40:31.131590 17816 solver.cpp:244]     Train net output #0: loss = 0.013096 (* 1 = 0.013096 loss)
I0730 17:40:31.131620 17816 sgd_solver.cpp:106] Iteration 38550, lr = 1e-18
I0730 17:42:13.557170 17816 solver.cpp:228] Iteration 38600, loss = 0.00179644
I0730 17:42:13.557317 17816 solver.cpp:244]     Train net output #0: loss = 0.00179653 (* 1 = 0.00179653 loss)
I0730 17:42:13.557349 17816 sgd_solver.cpp:106] Iteration 38600, lr = 1e-18
I0730 17:43:56.412523 17816 solver.cpp:228] Iteration 38650, loss = 0.000484642
I0730 17:43:56.412716 17816 solver.cpp:244]     Train net output #0: loss = 0.000484731 (* 1 = 0.000484731 loss)
I0730 17:43:56.412749 17816 sgd_solver.cpp:106] Iteration 38650, lr = 1e-18
I0730 17:45:40.570101 17816 solver.cpp:228] Iteration 38700, loss = 0.00133064
I0730 17:45:40.570250 17816 solver.cpp:244]     Train net output #0: loss = 0.00133073 (* 1 = 0.00133073 loss)
I0730 17:45:40.570272 17816 sgd_solver.cpp:106] Iteration 38700, lr = 1e-18
I0730 17:47:24.606540 17816 solver.cpp:228] Iteration 38750, loss = 0.00748536
I0730 17:47:24.606658 17816 solver.cpp:244]     Train net output #0: loss = 0.00748545 (* 1 = 0.00748545 loss)
I0730 17:47:24.606678 17816 sgd_solver.cpp:106] Iteration 38750, lr = 1e-18
I0730 17:49:04.779841 17816 solver.cpp:228] Iteration 38800, loss = 0.0017519
I0730 17:49:04.780014 17816 solver.cpp:244]     Train net output #0: loss = 0.00175199 (* 1 = 0.00175199 loss)
I0730 17:49:04.780045 17816 sgd_solver.cpp:106] Iteration 38800, lr = 1e-18
I0730 17:50:41.289310 17816 solver.cpp:228] Iteration 38850, loss = 0.000911816
I0730 17:50:41.289445 17816 solver.cpp:244]     Train net output #0: loss = 0.000911902 (* 1 = 0.000911902 loss)
I0730 17:50:41.289464 17816 sgd_solver.cpp:106] Iteration 38850, lr = 1e-18
I0730 17:52:16.719902 17816 solver.cpp:228] Iteration 38900, loss = 0.00292539
I0730 17:52:16.720036 17816 solver.cpp:244]     Train net output #0: loss = 0.00292548 (* 1 = 0.00292548 loss)
I0730 17:52:16.720053 17816 sgd_solver.cpp:106] Iteration 38900, lr = 1e-18
I0730 17:53:52.228539 17816 solver.cpp:228] Iteration 38950, loss = 0.00951921
I0730 17:53:52.228667 17816 solver.cpp:244]     Train net output #0: loss = 0.00951929 (* 1 = 0.00951929 loss)
I0730 17:53:52.228684 17816 sgd_solver.cpp:106] Iteration 38950, lr = 1e-18
I0730 17:55:24.441913 17816 solver.cpp:337] Iteration 39000, Testing net (#0)
I0730 17:59:45.857394 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 17:59:45.857565 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 17:59:47.303185 17816 solver.cpp:228] Iteration 39000, loss = 0.0438981
I0730 17:59:47.303256 17816 solver.cpp:244]     Train net output #0: loss = 0.0438982 (* 1 = 0.0438982 loss)
I0730 17:59:47.303282 17816 sgd_solver.cpp:106] Iteration 39000, lr = 1e-18
I0730 18:01:30.433876 17816 solver.cpp:228] Iteration 39050, loss = 0.0173279
I0730 18:01:30.448007 17816 solver.cpp:244]     Train net output #0: loss = 0.017328 (* 1 = 0.017328 loss)
I0730 18:01:30.448061 17816 sgd_solver.cpp:106] Iteration 39050, lr = 1e-18
I0730 18:03:10.768759 17816 solver.cpp:228] Iteration 39100, loss = 0.00162178
I0730 18:03:10.768929 17816 solver.cpp:244]     Train net output #0: loss = 0.00162187 (* 1 = 0.00162187 loss)
I0730 18:03:10.768965 17816 sgd_solver.cpp:106] Iteration 39100, lr = 1e-18
I0730 18:04:52.000087 17816 solver.cpp:228] Iteration 39150, loss = 0.00720315
I0730 18:04:52.000247 17816 solver.cpp:244]     Train net output #0: loss = 0.00720324 (* 1 = 0.00720324 loss)
I0730 18:04:52.000277 17816 sgd_solver.cpp:106] Iteration 39150, lr = 1e-18
I0730 18:06:33.175148 17816 solver.cpp:228] Iteration 39200, loss = 0.00369282
I0730 18:06:33.175303 17816 solver.cpp:244]     Train net output #0: loss = 0.0036929 (* 1 = 0.0036929 loss)
I0730 18:06:33.175328 17816 sgd_solver.cpp:106] Iteration 39200, lr = 1e-18
I0730 18:08:14.354877 17816 solver.cpp:228] Iteration 39250, loss = 0.00461934
I0730 18:08:14.355026 17816 solver.cpp:244]     Train net output #0: loss = 0.00461943 (* 1 = 0.00461943 loss)
I0730 18:08:14.355046 17816 sgd_solver.cpp:106] Iteration 39250, lr = 1e-18
I0730 18:09:56.877274 17816 solver.cpp:228] Iteration 39300, loss = 0.00175653
I0730 18:09:56.897124 17816 solver.cpp:244]     Train net output #0: loss = 0.00175662 (* 1 = 0.00175662 loss)
I0730 18:09:56.897166 17816 sgd_solver.cpp:106] Iteration 39300, lr = 1e-18
I0730 18:11:40.072713 17816 solver.cpp:228] Iteration 39350, loss = 0.000890576
I0730 18:11:40.091496 17816 solver.cpp:244]     Train net output #0: loss = 0.000890656 (* 1 = 0.000890656 loss)
I0730 18:11:40.091568 17816 sgd_solver.cpp:106] Iteration 39350, lr = 1e-18
I0730 18:13:23.322396 17816 solver.cpp:228] Iteration 39400, loss = 0.0129692
I0730 18:13:23.338594 17816 solver.cpp:244]     Train net output #0: loss = 0.0129693 (* 1 = 0.0129693 loss)
I0730 18:13:23.338635 17816 sgd_solver.cpp:106] Iteration 39400, lr = 1e-18
I0730 18:15:04.854943 17816 solver.cpp:228] Iteration 39450, loss = 0.00668362
I0730 18:15:04.877439 17816 solver.cpp:244]     Train net output #0: loss = 0.0066837 (* 1 = 0.0066837 loss)
I0730 18:15:04.877511 17816 sgd_solver.cpp:106] Iteration 39450, lr = 1e-18
I0730 18:16:47.290194 17816 solver.cpp:228] Iteration 39500, loss = 0.00299877
I0730 18:16:47.303714 17816 solver.cpp:244]     Train net output #0: loss = 0.00299885 (* 1 = 0.00299885 loss)
I0730 18:16:47.303773 17816 sgd_solver.cpp:106] Iteration 39500, lr = 1e-18
I0730 18:18:30.147091 17816 solver.cpp:228] Iteration 39550, loss = 0.00158889
I0730 18:18:30.173760 17816 solver.cpp:244]     Train net output #0: loss = 0.00158897 (* 1 = 0.00158897 loss)
I0730 18:18:30.173805 17816 sgd_solver.cpp:106] Iteration 39550, lr = 1e-18
I0730 18:20:13.843996 17816 solver.cpp:228] Iteration 39600, loss = 0.000776838
I0730 18:20:13.875843 17816 solver.cpp:244]     Train net output #0: loss = 0.00077692 (* 1 = 0.00077692 loss)
I0730 18:20:13.875896 17816 sgd_solver.cpp:106] Iteration 39600, lr = 1e-18
I0730 18:21:57.276564 17816 solver.cpp:228] Iteration 39650, loss = 0.00090327
I0730 18:21:57.300477 17816 solver.cpp:244]     Train net output #0: loss = 0.000903352 (* 1 = 0.000903352 loss)
I0730 18:21:57.300523 17816 sgd_solver.cpp:106] Iteration 39650, lr = 1e-18
I0730 18:23:40.870452 17816 solver.cpp:228] Iteration 39700, loss = 0.00739504
I0730 18:23:40.880579 17816 solver.cpp:244]     Train net output #0: loss = 0.00739512 (* 1 = 0.00739512 loss)
I0730 18:23:40.880641 17816 sgd_solver.cpp:106] Iteration 39700, lr = 1e-18
I0730 18:25:23.717164 17816 solver.cpp:228] Iteration 39750, loss = 0.000101634
I0730 18:25:23.739440 17816 solver.cpp:244]     Train net output #0: loss = 0.000101713 (* 1 = 0.000101713 loss)
I0730 18:25:23.739472 17816 sgd_solver.cpp:106] Iteration 39750, lr = 1e-18
I0730 18:27:07.004426 17816 solver.cpp:228] Iteration 39800, loss = 0.000479564
I0730 18:27:07.020014 17816 solver.cpp:244]     Train net output #0: loss = 0.000479642 (* 1 = 0.000479642 loss)
I0730 18:27:07.020059 17816 sgd_solver.cpp:106] Iteration 39800, lr = 1e-18
I0730 18:28:50.512384 17816 solver.cpp:228] Iteration 39850, loss = 0.00145421
I0730 18:28:50.533457 17816 solver.cpp:244]     Train net output #0: loss = 0.00145428 (* 1 = 0.00145428 loss)
I0730 18:28:50.533488 17816 sgd_solver.cpp:106] Iteration 39850, lr = 1e-18
I0730 18:30:34.049701 17816 solver.cpp:228] Iteration 39900, loss = 0.00251807
I0730 18:30:34.069452 17816 solver.cpp:244]     Train net output #0: loss = 0.00251815 (* 1 = 0.00251815 loss)
I0730 18:30:34.069519 17816 sgd_solver.cpp:106] Iteration 39900, lr = 1e-18
I0730 18:32:17.519644 17816 solver.cpp:228] Iteration 39950, loss = 0.00100848
I0730 18:32:17.549577 17816 solver.cpp:244]     Train net output #0: loss = 0.00100856 (* 1 = 0.00100856 loss)
I0730 18:32:17.549643 17816 sgd_solver.cpp:106] Iteration 39950, lr = 1e-18
I0730 18:33:58.911883 17816 solver.cpp:454] Snapshotting to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_40000.caffemodel
I0730 18:34:06.116492 17816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/manush/deeplearning-image-classifier/caffe_models/caffe_model_2/caffe_model_2_iter_40000.solverstate
I0730 18:34:11.478718 17816 solver.cpp:317] Iteration 40000, loss = 0.00505775
I0730 18:34:11.478775 17816 solver.cpp:337] Iteration 40000, Testing net (#0)
I0730 18:36:58.674433 17827 blocking_queue.cpp:50] Waiting for data
I0730 18:38:45.067555 17816 solver.cpp:404]     Test net output #0: accuracy = 0.972643
I0730 18:38:45.067723 17816 solver.cpp:404]     Test net output #1: loss = 0.085906 (* 1 = 0.085906 loss)
I0730 18:38:45.067742 17816 solver.cpp:322] Optimization Done.
I0730 18:38:45.091104 17816 caffe.cpp:222] Optimization Done.
